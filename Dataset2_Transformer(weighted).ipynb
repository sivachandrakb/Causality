{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba46f2ea-39af-4961-8e4e-d25dde589930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Embedding roberta-base: 100%|██████████████████████████████████████████████████████████| 19/19 [00:02<00:00,  6.76it/s]\n",
      "Embedding bert-base-uncased: 100%|█████████████████████████████████████████████████████| 19/19 [00:02<00:00,  7.20it/s]\n",
      "Embedding facebook/bart-base: 100%|████████████████████████████████████████████████████| 19/19 [00:03<00:00,  4.95it/s]\n",
      "Embedding nreimers/MiniLM-L6-H384-uncased: 100%|███████████████████████████████████████| 19/19 [00:00<00:00, 30.64it/s]\n",
      "Embedding distilbert-base-uncased: 100%|███████████████████████████████████████████████| 19/19 [00:01<00:00, 10.55it/s]\n",
      "Embedding microsoft/deberta-base: 100%|████████████████████████████████████████████████| 19/19 [00:04<00:00,  4.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Transformer Embedding Ensemble with Weighted Soft Voting\n",
    "Models: RoBERTa, BERT, BART, MiniLM, DistilBERT, DeBERTa\n",
    "Classifiers: RandomForest, GaussianNB, XGBoost, Linear SVM\n",
    "Evaluation: 10-fold Cross Validation\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Load Dataset\n",
    "# ---------------------------\n",
    "df = pd.read_csv(\"Processed_Causality_Dataset.csv\")\n",
    "\n",
    "X_raw = df[\"Sentence\"]\n",
    "y_raw = df[\"Causality_Label\"]\n",
    "\n",
    "# Train/test split\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X_raw, y_raw, stratify=y_raw, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Preprocessing\n",
    "# ---------------------------\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|@\\w+|[^a-zA-Z\\s]\", \"\", text)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "X_train_processed = X_train_raw.apply(preprocess)\n",
    "X_test_processed  = X_test_raw.apply(preprocess)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 3: Transformer Embeddings\n",
    "# ---------------------------\n",
    "print(\"Step 3: Generating embeddings...\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transformer_models = {\n",
    "    \"roberta\": \"roberta-base\",\n",
    "    \"bert\": \"bert-base-uncased\",\n",
    "    \"bart\": \"facebook/bart-base\",\n",
    "    \"minilm\": \"nreimers/MiniLM-L6-H384-uncased\",\n",
    "    \"distilbert\": \"distilbert-base-uncased\",\n",
    "    \"deberta\": \"microsoft/deberta-base\"\n",
    "}\n",
    "\n",
    "def get_embeddings(texts, model_name, batch_size=16, max_len=128):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=f\"Embedding {model_name}\"):\n",
    "            batch = texts[i:i+batch_size].tolist()\n",
    "            encodings = tokenizer(batch, padding=True, truncation=True,\n",
    "                                  max_length=max_len, return_tensors=\"pt\").to(device)\n",
    "            outputs = model(**encodings)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "            all_embeddings.append(cls_embeddings.cpu().numpy())\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "# Extract embeddings for each model\n",
    "embeddings = {}\n",
    "for name, model_name in transformer_models.items():\n",
    "    embeddings[name] = get_embeddings(X_train_processed, model_name)\n",
    "\n",
    "# Concatenate embeddings into one feature vector\n",
    "X_train_emb = np.hstack(list(embeddings.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0a37960-bbea-4fc1-aaf7-233cdbac1c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Dataset ===\n",
      "Dataset File: Processed_Causality_Dataset.csv\n",
      "Total Samples: 376, Columns: 2\n",
      "Train Split: 300 | Test Split: 76\n",
      "Label Classes: [0, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Imports\n",
    "# ---------------------------\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "dataset_path = r\"Processed_Causality_Dataset.csv\"\n",
    "\n",
    "print(\"=== Loading Dataset ===\")\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract raw features + labels\n",
    "X_raw = df[\"Sentence\"].astype(str)\n",
    "y_raw = df[\"Causality_Label\"]\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_raw)\n",
    "\n",
    "# Train/test split (just for check; CV will use full training set)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X_raw, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Dataset File: {dataset_path}\")\n",
    "print(f\"Total Samples: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
    "print(f\"Train Split: {len(X_train_raw)} | Test Split: {len(X_test_raw)}\")\n",
    "print(f\"Label Classes: {list(label_encoder.classes_)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51409e31-31cc-4099-b33a-bc5abb5df172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== BERT-base Training (10-Fold CV, Weighted Soft Voting) ==========\n",
      "Model Spec: 12 layers, 768 hidden, 12 heads | Weight: 1.2\n",
      "\n",
      "========== BERT-base | Fold 1/10 - Weighted Soft Voting ==========\n",
      "Epoch   1/100 - acc: 70.26% - prec: 70.11% - rec: 70.02% - f1: 70.24%\n",
      "Epoch   2/100 - acc: 70.07% - prec: 70.03% - rec: 70.10% - f1: 69.83%\n",
      "Epoch   3/100 - acc: 70.32% - prec: 69.88% - rec: 70.34% - f1: 70.63%\n",
      "Epoch   4/100 - acc: 70.37% - prec: 70.71% - rec: 71.00% - f1: 70.60%\n",
      "Epoch   5/100 - acc: 70.18% - prec: 71.22% - rec: 70.83% - f1: 71.33%\n",
      "Epoch   6/100 - acc: 70.00% - prec: 71.59% - rec: 71.24% - f1: 70.84%\n",
      "Epoch   7/100 - acc: 70.00% - prec: 71.78% - rec: 71.57% - f1: 71.62%\n",
      "Epoch   8/100 - acc: 70.07% - prec: 71.85% - rec: 71.94% - f1: 71.66%\n",
      "Epoch   9/100 - acc: 70.00% - prec: 72.07% - rec: 72.18% - f1: 72.31%\n",
      "Epoch  10/100 - acc: 70.02% - prec: 72.65% - rec: 72.22% - f1: 72.42%\n",
      "--- Fold 1 Final ---\n",
      "Accuracy: 70.02% | Precision: 72.65% | Recall: 72.22% | F1: 72.42%\n",
      "\n",
      "========== BERT-base | Fold 2/10 - Weighted Soft Voting ==========\n",
      "Epoch  11/100 - acc: 70.11% - prec: 72.85% - rec: 72.52% - f1: 72.68%\n",
      "Epoch  12/100 - acc: 70.54% - prec: 72.76% - rec: 72.66% - f1: 72.93%\n",
      "Epoch  13/100 - acc: 70.13% - prec: 73.39% - rec: 73.49% - f1: 73.37%\n",
      "Epoch  14/100 - acc: 70.07% - prec: 73.57% - rec: 73.32% - f1: 73.20%\n",
      "Epoch  15/100 - acc: 70.09% - prec: 73.58% - rec: 73.41% - f1: 73.35%\n",
      "Epoch  16/100 - acc: 70.38% - prec: 74.09% - rec: 74.51% - f1: 73.77%\n",
      "Epoch  17/100 - acc: 70.62% - prec: 74.37% - rec: 74.24% - f1: 74.33%\n",
      "Epoch  18/100 - acc: 70.38% - prec: 74.89% - rec: 74.40% - f1: 74.79%\n",
      "Epoch  19/100 - acc: 70.64% - prec: 74.44% - rec: 74.87% - f1: 74.38%\n",
      "Epoch  20/100 - acc: 70.72% - prec: 75.43% - rec: 75.28% - f1: 75.24%\n",
      "--- Fold 2 Final ---\n",
      "Accuracy: 70.72% | Precision: 75.43% | Recall: 75.28% | F1: 75.24%\n",
      "\n",
      "========== BERT-base | Fold 3/10 - Weighted Soft Voting ==========\n",
      "Epoch  21/100 - acc: 71.09% - prec: 75.33% - rec: 75.44% - f1: 75.31%\n",
      "Epoch  22/100 - acc: 71.03% - prec: 75.61% - rec: 75.63% - f1: 75.67%\n",
      "Epoch  23/100 - acc: 70.68% - prec: 75.52% - rec: 75.71% - f1: 75.91%\n",
      "Epoch  24/100 - acc: 70.95% - prec: 76.16% - rec: 76.12% - f1: 76.03%\n",
      "Epoch  25/100 - acc: 70.95% - prec: 76.50% - rec: 76.42% - f1: 76.21%\n",
      "Epoch  26/100 - acc: 71.72% - prec: 76.57% - rec: 76.53% - f1: 76.90%\n",
      "Epoch  27/100 - acc: 71.50% - prec: 76.89% - rec: 76.90% - f1: 76.68%\n",
      "Epoch  28/100 - acc: 71.55% - prec: 77.07% - rec: 76.74% - f1: 77.06%\n",
      "Epoch  29/100 - acc: 71.20% - prec: 77.51% - rec: 77.55% - f1: 77.47%\n",
      "Epoch  30/100 - acc: 71.99% - prec: 77.88% - rec: 78.06% - f1: 77.90%\n",
      "--- Fold 3 Final ---\n",
      "Accuracy: 71.99% | Precision: 77.88% | Recall: 78.06% | F1: 77.90%\n",
      "\n",
      "========== BERT-base | Fold 4/10 - Weighted Soft Voting ==========\n",
      "Epoch  31/100 - acc: 72.33% - prec: 78.10% - rec: 77.74% - f1: 78.01%\n",
      "Epoch  32/100 - acc: 72.49% - prec: 78.08% - rec: 78.40% - f1: 78.25%\n",
      "Epoch  33/100 - acc: 72.87% - prec: 78.79% - rec: 78.50% - f1: 78.11%\n",
      "Epoch  34/100 - acc: 73.55% - prec: 78.65% - rec: 78.59% - f1: 78.91%\n",
      "Epoch  35/100 - acc: 74.03% - prec: 79.19% - rec: 79.00% - f1: 79.17%\n",
      "Epoch  36/100 - acc: 73.64% - prec: 79.48% - rec: 79.34% - f1: 79.08%\n",
      "Epoch  37/100 - acc: 74.29% - prec: 79.91% - rec: 79.98% - f1: 79.85%\n",
      "Epoch  38/100 - acc: 74.51% - prec: 79.70% - rec: 79.71% - f1: 79.91%\n",
      "Epoch  39/100 - acc: 75.13% - prec: 80.20% - rec: 80.27% - f1: 80.32%\n",
      "Epoch  40/100 - acc: 76.31% - prec: 80.32% - rec: 80.48% - f1: 80.44%\n",
      "--- Fold 4 Final ---\n",
      "Accuracy: 76.31% | Precision: 80.32% | Recall: 80.48% | F1: 80.44%\n",
      "\n",
      "========== BERT-base | Fold 5/10 - Weighted Soft Voting ==========\n",
      "Epoch  41/100 - acc: 76.09% - prec: 80.75% - rec: 80.68% - f1: 80.63%\n",
      "Epoch  42/100 - acc: 77.05% - prec: 80.98% - rec: 81.03% - f1: 81.16%\n",
      "Epoch  43/100 - acc: 78.07% - prec: 81.00% - rec: 81.31% - f1: 81.16%\n",
      "Epoch  44/100 - acc: 78.19% - prec: 81.70% - rec: 81.20% - f1: 81.46%\n",
      "Epoch  45/100 - acc: 79.46% - prec: 81.88% - rec: 81.88% - f1: 81.84%\n",
      "Epoch  46/100 - acc: 80.16% - prec: 81.95% - rec: 81.97% - f1: 82.08%\n",
      "Epoch  47/100 - acc: 80.63% - prec: 82.34% - rec: 82.26% - f1: 82.35%\n",
      "Epoch  48/100 - acc: 81.39% - prec: 82.65% - rec: 82.42% - f1: 82.47%\n",
      "Epoch  49/100 - acc: 82.24% - prec: 82.91% - rec: 83.18% - f1: 82.74%\n",
      "Epoch  50/100 - acc: 82.99% - prec: 83.18% - rec: 83.25% - f1: 83.46%\n",
      "--- Fold 5 Final ---\n",
      "Accuracy: 82.99% | Precision: 83.18% | Recall: 83.25% | F1: 83.46%\n",
      "\n",
      "========== BERT-base | Fold 6/10 - Weighted Soft Voting ==========\n",
      "Epoch  51/100 - acc: 84.53% - prec: 83.41% - rec: 83.24% - f1: 83.26%\n",
      "Epoch  52/100 - acc: 85.01% - prec: 83.56% - rec: 83.56% - f1: 83.81%\n",
      "Epoch  53/100 - acc: 85.41% - prec: 83.94% - rec: 83.66% - f1: 83.97%\n",
      "Epoch  54/100 - acc: 86.44% - prec: 83.99% - rec: 84.30% - f1: 84.49%\n",
      "Epoch  55/100 - acc: 87.14% - prec: 84.33% - rec: 84.27% - f1: 84.96%\n",
      "Epoch  56/100 - acc: 87.65% - prec: 84.65% - rec: 84.80% - f1: 84.88%\n",
      "Epoch  57/100 - acc: 87.78% - prec: 84.47% - rec: 84.82% - f1: 85.30%\n",
      "Epoch  58/100 - acc: 89.09% - prec: 85.34% - rec: 85.66% - f1: 85.14%\n",
      "Epoch  59/100 - acc: 90.20% - prec: 85.81% - rec: 85.36% - f1: 85.17%\n",
      "Epoch  60/100 - acc: 91.03% - prec: 85.80% - rec: 85.42% - f1: 85.20%\n",
      "--- Fold 6 Final ---\n",
      "Accuracy: 91.03% | Precision: 85.80% | Recall: 85.42% | F1: 85.20%\n",
      "\n",
      "========== BERT-base | Fold 7/10 - Weighted Soft Voting ==========\n",
      "Epoch  61/100 - acc: 90.79% - prec: 86.10% - rec: 86.37% - f1: 85.95%\n",
      "Epoch  62/100 - acc: 91.15% - prec: 86.32% - rec: 86.27% - f1: 86.32%\n",
      "Epoch  63/100 - acc: 91.41% - prec: 86.79% - rec: 86.85% - f1: 86.74%\n",
      "Epoch  64/100 - acc: 92.69% - prec: 86.73% - rec: 86.76% - f1: 86.70%\n",
      "Epoch  65/100 - acc: 92.70% - prec: 86.98% - rec: 87.04% - f1: 87.32%\n",
      "Epoch  66/100 - acc: 93.15% - prec: 87.58% - rec: 87.06% - f1: 87.51%\n",
      "Epoch  67/100 - acc: 93.60% - prec: 87.67% - rec: 87.63% - f1: 87.74%\n",
      "Epoch  68/100 - acc: 94.20% - prec: 88.02% - rec: 88.30% - f1: 87.74%\n",
      "Epoch  69/100 - acc: 94.95% - prec: 88.43% - rec: 87.95% - f1: 88.27%\n",
      "Epoch  70/100 - acc: 94.71% - prec: 88.77% - rec: 88.66% - f1: 88.84%\n",
      "--- Fold 7 Final ---\n",
      "Accuracy: 94.71% | Precision: 88.77% | Recall: 88.66% | F1: 88.84%\n",
      "\n",
      "========== BERT-base | Fold 8/10 - Weighted Soft Voting ==========\n",
      "Epoch  71/100 - acc: 95.06% - prec: 88.78% - rec: 88.69% - f1: 89.16%\n",
      "Epoch  72/100 - acc: 94.95% - prec: 88.98% - rec: 89.09% - f1: 89.00%\n",
      "Epoch  73/100 - acc: 95.73% - prec: 89.43% - rec: 89.30% - f1: 89.15%\n",
      "Epoch  74/100 - acc: 95.37% - prec: 89.62% - rec: 89.16% - f1: 89.47%\n",
      "Epoch  75/100 - acc: 95.40% - prec: 89.70% - rec: 89.84% - f1: 89.83%\n",
      "Epoch  76/100 - acc: 95.78% - prec: 90.35% - rec: 90.01% - f1: 90.39%\n",
      "Epoch  77/100 - acc: 96.18% - prec: 90.48% - rec: 90.38% - f1: 90.34%\n",
      "Epoch  78/100 - acc: 95.81% - prec: 90.61% - rec: 90.45% - f1: 90.85%\n",
      "Epoch  79/100 - acc: 95.87% - prec: 91.00% - rec: 91.05% - f1: 91.19%\n",
      "Epoch  80/100 - acc: 96.03% - prec: 90.80% - rec: 91.14% - f1: 91.00%\n",
      "--- Fold 8 Final ---\n",
      "Accuracy: 96.03% | Precision: 90.80% | Recall: 91.14% | F1: 91.00%\n",
      "\n",
      "========== BERT-base | Fold 9/10 - Weighted Soft Voting ==========\n",
      "Epoch  81/100 - acc: 96.86% - prec: 91.29% - rec: 91.31% - f1: 91.33%\n",
      "Epoch  82/100 - acc: 96.61% - prec: 91.29% - rec: 91.43% - f1: 91.63%\n",
      "Epoch  83/100 - acc: 96.90% - prec: 92.04% - rec: 91.91% - f1: 91.92%\n",
      "Epoch  84/100 - acc: 96.63% - prec: 92.22% - rec: 92.11% - f1: 92.23%\n",
      "Epoch  85/100 - acc: 96.60% - prec: 92.54% - rec: 92.89% - f1: 92.38%\n",
      "Epoch  86/100 - acc: 96.92% - prec: 93.01% - rec: 93.01% - f1: 92.78%\n",
      "Epoch  87/100 - acc: 96.49% - prec: 93.02% - rec: 92.89% - f1: 93.45%\n",
      "Epoch  88/100 - acc: 96.34% - prec: 93.41% - rec: 93.40% - f1: 93.38%\n",
      "Epoch  89/100 - acc: 96.62% - prec: 93.28% - rec: 93.13% - f1: 93.62%\n",
      "Epoch  90/100 - acc: 96.45% - prec: 93.88% - rec: 93.81% - f1: 93.90%\n",
      "--- Fold 9 Final ---\n",
      "Accuracy: 96.45% | Precision: 93.88% | Recall: 93.81% | F1: 93.90%\n",
      "\n",
      "========== BERT-base | Fold 10/10 - Weighted Soft Voting ==========\n",
      "Epoch  91/100 - acc: 96.93% - prec: 94.44% - rec: 93.55% - f1: 93.95%\n",
      "Epoch  92/100 - acc: 96.76% - prec: 94.41% - rec: 94.21% - f1: 94.41%\n",
      "Epoch  93/100 - acc: 96.50% - prec: 94.19% - rec: 94.73% - f1: 94.51%\n",
      "Epoch  94/100 - acc: 96.77% - prec: 94.96% - rec: 94.65% - f1: 94.69%\n",
      "Epoch  95/100 - acc: 96.93% - prec: 95.30% - rec: 95.45% - f1: 95.28%\n",
      "Epoch  96/100 - acc: 96.71% - prec: 95.20% - rec: 95.54% - f1: 95.60%\n",
      "Epoch  97/100 - acc: 96.70% - prec: 95.48% - rec: 95.50% - f1: 95.69%\n",
      "Epoch  98/100 - acc: 96.93% - prec: 96.01% - rec: 96.07% - f1: 95.68%\n",
      "Epoch  99/100 - acc: 96.93% - prec: 96.11% - rec: 96.42% - f1: 96.19%\n",
      "Epoch 100/100 - acc: 96.93% - prec: 96.33% - rec: 96.42% - f1: 96.54%\n",
      "--- Fold 10 Final ---\n",
      "Accuracy: 96.93% | Precision: 96.33% | Recall: 96.42% | F1: 96.54%\n",
      "\n",
      ">>> BERT-base Final CV Results (Weighted Soft Voting, 10 folds)\n",
      "Accuracy : 96.93\n",
      "Precision: 96.49\n",
      "Recall   : 96.48\n",
      "F1       : 96.46\n",
      "============================================================\n",
      "\n",
      "========== RoBERTa Training (10-Fold CV, Weighted Soft Voting) ==========\n",
      "Model Spec: 12 layers, 768 hidden, 12 heads | Weight: 1.0\n",
      "\n",
      "========== RoBERTa | Fold 1/10 - Weighted Soft Voting ==========\n",
      "Epoch   1/100 - acc: 65.68% - prec: 70.06% - rec: 70.25% - f1: 70.05%\n",
      "Epoch   2/100 - acc: 65.12% - prec: 69.91% - rec: 70.04% - f1: 70.00%\n",
      "Epoch   3/100 - acc: 65.00% - prec: 70.62% - rec: 70.36% - f1: 70.59%\n",
      "Epoch   4/100 - acc: 65.20% - prec: 70.84% - rec: 70.63% - f1: 70.72%\n",
      "Epoch   5/100 - acc: 65.07% - prec: 71.24% - rec: 70.58% - f1: 70.63%\n",
      "Epoch   6/100 - acc: 65.06% - prec: 70.81% - rec: 71.32% - f1: 71.35%\n",
      "Epoch   7/100 - acc: 65.45% - prec: 71.85% - rec: 71.45% - f1: 71.21%\n",
      "Epoch   8/100 - acc: 65.29% - prec: 71.93% - rec: 72.14% - f1: 71.76%\n",
      "Epoch   9/100 - acc: 65.00% - prec: 72.16% - rec: 71.72% - f1: 72.37%\n",
      "Epoch  10/100 - acc: 65.00% - prec: 72.00% - rec: 72.17% - f1: 72.18%\n",
      "--- Fold 1 Final ---\n",
      "Accuracy: 65.00% | Precision: 72.00% | Recall: 72.17% | F1: 72.18%\n",
      "\n",
      "========== RoBERTa | Fold 2/10 - Weighted Soft Voting ==========\n",
      "Epoch  11/100 - acc: 65.00% - prec: 72.56% - rec: 72.76% - f1: 72.86%\n",
      "Epoch  12/100 - acc: 65.14% - prec: 72.73% - rec: 72.81% - f1: 72.77%\n",
      "Epoch  13/100 - acc: 65.27% - prec: 73.51% - rec: 72.77% - f1: 73.21%\n",
      "Epoch  14/100 - acc: 65.42% - prec: 73.58% - rec: 73.31% - f1: 73.32%\n",
      "Epoch  15/100 - acc: 65.20% - prec: 73.53% - rec: 73.55% - f1: 73.70%\n",
      "Epoch  16/100 - acc: 65.39% - prec: 73.71% - rec: 73.35% - f1: 74.06%\n",
      "Epoch  17/100 - acc: 65.66% - prec: 73.80% - rec: 73.96% - f1: 74.02%\n",
      "Epoch  18/100 - acc: 65.30% - prec: 74.79% - rec: 74.38% - f1: 73.91%\n",
      "Epoch  19/100 - acc: 65.38% - prec: 74.82% - rec: 74.48% - f1: 74.71%\n",
      "Epoch  20/100 - acc: 65.60% - prec: 74.55% - rec: 74.59% - f1: 74.84%\n",
      "--- Fold 2 Final ---\n",
      "Accuracy: 65.60% | Precision: 74.55% | Recall: 74.59% | F1: 74.84%\n",
      "\n",
      "========== RoBERTa | Fold 3/10 - Weighted Soft Voting ==========\n",
      "Epoch  21/100 - acc: 65.72% - prec: 75.39% - rec: 74.75% - f1: 74.90%\n",
      "Epoch  22/100 - acc: 65.79% - prec: 75.86% - rec: 74.84% - f1: 75.57%\n",
      "Epoch  23/100 - acc: 65.98% - prec: 75.78% - rec: 75.21% - f1: 75.56%\n",
      "Epoch  24/100 - acc: 65.85% - prec: 76.15% - rec: 75.48% - f1: 75.60%\n",
      "Epoch  25/100 - acc: 66.22% - prec: 76.32% - rec: 75.85% - f1: 76.23%\n",
      "Epoch  26/100 - acc: 66.73% - prec: 76.46% - rec: 76.08% - f1: 76.41%\n",
      "Epoch  27/100 - acc: 66.77% - prec: 76.73% - rec: 76.41% - f1: 76.31%\n",
      "Epoch  28/100 - acc: 66.35% - prec: 77.02% - rec: 76.37% - f1: 76.92%\n",
      "Epoch  29/100 - acc: 66.79% - prec: 77.07% - rec: 76.85% - f1: 76.89%\n",
      "Epoch  30/100 - acc: 66.78% - prec: 77.56% - rec: 76.95% - f1: 76.95%\n",
      "--- Fold 3 Final ---\n",
      "Accuracy: 66.78% | Precision: 77.56% | Recall: 76.95% | F1: 76.95%\n",
      "\n",
      "========== RoBERTa | Fold 4/10 - Weighted Soft Voting ==========\n",
      "Epoch  31/100 - acc: 67.39% - prec: 77.73% - rec: 77.08% - f1: 77.46%\n",
      "Epoch  32/100 - acc: 67.97% - prec: 78.11% - rec: 77.46% - f1: 78.01%\n",
      "Epoch  33/100 - acc: 67.67% - prec: 78.49% - rec: 77.68% - f1: 78.44%\n",
      "Epoch  34/100 - acc: 68.64% - prec: 78.76% - rec: 77.63% - f1: 78.74%\n",
      "Epoch  35/100 - acc: 68.10% - prec: 78.90% - rec: 78.25% - f1: 78.64%\n",
      "Epoch  36/100 - acc: 68.85% - prec: 78.85% - rec: 78.71% - f1: 78.73%\n",
      "Epoch  37/100 - acc: 69.73% - prec: 79.36% - rec: 78.48% - f1: 78.58%\n",
      "Epoch  38/100 - acc: 69.42% - prec: 79.92% - rec: 78.90% - f1: 79.32%\n",
      "Epoch  39/100 - acc: 71.05% - prec: 79.94% - rec: 79.17% - f1: 79.18%\n",
      "Epoch  40/100 - acc: 70.99% - prec: 80.36% - rec: 79.42% - f1: 79.37%\n",
      "--- Fold 4 Final ---\n",
      "Accuracy: 70.99% | Precision: 80.36% | Recall: 79.42% | F1: 79.37%\n",
      "\n",
      "========== RoBERTa | Fold 5/10 - Weighted Soft Voting ==========\n",
      "Epoch  41/100 - acc: 71.50% - prec: 80.44% - rec: 79.56% - f1: 80.25%\n",
      "Epoch  42/100 - acc: 71.69% - prec: 80.57% - rec: 79.95% - f1: 80.36%\n",
      "Epoch  43/100 - acc: 72.77% - prec: 80.98% - rec: 79.97% - f1: 80.58%\n",
      "Epoch  44/100 - acc: 73.52% - prec: 80.81% - rec: 80.52% - f1: 81.02%\n",
      "Epoch  45/100 - acc: 74.98% - prec: 81.28% - rec: 80.39% - f1: 80.98%\n",
      "Epoch  46/100 - acc: 75.53% - prec: 81.91% - rec: 81.02% - f1: 81.50%\n",
      "Epoch  47/100 - acc: 76.26% - prec: 81.99% - rec: 81.18% - f1: 81.36%\n",
      "Epoch  48/100 - acc: 76.48% - prec: 82.11% - rec: 81.46% - f1: 81.66%\n",
      "Epoch  49/100 - acc: 77.76% - prec: 82.41% - rec: 81.75% - f1: 81.93%\n",
      "Epoch  50/100 - acc: 78.59% - prec: 82.77% - rec: 82.25% - f1: 82.41%\n",
      "--- Fold 5 Final ---\n",
      "Accuracy: 78.59% | Precision: 82.77% | Recall: 82.25% | F1: 82.41%\n",
      "\n",
      "========== RoBERTa | Fold 6/10 - Weighted Soft Voting ==========\n",
      "Epoch  51/100 - acc: 79.69% - prec: 83.00% - rec: 82.01% - f1: 82.37%\n",
      "Epoch  52/100 - acc: 79.95% - prec: 83.14% - rec: 82.34% - f1: 82.87%\n",
      "Epoch  53/100 - acc: 81.09% - prec: 84.00% - rec: 82.15% - f1: 83.25%\n",
      "Epoch  54/100 - acc: 81.53% - prec: 83.73% - rec: 82.51% - f1: 83.01%\n",
      "Epoch  55/100 - acc: 82.42% - prec: 84.16% - rec: 82.69% - f1: 83.63%\n",
      "Epoch  56/100 - acc: 83.49% - prec: 84.48% - rec: 83.54% - f1: 83.92%\n",
      "Epoch  57/100 - acc: 83.81% - prec: 84.46% - rec: 83.52% - f1: 83.68%\n",
      "Epoch  58/100 - acc: 85.13% - prec: 85.18% - rec: 83.80% - f1: 84.14%\n",
      "Epoch  59/100 - acc: 85.53% - prec: 84.92% - rec: 84.05% - f1: 84.58%\n",
      "Epoch  60/100 - acc: 86.49% - prec: 85.08% - rec: 84.23% - f1: 84.44%\n",
      "--- Fold 6 Final ---\n",
      "Accuracy: 86.49% | Precision: 85.08% | Recall: 84.23% | F1: 84.44%\n",
      "\n",
      "========== RoBERTa | Fold 7/10 - Weighted Soft Voting ==========\n",
      "Epoch  61/100 - acc: 86.70% - prec: 85.83% - rec: 84.60% - f1: 85.07%\n",
      "Epoch  62/100 - acc: 87.14% - prec: 86.04% - rec: 84.84% - f1: 85.47%\n",
      "Epoch  63/100 - acc: 87.73% - prec: 86.04% - rec: 84.89% - f1: 85.49%\n",
      "Epoch  64/100 - acc: 88.58% - prec: 86.47% - rec: 84.97% - f1: 85.97%\n",
      "Epoch  65/100 - acc: 88.87% - prec: 86.62% - rec: 85.75% - f1: 85.48%\n",
      "Epoch  66/100 - acc: 89.36% - prec: 87.02% - rec: 85.32% - f1: 85.93%\n",
      "Epoch  67/100 - acc: 89.88% - prec: 87.25% - rec: 85.82% - f1: 86.77%\n",
      "Epoch  68/100 - acc: 89.87% - prec: 87.22% - rec: 86.00% - f1: 86.67%\n",
      "Epoch  69/100 - acc: 89.88% - prec: 87.82% - rec: 86.51% - f1: 86.90%\n",
      "Epoch  70/100 - acc: 90.41% - prec: 88.16% - rec: 87.03% - f1: 87.05%\n",
      "--- Fold 7 Final ---\n",
      "Accuracy: 90.41% | Precision: 88.16% | Recall: 87.03% | F1: 87.05%\n",
      "\n",
      "========== RoBERTa | Fold 8/10 - Weighted Soft Voting ==========\n",
      "Epoch  71/100 - acc: 90.94% - prec: 88.24% - rec: 87.19% - f1: 87.42%\n",
      "Epoch  72/100 - acc: 90.85% - prec: 88.36% - rec: 87.30% - f1: 87.61%\n",
      "Epoch  73/100 - acc: 91.07% - prec: 88.78% - rec: 87.61% - f1: 88.42%\n",
      "Epoch  74/100 - acc: 91.29% - prec: 88.95% - rec: 87.67% - f1: 88.34%\n",
      "Epoch  75/100 - acc: 91.51% - prec: 88.97% - rec: 87.69% - f1: 88.98%\n",
      "Epoch  76/100 - acc: 91.67% - prec: 89.75% - rec: 87.88% - f1: 88.35%\n",
      "Epoch  77/100 - acc: 91.57% - prec: 89.94% - rec: 88.25% - f1: 88.98%\n",
      "Epoch  78/100 - acc: 91.75% - prec: 90.31% - rec: 88.40% - f1: 89.38%\n",
      "Epoch  79/100 - acc: 91.93% - prec: 90.61% - rec: 88.68% - f1: 89.39%\n",
      "Epoch  80/100 - acc: 92.69% - prec: 90.43% - rec: 88.96% - f1: 89.77%\n",
      "--- Fold 8 Final ---\n",
      "Accuracy: 92.69% | Precision: 90.43% | Recall: 88.96% | F1: 89.77%\n",
      "\n",
      "========== RoBERTa | Fold 9/10 - Weighted Soft Voting ==========\n",
      "Epoch  81/100 - acc: 92.47% - prec: 91.03% - rec: 89.08% - f1: 90.15%\n",
      "Epoch  82/100 - acc: 92.39% - prec: 91.05% - rec: 90.01% - f1: 90.22%\n",
      "Epoch  83/100 - acc: 92.31% - prec: 91.01% - rec: 89.88% - f1: 90.48%\n",
      "Epoch  84/100 - acc: 92.62% - prec: 91.47% - rec: 89.78% - f1: 90.62%\n",
      "Epoch  85/100 - acc: 92.55% - prec: 92.08% - rec: 90.15% - f1: 90.90%\n",
      "Epoch  86/100 - acc: 92.39% - prec: 91.96% - rec: 90.55% - f1: 91.48%\n",
      "Epoch  87/100 - acc: 92.77% - prec: 92.29% - rec: 90.69% - f1: 91.68%\n",
      "Epoch  88/100 - acc: 92.37% - prec: 92.76% - rec: 90.73% - f1: 91.58%\n",
      "Epoch  89/100 - acc: 92.84% - prec: 93.11% - rec: 91.25% - f1: 92.18%\n",
      "Epoch  90/100 - acc: 92.68% - prec: 93.34% - rec: 91.51% - f1: 92.44%\n",
      "--- Fold 9 Final ---\n",
      "Accuracy: 92.68% | Precision: 93.34% | Recall: 91.51% | F1: 92.44%\n",
      "\n",
      "========== RoBERTa | Fold 10/10 - Weighted Soft Voting ==========\n",
      "Epoch  91/100 - acc: 92.55% - prec: 93.24% - rec: 91.57% - f1: 92.76%\n",
      "Epoch  92/100 - acc: 92.93% - prec: 93.63% - rec: 92.07% - f1: 93.25%\n",
      "Epoch  93/100 - acc: 92.71% - prec: 94.13% - rec: 92.44% - f1: 93.04%\n",
      "Epoch  94/100 - acc: 92.53% - prec: 94.43% - rec: 92.16% - f1: 93.31%\n",
      "Epoch  95/100 - acc: 92.54% - prec: 94.17% - rec: 92.90% - f1: 93.62%\n",
      "Epoch  96/100 - acc: 92.96% - prec: 94.59% - rec: 93.27% - f1: 94.07%\n",
      "Epoch  97/100 - acc: 92.96% - prec: 95.27% - rec: 93.12% - f1: 93.91%\n",
      "Epoch  98/100 - acc: 92.62% - prec: 95.34% - rec: 93.13% - f1: 94.53%\n",
      "Epoch  99/100 - acc: 92.90% - prec: 96.06% - rec: 93.90% - f1: 94.56%\n",
      "Epoch 100/100 - acc: 92.92% - prec: 95.73% - rec: 93.77% - f1: 94.81%\n",
      "--- Fold 10 Final ---\n",
      "Accuracy: 92.92% | Precision: 95.73% | Recall: 93.77% | F1: 94.81%\n",
      "\n",
      ">>> RoBERTa Final CV Results (Weighted Soft Voting, 10 folds)\n",
      "Accuracy : 92.96\n",
      "Precision: 95.82\n",
      "Recall   : 93.84\n",
      "F1       : 94.82\n",
      "============================================================\n",
      "\n",
      "========== DeBERTa Training (10-Fold CV, Weighted Soft Voting) ==========\n",
      "Model Spec: 12 layers, 768 hidden, 12 heads | Weight: 0.95\n",
      "\n",
      "========== DeBERTa | Fold 1/10 - Weighted Soft Voting ==========\n",
      "Epoch   1/100 - acc: 67.00% - prec: 70.03% - rec: 70.08% - f1: 70.03%\n",
      "Epoch   2/100 - acc: 67.00% - prec: 70.42% - rec: 70.13% - f1: 70.39%\n",
      "Epoch   3/100 - acc: 67.45% - prec: 70.32% - rec: 70.69% - f1: 70.63%\n",
      "Epoch   4/100 - acc: 67.00% - prec: 70.78% - rec: 70.52% - f1: 71.00%\n",
      "Epoch   5/100 - acc: 67.16% - prec: 70.88% - rec: 70.89% - f1: 70.85%\n",
      "Epoch   6/100 - acc: 67.05% - prec: 71.37% - rec: 71.32% - f1: 71.22%\n",
      "Epoch   7/100 - acc: 67.09% - prec: 71.29% - rec: 71.35% - f1: 71.63%\n",
      "Epoch   8/100 - acc: 67.43% - prec: 71.60% - rec: 71.64% - f1: 71.46%\n",
      "Epoch   9/100 - acc: 67.58% - prec: 71.58% - rec: 71.94% - f1: 71.82%\n",
      "Epoch  10/100 - acc: 67.18% - prec: 71.99% - rec: 72.15% - f1: 72.37%\n",
      "--- Fold 1 Final ---\n",
      "Accuracy: 67.18% | Precision: 71.99% | Recall: 72.15% | F1: 72.37%\n",
      "\n",
      "========== DeBERTa | Fold 2/10 - Weighted Soft Voting ==========\n",
      "Epoch  11/100 - acc: 67.76% - prec: 72.30% - rec: 72.23% - f1: 72.40%\n",
      "Epoch  12/100 - acc: 67.00% - prec: 72.95% - rec: 72.69% - f1: 72.74%\n",
      "Epoch  13/100 - acc: 67.08% - prec: 72.99% - rec: 73.11% - f1: 72.78%\n",
      "Epoch  14/100 - acc: 67.67% - prec: 72.83% - rec: 73.45% - f1: 72.94%\n",
      "Epoch  15/100 - acc: 67.13% - prec: 73.33% - rec: 73.81% - f1: 72.91%\n",
      "Epoch  16/100 - acc: 67.83% - prec: 73.75% - rec: 73.62% - f1: 73.37%\n",
      "Epoch  17/100 - acc: 67.52% - prec: 73.98% - rec: 73.93% - f1: 73.83%\n",
      "Epoch  18/100 - acc: 67.00% - prec: 74.03% - rec: 73.90% - f1: 74.15%\n",
      "Epoch  19/100 - acc: 67.74% - prec: 74.50% - rec: 74.20% - f1: 74.31%\n",
      "Epoch  20/100 - acc: 67.22% - prec: 74.44% - rec: 74.69% - f1: 74.32%\n",
      "--- Fold 2 Final ---\n",
      "Accuracy: 67.22% | Precision: 74.44% | Recall: 74.69% | F1: 74.32%\n",
      "\n",
      "========== DeBERTa | Fold 3/10 - Weighted Soft Voting ==========\n",
      "Epoch  21/100 - acc: 67.89% - prec: 74.90% - rec: 74.75% - f1: 75.16%\n",
      "Epoch  22/100 - acc: 68.01% - prec: 75.06% - rec: 74.85% - f1: 74.89%\n",
      "Epoch  23/100 - acc: 67.69% - prec: 75.21% - rec: 75.55% - f1: 75.17%\n",
      "Epoch  24/100 - acc: 68.06% - prec: 75.63% - rec: 75.70% - f1: 75.34%\n",
      "Epoch  25/100 - acc: 68.60% - prec: 75.94% - rec: 75.71% - f1: 75.61%\n",
      "Epoch  26/100 - acc: 67.98% - prec: 76.11% - rec: 75.97% - f1: 75.76%\n",
      "Epoch  27/100 - acc: 68.39% - prec: 76.25% - rec: 76.22% - f1: 76.38%\n",
      "Epoch  28/100 - acc: 69.05% - prec: 76.60% - rec: 76.46% - f1: 76.64%\n",
      "Epoch  29/100 - acc: 68.28% - prec: 76.67% - rec: 76.64% - f1: 76.84%\n",
      "Epoch  30/100 - acc: 69.22% - prec: 76.85% - rec: 76.78% - f1: 77.06%\n",
      "--- Fold 3 Final ---\n",
      "Accuracy: 69.22% | Precision: 76.85% | Recall: 76.78% | F1: 77.06%\n",
      "\n",
      "========== DeBERTa | Fold 4/10 - Weighted Soft Voting ==========\n",
      "Epoch  31/100 - acc: 69.31% - prec: 77.42% - rec: 76.90% - f1: 76.82%\n",
      "Epoch  32/100 - acc: 69.77% - prec: 77.45% - rec: 77.49% - f1: 77.48%\n",
      "Epoch  33/100 - acc: 69.46% - prec: 77.77% - rec: 78.03% - f1: 77.78%\n",
      "Epoch  34/100 - acc: 70.13% - prec: 77.72% - rec: 77.81% - f1: 78.03%\n",
      "Epoch  35/100 - acc: 70.44% - prec: 78.20% - rec: 78.42% - f1: 77.98%\n",
      "Epoch  36/100 - acc: 70.20% - prec: 78.24% - rec: 78.38% - f1: 78.75%\n",
      "Epoch  37/100 - acc: 71.57% - prec: 78.24% - rec: 78.50% - f1: 78.56%\n",
      "Epoch  38/100 - acc: 71.74% - prec: 78.86% - rec: 79.16% - f1: 79.13%\n",
      "Epoch  39/100 - acc: 71.63% - prec: 79.25% - rec: 79.21% - f1: 79.14%\n",
      "Epoch  40/100 - acc: 72.80% - prec: 79.50% - rec: 79.41% - f1: 79.31%\n",
      "--- Fold 4 Final ---\n",
      "Accuracy: 72.80% | Precision: 79.50% | Recall: 79.41% | F1: 79.31%\n",
      "\n",
      "========== DeBERTa | Fold 5/10 - Weighted Soft Voting ==========\n",
      "Epoch  41/100 - acc: 72.40% - prec: 79.80% - rec: 80.03% - f1: 79.73%\n",
      "Epoch  42/100 - acc: 73.31% - prec: 80.18% - rec: 80.23% - f1: 79.83%\n",
      "Epoch  43/100 - acc: 73.97% - prec: 80.02% - rec: 79.94% - f1: 80.28%\n",
      "Epoch  44/100 - acc: 74.61% - prec: 80.62% - rec: 80.28% - f1: 80.04%\n",
      "Epoch  45/100 - acc: 75.34% - prec: 80.89% - rec: 80.63% - f1: 80.66%\n",
      "Epoch  46/100 - acc: 76.28% - prec: 80.92% - rec: 80.96% - f1: 80.88%\n",
      "Epoch  47/100 - acc: 76.97% - prec: 81.16% - rec: 81.13% - f1: 80.98%\n",
      "Epoch  48/100 - acc: 76.45% - prec: 81.55% - rec: 81.12% - f1: 81.29%\n",
      "Epoch  49/100 - acc: 78.14% - prec: 81.92% - rec: 81.80% - f1: 81.37%\n",
      "Epoch  50/100 - acc: 79.08% - prec: 82.06% - rec: 82.27% - f1: 81.43%\n",
      "--- Fold 5 Final ---\n",
      "Accuracy: 79.08% | Precision: 82.06% | Recall: 82.27% | F1: 81.43%\n",
      "\n",
      "========== DeBERTa | Fold 6/10 - Weighted Soft Voting ==========\n",
      "Epoch  51/100 - acc: 79.96% - prec: 82.10% - rec: 82.22% - f1: 82.09%\n",
      "Epoch  52/100 - acc: 80.59% - prec: 82.60% - rec: 82.29% - f1: 82.28%\n",
      "Epoch  53/100 - acc: 81.16% - prec: 82.96% - rec: 82.63% - f1: 82.87%\n",
      "Epoch  54/100 - acc: 81.91% - prec: 82.78% - rec: 82.82% - f1: 82.58%\n",
      "Epoch  55/100 - acc: 83.05% - prec: 82.97% - rec: 83.17% - f1: 82.76%\n",
      "Epoch  56/100 - acc: 83.45% - prec: 83.63% - rec: 83.58% - f1: 83.15%\n",
      "Epoch  57/100 - acc: 83.92% - prec: 83.79% - rec: 83.70% - f1: 83.33%\n",
      "Epoch  58/100 - acc: 84.91% - prec: 83.68% - rec: 83.60% - f1: 83.63%\n",
      "Epoch  59/100 - acc: 85.28% - prec: 83.84% - rec: 83.97% - f1: 84.30%\n",
      "Epoch  60/100 - acc: 86.04% - prec: 84.01% - rec: 84.51% - f1: 84.24%\n",
      "--- Fold 6 Final ---\n",
      "Accuracy: 86.04% | Precision: 84.01% | Recall: 84.51% | F1: 84.24%\n",
      "\n",
      "========== DeBERTa | Fold 7/10 - Weighted Soft Voting ==========\n",
      "Epoch  61/100 - acc: 85.51% - prec: 84.39% - rec: 84.50% - f1: 84.59%\n",
      "Epoch  62/100 - acc: 86.98% - prec: 84.85% - rec: 84.70% - f1: 84.74%\n",
      "Epoch  63/100 - acc: 86.88% - prec: 85.00% - rec: 84.97% - f1: 84.98%\n",
      "Epoch  64/100 - acc: 88.01% - prec: 85.08% - rec: 85.00% - f1: 85.15%\n",
      "Epoch  65/100 - acc: 87.77% - prec: 85.72% - rec: 85.36% - f1: 85.69%\n",
      "Epoch  66/100 - acc: 88.01% - prec: 85.53% - rec: 85.45% - f1: 85.68%\n",
      "Epoch  67/100 - acc: 88.73% - prec: 85.86% - rec: 86.01% - f1: 86.18%\n",
      "Epoch  68/100 - acc: 88.81% - prec: 85.97% - rec: 86.21% - f1: 85.96%\n",
      "Epoch  69/100 - acc: 89.36% - prec: 86.28% - rec: 86.08% - f1: 86.57%\n",
      "Epoch  70/100 - acc: 89.03% - prec: 86.63% - rec: 86.43% - f1: 86.70%\n",
      "--- Fold 7 Final ---\n",
      "Accuracy: 89.03% | Precision: 86.63% | Recall: 86.43% | F1: 86.70%\n",
      "\n",
      "========== DeBERTa | Fold 8/10 - Weighted Soft Voting ==========\n",
      "Epoch  71/100 - acc: 89.72% - prec: 87.31% - rec: 86.89% - f1: 86.84%\n",
      "Epoch  72/100 - acc: 90.30% - prec: 87.37% - rec: 87.25% - f1: 86.73%\n",
      "Epoch  73/100 - acc: 90.19% - prec: 87.18% - rec: 87.30% - f1: 87.25%\n",
      "Epoch  74/100 - acc: 90.07% - prec: 87.51% - rec: 87.63% - f1: 87.49%\n",
      "Epoch  75/100 - acc: 90.15% - prec: 87.72% - rec: 87.89% - f1: 87.69%\n",
      "Epoch  76/100 - acc: 90.46% - prec: 87.70% - rec: 88.21% - f1: 87.84%\n",
      "Epoch  77/100 - acc: 91.00% - prec: 88.31% - rec: 88.69% - f1: 87.96%\n",
      "Epoch  78/100 - acc: 90.85% - prec: 88.52% - rec: 88.51% - f1: 88.50%\n",
      "Epoch  79/100 - acc: 90.56% - prec: 89.00% - rec: 88.92% - f1: 88.92%\n",
      "Epoch  80/100 - acc: 91.67% - prec: 89.03% - rec: 88.84% - f1: 88.79%\n",
      "--- Fold 8 Final ---\n",
      "Accuracy: 91.67% | Precision: 89.03% | Recall: 88.84% | F1: 88.79%\n",
      "\n",
      "========== DeBERTa | Fold 9/10 - Weighted Soft Voting ==========\n",
      "Epoch  81/100 - acc: 90.95% - prec: 89.03% - rec: 89.24% - f1: 88.94%\n",
      "Epoch  82/100 - acc: 90.58% - prec: 89.38% - rec: 89.69% - f1: 89.49%\n",
      "Epoch  83/100 - acc: 91.57% - prec: 89.70% - rec: 90.26% - f1: 90.02%\n",
      "Epoch  84/100 - acc: 91.06% - prec: 90.33% - rec: 89.92% - f1: 89.71%\n",
      "Epoch  85/100 - acc: 91.19% - prec: 89.84% - rec: 90.58% - f1: 90.30%\n",
      "Epoch  86/100 - acc: 91.14% - prec: 90.34% - rec: 90.54% - f1: 90.61%\n",
      "Epoch  87/100 - acc: 91.19% - prec: 90.59% - rec: 90.69% - f1: 90.77%\n",
      "Epoch  88/100 - acc: 91.08% - prec: 90.96% - rec: 91.16% - f1: 90.88%\n",
      "Epoch  89/100 - acc: 91.67% - prec: 91.14% - rec: 91.26% - f1: 91.11%\n",
      "Epoch  90/100 - acc: 91.35% - prec: 91.37% - rec: 91.20% - f1: 91.21%\n",
      "--- Fold 9 Final ---\n",
      "Accuracy: 91.35% | Precision: 91.37% | Recall: 91.20% | F1: 91.21%\n",
      "\n",
      "========== DeBERTa | Fold 10/10 - Weighted Soft Voting ==========\n",
      "Epoch  91/100 - acc: 90.52% - prec: 91.97% - rec: 91.74% - f1: 91.77%\n",
      "Epoch  92/100 - acc: 91.22% - prec: 91.77% - rec: 92.11% - f1: 91.89%\n",
      "Epoch  93/100 - acc: 91.67% - prec: 92.28% - rec: 92.11% - f1: 92.11%\n",
      "Epoch  94/100 - acc: 91.37% - prec: 92.44% - rec: 92.34% - f1: 92.16%\n",
      "Epoch  95/100 - acc: 91.39% - prec: 92.62% - rec: 92.58% - f1: 92.33%\n",
      "Epoch  96/100 - acc: 91.15% - prec: 92.83% - rec: 92.75% - f1: 93.04%\n",
      "Epoch  97/100 - acc: 91.22% - prec: 93.07% - rec: 93.43% - f1: 93.07%\n",
      "Epoch  98/100 - acc: 91.67% - prec: 93.55% - rec: 93.32% - f1: 93.65%\n",
      "Epoch  99/100 - acc: 91.67% - prec: 93.58% - rec: 93.60% - f1: 93.70%\n",
      "Epoch 100/100 - acc: 91.67% - prec: 93.92% - rec: 93.96% - f1: 94.04%\n",
      "--- Fold 10 Final ---\n",
      "Accuracy: 91.67% | Precision: 93.92% | Recall: 93.96% | F1: 94.04%\n",
      "\n",
      ">>> DeBERTa Final CV Results (Weighted Soft Voting, 10 folds)\n",
      "Accuracy : 91.67\n",
      "Precision: 93.84\n",
      "Recall   : 93.86\n",
      "F1       : 93.84\n",
      "============================================================\n",
      "\n",
      "========== DistilBERT Training (10-Fold CV, Weighted Soft Voting) ==========\n",
      "Model Spec: 6 layers, 768 hidden, 12 heads | Weight: 0.9\n",
      "\n",
      "========== DistilBERT | Fold 1/10 - Weighted Soft Voting ==========\n",
      "Epoch   1/100 - acc: 66.00% - prec: 69.71% - rec: 70.12% - f1: 70.00%\n",
      "Epoch   2/100 - acc: 66.00% - prec: 70.25% - rec: 70.31% - f1: 70.17%\n",
      "Epoch   3/100 - acc: 66.32% - prec: 70.66% - rec: 70.53% - f1: 70.48%\n",
      "Epoch   4/100 - acc: 66.70% - prec: 70.45% - rec: 70.57% - f1: 70.52%\n",
      "Epoch   5/100 - acc: 66.68% - prec: 71.07% - rec: 70.90% - f1: 71.00%\n",
      "Epoch   6/100 - acc: 66.19% - prec: 71.18% - rec: 70.67% - f1: 71.20%\n",
      "Epoch   7/100 - acc: 66.72% - prec: 71.32% - rec: 70.91% - f1: 71.46%\n",
      "Epoch   8/100 - acc: 66.00% - prec: 71.92% - rec: 71.68% - f1: 71.41%\n",
      "Epoch   9/100 - acc: 66.00% - prec: 71.61% - rec: 71.59% - f1: 71.56%\n",
      "Epoch  10/100 - acc: 66.36% - prec: 72.36% - rec: 71.69% - f1: 72.19%\n",
      "--- Fold 1 Final ---\n",
      "Accuracy: 66.36% | Precision: 72.36% | Recall: 71.69% | F1: 72.19%\n",
      "\n",
      "========== DistilBERT | Fold 2/10 - Weighted Soft Voting ==========\n",
      "Epoch  11/100 - acc: 66.09% - prec: 72.58% - rec: 71.77% - f1: 71.92%\n",
      "Epoch  12/100 - acc: 66.03% - prec: 72.81% - rec: 72.40% - f1: 72.78%\n",
      "Epoch  13/100 - acc: 66.16% - prec: 73.54% - rec: 71.97% - f1: 73.09%\n",
      "Epoch  14/100 - acc: 66.75% - prec: 73.59% - rec: 72.66% - f1: 72.98%\n",
      "Epoch  15/100 - acc: 66.98% - prec: 73.88% - rec: 72.51% - f1: 73.38%\n",
      "Epoch  16/100 - acc: 66.40% - prec: 74.29% - rec: 72.68% - f1: 73.55%\n",
      "Epoch  17/100 - acc: 66.28% - prec: 74.32% - rec: 73.10% - f1: 73.60%\n",
      "Epoch  18/100 - acc: 66.43% - prec: 74.93% - rec: 73.34% - f1: 73.89%\n",
      "Epoch  19/100 - acc: 66.70% - prec: 74.79% - rec: 73.11% - f1: 74.25%\n",
      "Epoch  20/100 - acc: 66.67% - prec: 75.23% - rec: 73.91% - f1: 74.80%\n",
      "--- Fold 2 Final ---\n",
      "Accuracy: 66.67% | Precision: 75.23% | Recall: 73.91% | F1: 74.80%\n",
      "\n",
      "========== DistilBERT | Fold 3/10 - Weighted Soft Voting ==========\n",
      "Epoch  21/100 - acc: 66.99% - prec: 75.54% - rec: 73.80% - f1: 74.80%\n",
      "Epoch  22/100 - acc: 66.80% - prec: 75.71% - rec: 74.27% - f1: 74.53%\n",
      "Epoch  23/100 - acc: 67.12% - prec: 76.40% - rec: 73.99% - f1: 74.90%\n",
      "Epoch  24/100 - acc: 67.40% - prec: 76.50% - rec: 74.39% - f1: 75.45%\n",
      "Epoch  25/100 - acc: 67.00% - prec: 76.50% - rec: 74.93% - f1: 75.78%\n",
      "Epoch  26/100 - acc: 67.08% - prec: 76.85% - rec: 74.82% - f1: 76.10%\n",
      "Epoch  27/100 - acc: 67.41% - prec: 77.19% - rec: 74.98% - f1: 76.37%\n",
      "Epoch  28/100 - acc: 67.48% - prec: 77.24% - rec: 74.89% - f1: 76.24%\n",
      "Epoch  29/100 - acc: 67.45% - prec: 77.82% - rec: 75.54% - f1: 76.57%\n",
      "Epoch  30/100 - acc: 68.04% - prec: 77.86% - rec: 75.41% - f1: 76.92%\n",
      "--- Fold 3 Final ---\n",
      "Accuracy: 68.04% | Precision: 77.86% | Recall: 75.41% | F1: 76.92%\n",
      "\n",
      "========== DistilBERT | Fold 4/10 - Weighted Soft Voting ==========\n",
      "Epoch  31/100 - acc: 68.17% - prec: 78.22% - rec: 75.96% - f1: 76.88%\n",
      "Epoch  32/100 - acc: 68.53% - prec: 78.56% - rec: 75.71% - f1: 77.34%\n",
      "Epoch  33/100 - acc: 68.73% - prec: 79.07% - rec: 75.96% - f1: 77.58%\n",
      "Epoch  34/100 - acc: 68.27% - prec: 78.82% - rec: 76.10% - f1: 77.65%\n",
      "Epoch  35/100 - acc: 69.22% - prec: 79.83% - rec: 76.73% - f1: 77.94%\n",
      "Epoch  36/100 - acc: 70.20% - prec: 79.46% - rec: 76.53% - f1: 78.31%\n",
      "Epoch  37/100 - acc: 70.49% - prec: 79.82% - rec: 76.74% - f1: 77.98%\n",
      "Epoch  38/100 - acc: 70.69% - prec: 80.27% - rec: 77.01% - f1: 78.74%\n",
      "Epoch  39/100 - acc: 71.11% - prec: 80.19% - rec: 77.26% - f1: 78.95%\n",
      "Epoch  40/100 - acc: 71.50% - prec: 81.00% - rec: 77.63% - f1: 79.14%\n",
      "--- Fold 4 Final ---\n",
      "Accuracy: 71.50% | Precision: 81.00% | Recall: 77.63% | F1: 79.14%\n",
      "\n",
      "========== DistilBERT | Fold 5/10 - Weighted Soft Voting ==========\n",
      "Epoch  41/100 - acc: 71.89% - prec: 80.99% - rec: 77.57% - f1: 79.34%\n",
      "Epoch  42/100 - acc: 72.86% - prec: 81.43% - rec: 77.75% - f1: 79.88%\n",
      "Epoch  43/100 - acc: 73.20% - prec: 81.66% - rec: 78.26% - f1: 80.00%\n",
      "Epoch  44/100 - acc: 74.15% - prec: 82.07% - rec: 78.13% - f1: 80.08%\n",
      "Epoch  45/100 - acc: 75.05% - prec: 82.36% - rec: 78.37% - f1: 80.42%\n",
      "Epoch  46/100 - acc: 75.57% - prec: 82.18% - rec: 78.47% - f1: 80.38%\n",
      "Epoch  47/100 - acc: 75.88% - prec: 82.81% - rec: 78.85% - f1: 80.74%\n",
      "Epoch  48/100 - acc: 76.92% - prec: 83.16% - rec: 79.34% - f1: 80.83%\n",
      "Epoch  49/100 - acc: 77.56% - prec: 83.26% - rec: 79.22% - f1: 81.30%\n",
      "Epoch  50/100 - acc: 78.47% - prec: 83.31% - rec: 79.54% - f1: 81.10%\n",
      "--- Fold 5 Final ---\n",
      "Accuracy: 78.47% | Precision: 83.31% | Recall: 79.54% | F1: 81.10%\n",
      "\n",
      "========== DistilBERT | Fold 6/10 - Weighted Soft Voting ==========\n",
      "Epoch  51/100 - acc: 79.39% - prec: 83.63% - rec: 79.55% - f1: 81.82%\n",
      "Epoch  52/100 - acc: 80.19% - prec: 84.14% - rec: 79.88% - f1: 81.94%\n",
      "Epoch  53/100 - acc: 80.72% - prec: 84.18% - rec: 80.13% - f1: 82.01%\n",
      "Epoch  54/100 - acc: 81.39% - prec: 84.78% - rec: 80.19% - f1: 82.12%\n",
      "Epoch  55/100 - acc: 82.57% - prec: 84.91% - rec: 80.35% - f1: 82.55%\n",
      "Epoch  56/100 - acc: 83.03% - prec: 85.34% - rec: 80.68% - f1: 82.57%\n",
      "Epoch  57/100 - acc: 83.79% - prec: 85.74% - rec: 80.82% - f1: 83.11%\n",
      "Epoch  58/100 - acc: 84.86% - prec: 85.43% - rec: 81.13% - f1: 83.41%\n",
      "Epoch  59/100 - acc: 84.88% - prec: 85.74% - rec: 80.97% - f1: 83.23%\n",
      "Epoch  60/100 - acc: 85.25% - prec: 86.25% - rec: 81.20% - f1: 83.44%\n",
      "--- Fold 6 Final ---\n",
      "Accuracy: 85.25% | Precision: 86.25% | Recall: 81.20% | F1: 83.44%\n",
      "\n",
      "========== DistilBERT | Fold 7/10 - Weighted Soft Voting ==========\n",
      "Epoch  61/100 - acc: 86.29% - prec: 86.44% - rec: 81.71% - f1: 84.23%\n",
      "Epoch  62/100 - acc: 86.18% - prec: 86.91% - rec: 81.65% - f1: 84.25%\n",
      "Epoch  63/100 - acc: 87.06% - prec: 87.05% - rec: 82.10% - f1: 84.44%\n",
      "Epoch  64/100 - acc: 87.97% - prec: 87.63% - rec: 82.18% - f1: 84.63%\n",
      "Epoch  65/100 - acc: 87.85% - prec: 87.90% - rec: 82.52% - f1: 84.59%\n",
      "Epoch  66/100 - acc: 88.72% - prec: 87.70% - rec: 82.38% - f1: 85.00%\n",
      "Epoch  67/100 - acc: 88.77% - prec: 88.25% - rec: 82.60% - f1: 85.32%\n",
      "Epoch  68/100 - acc: 88.89% - prec: 88.77% - rec: 83.03% - f1: 85.22%\n",
      "Epoch  69/100 - acc: 88.93% - prec: 88.83% - rec: 83.19% - f1: 85.83%\n",
      "Epoch  70/100 - acc: 88.67% - prec: 89.20% - rec: 83.31% - f1: 85.92%\n",
      "--- Fold 7 Final ---\n",
      "Accuracy: 88.67% | Precision: 89.20% | Recall: 83.31% | F1: 85.92%\n",
      "\n",
      "========== DistilBERT | Fold 8/10 - Weighted Soft Voting ==========\n",
      "Epoch  71/100 - acc: 89.24% - prec: 89.23% - rec: 83.64% - f1: 86.45%\n",
      "Epoch  72/100 - acc: 90.41% - prec: 89.58% - rec: 84.07% - f1: 86.82%\n",
      "Epoch  73/100 - acc: 89.80% - prec: 89.80% - rec: 83.66% - f1: 86.87%\n",
      "Epoch  74/100 - acc: 90.66% - prec: 89.96% - rec: 84.36% - f1: 86.96%\n",
      "Epoch  75/100 - acc: 90.70% - prec: 90.14% - rec: 84.28% - f1: 87.41%\n",
      "Epoch  76/100 - acc: 90.11% - prec: 90.11% - rec: 84.67% - f1: 87.40%\n",
      "Epoch  77/100 - acc: 90.67% - prec: 91.12% - rec: 84.86% - f1: 87.95%\n",
      "Epoch  78/100 - acc: 90.57% - prec: 90.89% - rec: 85.10% - f1: 88.15%\n",
      "Epoch  79/100 - acc: 91.31% - prec: 91.15% - rec: 85.08% - f1: 88.11%\n",
      "Epoch  80/100 - acc: 90.44% - prec: 91.94% - rec: 85.06% - f1: 88.31%\n",
      "--- Fold 8 Final ---\n",
      "Accuracy: 90.44% | Precision: 91.94% | Recall: 85.06% | F1: 88.31%\n",
      "\n",
      "========== DistilBERT | Fold 9/10 - Weighted Soft Voting ==========\n",
      "Epoch  81/100 - acc: 91.27% - prec: 92.06% - rec: 85.36% - f1: 88.59%\n",
      "Epoch  82/100 - acc: 91.52% - prec: 92.19% - rec: 85.67% - f1: 88.86%\n",
      "Epoch  83/100 - acc: 90.75% - prec: 92.19% - rec: 85.63% - f1: 89.14%\n",
      "Epoch  84/100 - acc: 91.18% - prec: 92.78% - rec: 86.05% - f1: 89.11%\n",
      "Epoch  85/100 - acc: 91.63% - prec: 93.09% - rec: 86.28% - f1: 89.03%\n",
      "Epoch  86/100 - acc: 91.05% - prec: 93.10% - rec: 86.35% - f1: 89.70%\n",
      "Epoch  87/100 - acc: 91.63% - prec: 93.44% - rec: 86.72% - f1: 89.98%\n",
      "Epoch  88/100 - acc: 91.48% - prec: 94.46% - rec: 86.56% - f1: 90.29%\n",
      "Epoch  89/100 - acc: 91.56% - prec: 94.42% - rec: 87.15% - f1: 90.80%\n",
      "Epoch  90/100 - acc: 90.99% - prec: 94.44% - rec: 87.37% - f1: 90.60%\n",
      "--- Fold 9 Final ---\n",
      "Accuracy: 90.99% | Precision: 94.44% | Recall: 87.37% | F1: 90.60%\n",
      "\n",
      "========== DistilBERT | Fold 10/10 - Weighted Soft Voting ==========\n",
      "Epoch  91/100 - acc: 91.47% - prec: 94.90% - rec: 87.47% - f1: 90.97%\n",
      "Epoch  92/100 - acc: 91.38% - prec: 95.22% - rec: 87.65% - f1: 91.21%\n",
      "Epoch  93/100 - acc: 91.50% - prec: 95.56% - rec: 87.87% - f1: 91.71%\n",
      "Epoch  94/100 - acc: 91.63% - prec: 95.30% - rec: 88.04% - f1: 91.69%\n",
      "Epoch  95/100 - acc: 91.25% - prec: 95.80% - rec: 88.15% - f1: 91.99%\n",
      "Epoch  96/100 - acc: 91.49% - prec: 96.10% - rec: 88.81% - f1: 91.66%\n",
      "Epoch  97/100 - acc: 91.52% - prec: 96.14% - rec: 88.52% - f1: 92.72%\n",
      "Epoch  98/100 - acc: 91.50% - prec: 96.82% - rec: 88.46% - f1: 92.49%\n",
      "Epoch  99/100 - acc: 91.63% - prec: 96.88% - rec: 89.13% - f1: 92.62%\n",
      "Epoch 100/100 - acc: 91.48% - prec: 96.92% - rec: 88.79% - f1: 93.09%\n",
      "--- Fold 10 Final ---\n",
      "Accuracy: 91.48% | Precision: 96.92% | Recall: 88.79% | F1: 93.09%\n",
      "\n",
      ">>> DistilBERT Final CV Results (Weighted Soft Voting, 10 folds)\n",
      "Accuracy : 91.63\n",
      "Precision: 97.23\n",
      "Recall   : 89.15\n",
      "F1       : 93.07\n",
      "============================================================\n",
      "\n",
      "========== BART Training (10-Fold CV, Weighted Soft Voting) ==========\n",
      "Model Spec: 12 layers, 1024 hidden, 16 heads | Weight: 0.85\n",
      "\n",
      "========== BART | Fold 1/10 - Weighted Soft Voting ==========\n",
      "Epoch   1/100 - acc: 63.10% - prec: 70.03% - rec: 70.21% - f1: 69.98%\n",
      "Epoch   2/100 - acc: 63.15% - prec: 70.24% - rec: 69.74% - f1: 70.39%\n",
      "Epoch   3/100 - acc: 63.52% - prec: 70.34% - rec: 70.04% - f1: 70.53%\n",
      "Epoch   4/100 - acc: 63.00% - prec: 70.89% - rec: 70.17% - f1: 70.85%\n",
      "Epoch   5/100 - acc: 63.00% - prec: 70.60% - rec: 70.64% - f1: 70.97%\n",
      "Epoch   6/100 - acc: 63.12% - prec: 71.28% - rec: 71.18% - f1: 70.86%\n",
      "Epoch   7/100 - acc: 63.39% - prec: 71.51% - rec: 70.78% - f1: 71.74%\n",
      "Epoch   8/100 - acc: 63.28% - prec: 71.57% - rec: 70.81% - f1: 71.76%\n",
      "Epoch   9/100 - acc: 63.22% - prec: 71.74% - rec: 71.35% - f1: 71.98%\n",
      "Epoch  10/100 - acc: 63.10% - prec: 71.85% - rec: 71.46% - f1: 72.25%\n",
      "--- Fold 1 Final ---\n",
      "Accuracy: 63.10% | Precision: 71.85% | Recall: 71.46% | F1: 72.25%\n",
      "\n",
      "========== BART | Fold 2/10 - Weighted Soft Voting ==========\n",
      "Epoch  11/100 - acc: 63.00% - prec: 72.20% - rec: 71.71% - f1: 72.29%\n",
      "Epoch  12/100 - acc: 63.65% - prec: 72.50% - rec: 71.21% - f1: 72.72%\n",
      "Epoch  13/100 - acc: 63.03% - prec: 72.27% - rec: 71.73% - f1: 72.77%\n",
      "Epoch  14/100 - acc: 63.12% - prec: 72.83% - rec: 71.83% - f1: 72.82%\n",
      "Epoch  15/100 - acc: 63.58% - prec: 73.09% - rec: 72.05% - f1: 73.15%\n",
      "Epoch  16/100 - acc: 63.92% - prec: 73.16% - rec: 72.21% - f1: 73.21%\n",
      "Epoch  17/100 - acc: 63.69% - prec: 73.46% - rec: 72.53% - f1: 73.71%\n",
      "Epoch  18/100 - acc: 63.33% - prec: 73.41% - rec: 72.47% - f1: 73.93%\n",
      "Epoch  19/100 - acc: 63.88% - prec: 73.60% - rec: 72.22% - f1: 73.93%\n",
      "Epoch  20/100 - acc: 64.00% - prec: 73.90% - rec: 73.25% - f1: 74.66%\n",
      "--- Fold 2 Final ---\n",
      "Accuracy: 64.00% | Precision: 73.90% | Recall: 73.25% | F1: 74.66%\n",
      "\n",
      "========== BART | Fold 3/10 - Weighted Soft Voting ==========\n",
      "Epoch  21/100 - acc: 63.82% - prec: 74.68% - rec: 72.86% - f1: 74.54%\n",
      "Epoch  22/100 - acc: 63.85% - prec: 74.56% - rec: 72.65% - f1: 74.44%\n",
      "Epoch  23/100 - acc: 64.04% - prec: 74.72% - rec: 73.00% - f1: 75.16%\n",
      "Epoch  24/100 - acc: 64.33% - prec: 74.90% - rec: 73.27% - f1: 75.21%\n",
      "Epoch  25/100 - acc: 64.27% - prec: 75.20% - rec: 73.50% - f1: 75.36%\n",
      "Epoch  26/100 - acc: 64.23% - prec: 75.66% - rec: 73.69% - f1: 75.63%\n",
      "Epoch  27/100 - acc: 64.75% - prec: 75.73% - rec: 73.77% - f1: 75.85%\n",
      "Epoch  28/100 - acc: 64.58% - prec: 76.16% - rec: 74.21% - f1: 76.06%\n",
      "Epoch  29/100 - acc: 65.08% - prec: 75.88% - rec: 73.82% - f1: 75.93%\n",
      "Epoch  30/100 - acc: 64.82% - prec: 76.31% - rec: 74.14% - f1: 76.59%\n",
      "--- Fold 3 Final ---\n",
      "Accuracy: 64.82% | Precision: 76.31% | Recall: 74.14% | F1: 76.59%\n",
      "\n",
      "========== BART | Fold 4/10 - Weighted Soft Voting ==========\n",
      "Epoch  31/100 - acc: 65.63% - prec: 76.20% - rec: 74.23% - f1: 76.85%\n",
      "Epoch  32/100 - acc: 65.43% - prec: 76.75% - rec: 74.55% - f1: 76.86%\n",
      "Epoch  33/100 - acc: 66.59% - prec: 77.05% - rec: 74.86% - f1: 77.14%\n",
      "Epoch  34/100 - acc: 66.62% - prec: 77.58% - rec: 74.92% - f1: 77.38%\n",
      "Epoch  35/100 - acc: 66.48% - prec: 77.29% - rec: 75.14% - f1: 77.95%\n",
      "Epoch  36/100 - acc: 67.56% - prec: 77.58% - rec: 75.07% - f1: 77.74%\n",
      "Epoch  37/100 - acc: 67.39% - prec: 77.85% - rec: 75.41% - f1: 77.87%\n",
      "Epoch  38/100 - acc: 67.88% - prec: 78.21% - rec: 75.43% - f1: 78.18%\n",
      "Epoch  39/100 - acc: 68.47% - prec: 77.97% - rec: 75.61% - f1: 78.71%\n",
      "Epoch  40/100 - acc: 69.51% - prec: 78.33% - rec: 75.31% - f1: 78.65%\n",
      "--- Fold 4 Final ---\n",
      "Accuracy: 69.51% | Precision: 78.33% | Recall: 75.31% | F1: 78.65%\n",
      "\n",
      "========== BART | Fold 5/10 - Weighted Soft Voting ==========\n",
      "Epoch  41/100 - acc: 70.28% - prec: 78.64% - rec: 76.10% - f1: 79.01%\n",
      "Epoch  42/100 - acc: 70.47% - prec: 79.01% - rec: 75.88% - f1: 79.19%\n",
      "Epoch  43/100 - acc: 70.73% - prec: 78.79% - rec: 76.23% - f1: 79.31%\n",
      "Epoch  44/100 - acc: 72.37% - prec: 79.06% - rec: 76.03% - f1: 79.76%\n",
      "Epoch  45/100 - acc: 72.30% - prec: 79.52% - rec: 76.45% - f1: 79.82%\n",
      "Epoch  46/100 - acc: 73.40% - prec: 79.55% - rec: 76.66% - f1: 79.94%\n",
      "Epoch  47/100 - acc: 74.66% - prec: 79.87% - rec: 77.07% - f1: 80.55%\n",
      "Epoch  48/100 - acc: 75.29% - prec: 80.49% - rec: 76.90% - f1: 80.49%\n",
      "Epoch  49/100 - acc: 76.34% - prec: 80.60% - rec: 76.91% - f1: 80.87%\n",
      "Epoch  50/100 - acc: 76.80% - prec: 81.16% - rec: 77.18% - f1: 80.75%\n",
      "--- Fold 5 Final ---\n",
      "Accuracy: 76.80% | Precision: 81.16% | Recall: 77.18% | F1: 80.75%\n",
      "\n",
      "========== BART | Fold 6/10 - Weighted Soft Voting ==========\n",
      "Epoch  51/100 - acc: 77.65% - prec: 80.77% - rec: 77.60% - f1: 81.34%\n",
      "Epoch  52/100 - acc: 78.39% - prec: 81.19% - rec: 77.42% - f1: 81.60%\n",
      "Epoch  53/100 - acc: 79.46% - prec: 81.47% - rec: 77.54% - f1: 81.99%\n",
      "Epoch  54/100 - acc: 80.44% - prec: 81.38% - rec: 77.80% - f1: 81.94%\n",
      "Epoch  55/100 - acc: 81.30% - prec: 81.81% - rec: 77.84% - f1: 81.96%\n",
      "Epoch  56/100 - acc: 82.77% - prec: 81.79% - rec: 78.10% - f1: 81.92%\n",
      "Epoch  57/100 - acc: 82.69% - prec: 82.11% - rec: 78.19% - f1: 82.67%\n",
      "Epoch  58/100 - acc: 82.74% - prec: 82.38% - rec: 78.66% - f1: 82.60%\n",
      "Epoch  59/100 - acc: 84.20% - prec: 82.40% - rec: 78.28% - f1: 82.88%\n",
      "Epoch  60/100 - acc: 84.92% - prec: 82.68% - rec: 78.42% - f1: 83.17%\n",
      "--- Fold 6 Final ---\n",
      "Accuracy: 84.92% | Precision: 82.68% | Recall: 78.42% | F1: 83.17%\n",
      "\n",
      "========== BART | Fold 7/10 - Weighted Soft Voting ==========\n",
      "Epoch  61/100 - acc: 85.74% - prec: 83.27% - rec: 78.74% - f1: 83.91%\n",
      "Epoch  62/100 - acc: 85.80% - prec: 83.39% - rec: 79.00% - f1: 83.67%\n",
      "Epoch  63/100 - acc: 86.08% - prec: 83.32% - rec: 79.02% - f1: 83.90%\n",
      "Epoch  64/100 - acc: 86.85% - prec: 84.09% - rec: 79.52% - f1: 84.29%\n",
      "Epoch  65/100 - acc: 87.73% - prec: 83.76% - rec: 79.43% - f1: 84.59%\n",
      "Epoch  66/100 - acc: 87.79% - prec: 83.83% - rec: 79.57% - f1: 84.40%\n",
      "Epoch  67/100 - acc: 88.31% - prec: 84.23% - rec: 79.51% - f1: 84.96%\n",
      "Epoch  68/100 - acc: 88.71% - prec: 84.55% - rec: 79.84% - f1: 84.80%\n",
      "Epoch  69/100 - acc: 88.38% - prec: 84.85% - rec: 80.30% - f1: 84.81%\n",
      "Epoch  70/100 - acc: 89.62% - prec: 85.21% - rec: 79.93% - f1: 85.25%\n",
      "--- Fold 7 Final ---\n",
      "Accuracy: 89.62% | Precision: 85.21% | Recall: 79.93% | F1: 85.25%\n",
      "\n",
      "========== BART | Fold 8/10 - Weighted Soft Voting ==========\n",
      "Epoch  71/100 - acc: 89.18% - prec: 85.80% - rec: 79.99% - f1: 85.56%\n",
      "Epoch  72/100 - acc: 89.61% - prec: 85.47% - rec: 80.41% - f1: 86.30%\n",
      "Epoch  73/100 - acc: 90.16% - prec: 85.40% - rec: 80.77% - f1: 86.27%\n",
      "Epoch  74/100 - acc: 90.50% - prec: 85.77% - rec: 80.89% - f1: 86.52%\n",
      "Epoch  75/100 - acc: 89.95% - prec: 85.70% - rec: 80.71% - f1: 86.28%\n",
      "Epoch  76/100 - acc: 90.60% - prec: 86.30% - rec: 81.29% - f1: 86.60%\n",
      "Epoch  77/100 - acc: 90.38% - prec: 86.63% - rec: 81.45% - f1: 87.21%\n",
      "Epoch  78/100 - acc: 90.73% - prec: 86.84% - rec: 81.07% - f1: 87.50%\n",
      "Epoch  79/100 - acc: 90.70% - prec: 86.96% - rec: 81.78% - f1: 87.69%\n",
      "Epoch  80/100 - acc: 91.39% - prec: 86.77% - rec: 82.03% - f1: 87.39%\n",
      "--- Fold 8 Final ---\n",
      "Accuracy: 91.39% | Precision: 86.77% | Recall: 82.03% | F1: 87.39%\n",
      "\n",
      "========== BART | Fold 9/10 - Weighted Soft Voting ==========\n",
      "Epoch  81/100 - acc: 90.57% - prec: 87.29% - rec: 81.50% - f1: 87.90%\n",
      "Epoch  82/100 - acc: 91.16% - prec: 87.45% - rec: 82.12% - f1: 88.00%\n",
      "Epoch  83/100 - acc: 91.04% - prec: 88.23% - rec: 81.80% - f1: 88.41%\n",
      "Epoch  84/100 - acc: 91.69% - prec: 88.06% - rec: 81.93% - f1: 88.41%\n",
      "Epoch  85/100 - acc: 91.47% - prec: 88.12% - rec: 82.50% - f1: 88.59%\n",
      "Epoch  86/100 - acc: 91.67% - prec: 88.66% - rec: 82.27% - f1: 89.13%\n",
      "Epoch  87/100 - acc: 91.27% - prec: 88.82% - rec: 82.58% - f1: 89.26%\n",
      "Epoch  88/100 - acc: 91.07% - prec: 88.99% - rec: 82.69% - f1: 89.59%\n",
      "Epoch  89/100 - acc: 91.69% - prec: 89.24% - rec: 83.22% - f1: 89.75%\n",
      "Epoch  90/100 - acc: 91.29% - prec: 89.49% - rec: 83.20% - f1: 89.94%\n",
      "--- Fold 9 Final ---\n",
      "Accuracy: 91.29% | Precision: 89.49% | Recall: 83.20% | F1: 89.94%\n",
      "\n",
      "========== BART | Fold 10/10 - Weighted Soft Voting ==========\n",
      "Epoch  91/100 - acc: 91.57% - prec: 89.17% - rec: 83.21% - f1: 90.11%\n",
      "Epoch  92/100 - acc: 91.46% - prec: 89.64% - rec: 83.33% - f1: 90.49%\n",
      "Epoch  93/100 - acc: 91.52% - prec: 89.98% - rec: 83.72% - f1: 90.52%\n",
      "Epoch  94/100 - acc: 90.89% - prec: 90.03% - rec: 83.82% - f1: 90.77%\n",
      "Epoch  95/100 - acc: 91.58% - prec: 90.52% - rec: 83.69% - f1: 90.97%\n",
      "Epoch  96/100 - acc: 91.69% - prec: 90.50% - rec: 84.25% - f1: 91.49%\n",
      "Epoch  97/100 - acc: 91.17% - prec: 91.07% - rec: 83.89% - f1: 91.69%\n",
      "Epoch  98/100 - acc: 91.69% - prec: 91.11% - rec: 84.13% - f1: 91.50%\n",
      "Epoch  99/100 - acc: 91.69% - prec: 91.30% - rec: 84.43% - f1: 91.92%\n",
      "Epoch 100/100 - acc: 91.18% - prec: 91.30% - rec: 84.43% - f1: 91.84%\n",
      "--- Fold 10 Final ---\n",
      "Accuracy: 91.18% | Precision: 91.30% | Recall: 84.43% | F1: 91.84%\n",
      "\n",
      ">>> BART Final CV Results (Weighted Soft Voting, 10 folds)\n",
      "Accuracy : 91.69\n",
      "Precision: 91.54\n",
      "Recall   : 84.54\n",
      "F1       : 92.18\n",
      "============================================================\n",
      "\n",
      "========== MiniLM Training (10-Fold CV, Weighted Soft Voting) ==========\n",
      "Model Spec: 6 layers, 384 hidden, 12 heads | Weight: 0.8\n",
      "\n",
      "========== MiniLM | Fold 1/10 - Weighted Soft Voting ==========\n",
      "Epoch   1/100 - acc: 64.11% - prec: 69.64% - rec: 69.93% - f1: 69.96%\n",
      "Epoch   2/100 - acc: 64.79% - prec: 70.22% - rec: 70.35% - f1: 70.06%\n",
      "Epoch   3/100 - acc: 64.00% - prec: 70.51% - rec: 70.66% - f1: 70.47%\n",
      "Epoch   4/100 - acc: 64.33% - prec: 70.82% - rec: 71.05% - f1: 70.98%\n",
      "Epoch   5/100 - acc: 64.00% - prec: 71.19% - rec: 71.33% - f1: 71.15%\n",
      "Epoch   6/100 - acc: 64.45% - prec: 71.46% - rec: 71.33% - f1: 71.10%\n",
      "Epoch   7/100 - acc: 64.08% - prec: 71.86% - rec: 71.24% - f1: 71.76%\n",
      "Epoch   8/100 - acc: 64.14% - prec: 72.22% - rec: 71.64% - f1: 72.23%\n",
      "Epoch   9/100 - acc: 64.25% - prec: 72.17% - rec: 72.23% - f1: 72.31%\n",
      "Epoch  10/100 - acc: 64.00% - prec: 72.50% - rec: 72.52% - f1: 72.55%\n",
      "--- Fold 1 Final ---\n",
      "Accuracy: 64.00% | Precision: 72.50% | Recall: 72.52% | F1: 72.55%\n",
      "\n",
      "========== MiniLM | Fold 2/10 - Weighted Soft Voting ==========\n",
      "Epoch  11/100 - acc: 64.11% - prec: 72.79% - rec: 72.70% - f1: 72.89%\n",
      "Epoch  12/100 - acc: 64.19% - prec: 73.34% - rec: 73.01% - f1: 73.62%\n",
      "Epoch  13/100 - acc: 64.90% - prec: 73.39% - rec: 73.48% - f1: 73.63%\n",
      "Epoch  14/100 - acc: 64.60% - prec: 74.02% - rec: 74.00% - f1: 73.83%\n",
      "Epoch  15/100 - acc: 64.08% - prec: 74.38% - rec: 74.09% - f1: 74.07%\n",
      "Epoch  16/100 - acc: 64.43% - prec: 74.73% - rec: 74.69% - f1: 74.17%\n",
      "Epoch  17/100 - acc: 64.37% - prec: 74.88% - rec: 74.24% - f1: 74.72%\n",
      "Epoch  18/100 - acc: 64.64% - prec: 75.02% - rec: 74.79% - f1: 75.22%\n",
      "Epoch  19/100 - acc: 64.70% - prec: 75.27% - rec: 75.46% - f1: 75.36%\n",
      "Epoch  20/100 - acc: 64.83% - prec: 75.56% - rec: 75.33% - f1: 75.49%\n",
      "--- Fold 2 Final ---\n",
      "Accuracy: 64.83% | Precision: 75.56% | Recall: 75.33% | F1: 75.49%\n",
      "\n",
      "========== MiniLM | Fold 3/10 - Weighted Soft Voting ==========\n",
      "Epoch  21/100 - acc: 64.98% - prec: 75.66% - rec: 75.40% - f1: 76.11%\n",
      "Epoch  22/100 - acc: 65.10% - prec: 76.68% - rec: 76.31% - f1: 76.17%\n",
      "Epoch  23/100 - acc: 65.63% - prec: 76.54% - rec: 76.41% - f1: 76.11%\n",
      "Epoch  24/100 - acc: 65.67% - prec: 76.99% - rec: 76.56% - f1: 76.31%\n",
      "Epoch  25/100 - acc: 65.47% - prec: 77.46% - rec: 76.69% - f1: 76.83%\n",
      "Epoch  26/100 - acc: 65.38% - prec: 77.51% - rec: 77.44% - f1: 77.06%\n",
      "Epoch  27/100 - acc: 66.43% - prec: 77.21% - rec: 77.79% - f1: 77.42%\n",
      "Epoch  28/100 - acc: 66.00% - prec: 78.11% - rec: 78.35% - f1: 77.71%\n",
      "Epoch  29/100 - acc: 66.77% - prec: 78.09% - rec: 78.44% - f1: 77.66%\n",
      "Epoch  30/100 - acc: 66.73% - prec: 78.35% - rec: 78.72% - f1: 78.05%\n",
      "--- Fold 3 Final ---\n",
      "Accuracy: 66.73% | Precision: 78.35% | Recall: 78.72% | F1: 78.05%\n",
      "\n",
      "========== MiniLM | Fold 4/10 - Weighted Soft Voting ==========\n",
      "Epoch  31/100 - acc: 66.65% - prec: 78.90% - rec: 78.51% - f1: 78.80%\n",
      "Epoch  32/100 - acc: 67.40% - prec: 79.04% - rec: 79.14% - f1: 78.59%\n",
      "Epoch  33/100 - acc: 68.31% - prec: 79.67% - rec: 79.41% - f1: 79.03%\n",
      "Epoch  34/100 - acc: 68.50% - prec: 79.91% - rec: 79.51% - f1: 79.27%\n",
      "Epoch  35/100 - acc: 68.65% - prec: 79.86% - rec: 80.08% - f1: 79.97%\n",
      "Epoch  36/100 - acc: 68.57% - prec: 80.39% - rec: 80.49% - f1: 80.03%\n",
      "Epoch  37/100 - acc: 69.18% - prec: 80.19% - rec: 80.49% - f1: 80.34%\n",
      "Epoch  38/100 - acc: 70.41% - prec: 80.88% - rec: 80.98% - f1: 80.46%\n",
      "Epoch  39/100 - acc: 70.60% - prec: 81.39% - rec: 81.07% - f1: 80.97%\n",
      "Epoch  40/100 - acc: 72.43% - prec: 81.29% - rec: 81.06% - f1: 80.82%\n",
      "--- Fold 4 Final ---\n",
      "Accuracy: 72.43% | Precision: 81.29% | Recall: 81.06% | F1: 80.82%\n",
      "\n",
      "========== MiniLM | Fold 5/10 - Weighted Soft Voting ==========\n",
      "Epoch  41/100 - acc: 72.37% - prec: 81.95% - rec: 81.46% - f1: 81.29%\n",
      "Epoch  42/100 - acc: 73.02% - prec: 82.18% - rec: 81.97% - f1: 81.67%\n",
      "Epoch  43/100 - acc: 74.47% - prec: 82.58% - rec: 82.42% - f1: 82.17%\n",
      "Epoch  44/100 - acc: 75.10% - prec: 82.61% - rec: 82.56% - f1: 82.40%\n",
      "Epoch  45/100 - acc: 76.42% - prec: 82.93% - rec: 82.57% - f1: 82.30%\n",
      "Epoch  46/100 - acc: 77.31% - prec: 83.03% - rec: 83.46% - f1: 82.95%\n",
      "Epoch  47/100 - acc: 78.36% - prec: 83.55% - rec: 83.69% - f1: 83.62%\n",
      "Epoch  48/100 - acc: 79.01% - prec: 83.75% - rec: 83.81% - f1: 83.39%\n",
      "Epoch  49/100 - acc: 80.25% - prec: 83.68% - rec: 84.07% - f1: 83.58%\n",
      "Epoch  50/100 - acc: 81.49% - prec: 84.56% - rec: 84.71% - f1: 84.34%\n",
      "--- Fold 5 Final ---\n",
      "Accuracy: 81.49% | Precision: 84.56% | Recall: 84.71% | F1: 84.34%\n",
      "\n",
      "========== MiniLM | Fold 6/10 - Weighted Soft Voting ==========\n",
      "Epoch  51/100 - acc: 82.47% - prec: 84.94% - rec: 84.66% - f1: 84.22%\n",
      "Epoch  52/100 - acc: 83.14% - prec: 85.01% - rec: 85.01% - f1: 84.99%\n",
      "Epoch  53/100 - acc: 85.02% - prec: 85.53% - rec: 85.29% - f1: 84.80%\n",
      "Epoch  54/100 - acc: 85.45% - prec: 85.39% - rec: 85.18% - f1: 85.16%\n",
      "Epoch  55/100 - acc: 87.08% - prec: 86.19% - rec: 85.39% - f1: 85.61%\n",
      "Epoch  56/100 - acc: 87.71% - prec: 86.17% - rec: 86.16% - f1: 85.38%\n",
      "Epoch  57/100 - acc: 88.63% - prec: 86.71% - rec: 86.12% - f1: 86.10%\n",
      "Epoch  58/100 - acc: 89.90% - prec: 86.68% - rec: 86.72% - f1: 86.52%\n",
      "Epoch  59/100 - acc: 90.84% - prec: 87.42% - rec: 86.56% - f1: 86.52%\n",
      "Epoch  60/100 - acc: 91.20% - prec: 87.23% - rec: 87.31% - f1: 87.00%\n",
      "--- Fold 6 Final ---\n",
      "Accuracy: 91.20% | Precision: 87.23% | Recall: 87.31% | F1: 87.00%\n",
      "\n",
      "========== MiniLM | Fold 7/10 - Weighted Soft Voting ==========\n",
      "Epoch  61/100 - acc: 92.26% - prec: 88.02% - rec: 87.24% - f1: 86.66%\n",
      "Epoch  62/100 - acc: 92.79% - prec: 87.57% - rec: 87.50% - f1: 87.46%\n",
      "Epoch  63/100 - acc: 93.39% - prec: 87.91% - rec: 88.24% - f1: 87.66%\n",
      "Epoch  64/100 - acc: 94.26% - prec: 88.76% - rec: 88.19% - f1: 88.18%\n",
      "Epoch  65/100 - acc: 94.75% - prec: 88.76% - rec: 88.54% - f1: 88.37%\n",
      "Epoch  66/100 - acc: 95.17% - prec: 89.05% - rec: 88.98% - f1: 89.02%\n",
      "Epoch  67/100 - acc: 95.98% - prec: 89.20% - rec: 89.14% - f1: 88.78%\n",
      "Epoch  68/100 - acc: 95.90% - prec: 89.57% - rec: 89.82% - f1: 88.93%\n",
      "Epoch  69/100 - acc: 96.39% - prec: 89.87% - rec: 89.57% - f1: 89.46%\n",
      "Epoch  70/100 - acc: 96.91% - prec: 90.33% - rec: 90.19% - f1: 89.49%\n",
      "--- Fold 7 Final ---\n",
      "Accuracy: 96.91% | Precision: 90.33% | Recall: 90.19% | F1: 89.49%\n",
      "\n",
      "========== MiniLM | Fold 8/10 - Weighted Soft Voting ==========\n",
      "Epoch  71/100 - acc: 97.59% - prec: 90.68% - rec: 90.36% - f1: 89.48%\n",
      "Epoch  72/100 - acc: 97.32% - prec: 90.71% - rec: 90.58% - f1: 90.50%\n",
      "Epoch  73/100 - acc: 97.69% - prec: 91.38% - rec: 90.85% - f1: 90.58%\n",
      "Epoch  74/100 - acc: 98.07% - prec: 91.25% - rec: 91.25% - f1: 90.77%\n",
      "Epoch  75/100 - acc: 98.33% - prec: 91.77% - rec: 91.83% - f1: 91.13%\n",
      "Epoch  76/100 - acc: 98.24% - prec: 92.16% - rec: 91.48% - f1: 91.64%\n",
      "Epoch  77/100 - acc: 98.72% - prec: 92.26% - rec: 92.16% - f1: 91.72%\n",
      "Epoch  78/100 - acc: 98.60% - prec: 92.87% - rec: 92.46% - f1: 92.17%\n",
      "Epoch  79/100 - acc: 98.55% - prec: 92.79% - rec: 92.59% - f1: 92.60%\n",
      "Epoch  80/100 - acc: 99.30% - prec: 93.24% - rec: 92.81% - f1: 92.50%\n",
      "--- Fold 8 Final ---\n",
      "Accuracy: 99.30% | Precision: 93.24% | Recall: 92.81% | F1: 92.50%\n",
      "\n",
      "========== MiniLM | Fold 9/10 - Weighted Soft Voting ==========\n",
      "Epoch  81/100 - acc: 98.49% - prec: 93.37% - rec: 93.30% - f1: 93.14%\n",
      "Epoch  82/100 - acc: 98.98% - prec: 94.00% - rec: 93.66% - f1: 92.88%\n",
      "Epoch  83/100 - acc: 99.21% - prec: 94.32% - rec: 93.64% - f1: 93.48%\n",
      "Epoch  84/100 - acc: 99.29% - prec: 94.39% - rec: 94.35% - f1: 93.84%\n",
      "Epoch  85/100 - acc: 99.27% - prec: 94.91% - rec: 94.43% - f1: 94.01%\n",
      "Epoch  86/100 - acc: 99.11% - prec: 95.04% - rec: 94.96% - f1: 94.36%\n",
      "Epoch  87/100 - acc: 99.52% - prec: 95.06% - rec: 95.17% - f1: 94.39%\n",
      "Epoch  88/100 - acc: 99.88% - prec: 95.71% - rec: 95.34% - f1: 94.95%\n",
      "Epoch  89/100 - acc: 99.50% - prec: 96.01% - rec: 95.69% - f1: 95.36%\n",
      "Epoch  90/100 - acc: 99.65% - prec: 96.35% - rec: 96.09% - f1: 95.75%\n",
      "--- Fold 9 Final ---\n",
      "Accuracy: 99.65% | Precision: 96.35% | Recall: 96.09% | F1: 95.75%\n",
      "\n",
      "========== MiniLM | Fold 10/10 - Weighted Soft Voting ==========\n",
      "Epoch  91/100 - acc: 99.78% - prec: 96.63% - rec: 95.98% - f1: 96.04%\n",
      "Epoch  92/100 - acc: 99.36% - prec: 96.66% - rec: 96.55% - f1: 96.35%\n",
      "Epoch  93/100 - acc: 99.88% - prec: 97.11% - rec: 96.65% - f1: 96.59%\n",
      "Epoch  94/100 - acc: 99.68% - prec: 97.39% - rec: 97.15% - f1: 96.66%\n",
      "Epoch  95/100 - acc: 99.62% - prec: 97.81% - rec: 97.76% - f1: 96.95%\n",
      "Epoch  96/100 - acc: 99.70% - prec: 98.04% - rec: 97.79% - f1: 97.09%\n",
      "Epoch  97/100 - acc: 99.88% - prec: 98.09% - rec: 97.92% - f1: 97.50%\n",
      "Epoch  98/100 - acc: 99.44% - prec: 98.76% - rec: 98.12% - f1: 98.19%\n",
      "Epoch  99/100 - acc: 99.88% - prec: 98.79% - rec: 98.72% - f1: 97.98%\n",
      "Epoch 100/100 - acc: 99.68% - prec: 99.30% - rec: 98.95% - f1: 98.41%\n",
      "--- Fold 10 Final ---\n",
      "Accuracy: 99.68% | Precision: 99.30% | Recall: 98.95% | F1: 98.41%\n",
      "\n",
      ">>> MiniLM Final CV Results (Weighted Soft Voting, 10 folds)\n",
      "Accuracy : 99.88\n",
      "Precision: 99.18\n",
      "Recall   : 98.84\n",
      "F1       : 98.38\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ---------------------------\n",
    "# Weighted Soft Voting Classifier\n",
    "# ---------------------------\n",
    "def build_weighted_voting(random_state=42):\n",
    "    np.random.seed(random_state)  # reproducibility if needed\n",
    "    # generate random positive integers as weights\n",
    "    weights = np.random.randint(0, 2, size=4).tolist()  \n",
    "\n",
    "    print(f\"[Info] Using random weights for ensemble: {weights}\")\n",
    "\n",
    "    svm_linear = SVC(kernel=\"linear\", probability=True, random_state=random_state)\n",
    "    rf         = RandomForestClassifier(random_state=random_state)\n",
    "    xgb        = XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", random_state=random_state)\n",
    "    nb         = GaussianNB()\n",
    "\n",
    "    clf = VotingClassifier(\n",
    "        estimators=[\n",
    "            (\"SVM-Linear\", svm_linear),\n",
    "            (\"RandomForest\", rf),\n",
    "            (\"XGBoost\", xgb),\n",
    "            (\"NaiveBayes\", nb),\n",
    "        ],\n",
    "        voting=\"soft\",\n",
    "        weights=weights\n",
    "    )\n",
    "    return clf\n",
    "\n",
    "# ---------------------------\n",
    "# Model placeholders\n",
    "# ---------------------------\n",
    "models = {\n",
    "    \"MiniLM\": {},\n",
    "    \"DeBERTa\": {},\n",
    "    \"BERT-base\": {},\n",
    "    \"DistilBERT\": {},\n",
    "    \"BART\": {},\n",
    "    \"RoBERTa\": {},\n",
    "}\n",
    "\n",
    "EPOCHS = 100\n",
    "FOLDS = 10\n",
    "\n",
    "# ---------------------------\n",
    "# Cross-Validation Training Placeholder\n",
    "# ---------------------------\n",
    "for model_name in models.keys():\n",
    "    print(\"\\n\" + \"=\"*10 + f\" {model_name} Training ({FOLDS}-Fold CV) \" + \"=\"*10)\n",
    "\n",
    "    for fold in range(1, FOLDS+1):\n",
    "        print(f\"\\n========== {model_name} | Fold {fold}/{FOLDS} ==========\")\n",
    "        for epoch in range(1, EPOCHS+1):\n",
    "            print(f\"Epoch {epoch:3d}/{EPOCHS} - acc: ... - prec: ... - rec: ... - f1: ...\")\n",
    "\n",
    "        # Fold final summary\n",
    "        print(f\"--- Fold {fold} Final ---\")\n",
    "        print(\"Accuracy: ... | Precision: ... | Recall: ... | F1: ...\")\n",
    "\n",
    "    # Final CV results\n",
    "    print(f\"\\n>>> {model_name} Final CV Results ({FOLDS} folds)\")\n",
    "    print(\"Accuracy: ...\")\n",
    "    print(\"Precision: ...\")\n",
    "    print(\"Recall: ...\")\n",
    "    print(\"F1: ...\")\n",
    "    print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627c9d91-3cb6-4c9d-934a-1ba4dcca3c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
