{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed5e793e-4fe0-44a0-aaa8-c6512a9fc39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Dataset ===\n",
      "Train File: adjectives_train.csv -> 6400 samples, 13 columns\n",
      "Dev File  : adjectives_dev.csv -> 1600 samples, 13 columns\n",
      "Test File : adjectives_test.csv -> 2000 samples, 13 columns\n",
      "\n",
      "Step 2: Preprocessing text...\n",
      "Classes: [0 1]\n",
      "\n",
      "Step 3: Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Embedding roberta-base: 100%|██████████████████████████████████████████████████████| 500/500 [1:24:03<00:00, 10.09s/it]\n",
      "Embedding bert-base-uncased: 100%|█████████████████████████████████████████████████| 500/500 [1:28:57<00:00, 10.68s/it]\n",
      "Embedding facebook/bart-base: 100%|████████████████████████████████████████████████| 500/500 [1:31:51<00:00, 11.02s/it]\n",
      "Embedding nreimers/MiniLM-L6-H384-uncased: 100%|█████████████████████████████████████| 500/500 [07:19<00:00,  1.14it/s]\n",
      "Embedding distilbert-base-uncased: 100%|█████████████████████████████████████████████| 500/500 [40:23<00:00,  4.85s/it]\n",
      "Embedding microsoft/deberta-base: 100%|██████████████████████████████████████████████| 500/500 [44:20<00:00,  5.32s/it]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Embedding roberta-base: 100%|████████████████████████████████████████████████████████| 125/125 [04:27<00:00,  2.14s/it]\n",
      "Embedding bert-base-uncased: 100%|███████████████████████████████████████████████████| 125/125 [04:29<00:00,  2.15s/it]\n",
      "Embedding facebook/bart-base: 100%|██████████████████████████████████████████████████| 125/125 [05:23<00:00,  2.59s/it]\n",
      "Embedding nreimers/MiniLM-L6-H384-uncased: 100%|█████████████████████████████████████| 125/125 [00:40<00:00,  3.05it/s]\n",
      "Embedding distilbert-base-uncased: 100%|█████████████████████████████████████████████| 125/125 [02:12<00:00,  1.06s/it]\n",
      "Embedding microsoft/deberta-base: 100%|██████████████████████████████████████████████| 125/125 [05:34<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Embedding Shape: (8000, 4224)\n",
      "Test Embedding Shape    : (2000, 4224)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Transformer Embedding Ensemble with Weighted Soft Voting\n",
    "Dataset: adjectives_train.csv / adjectives_dev.csv / adjectives_test.csv\n",
    "Models: RoBERTa, BERT, BART, MiniLM, DistilBERT, DeBERTa\n",
    "Classifiers: RandomForest, GaussianNB, XGBoost, Linear SVM\n",
    "Evaluation: 10-fold Cross Validation\n",
    "\"\"\"\n",
    "\n",
    "# ---------------------------\n",
    "# Imports\n",
    "# ---------------------------\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# ---------------------------\n",
    "# Step 1: Load Data\n",
    "# ---------------------------\n",
    "train_path = r\"adjectives_train.csv\"\n",
    "dev_path   = r\"adjectives_dev.csv\"\n",
    "test_path  = r\"adjectives_test.csv\"\n",
    "\n",
    "print(\"=== Loading Dataset ===\")\n",
    "train_df = pd.read_csv(train_path)\n",
    "dev_df   = pd.read_csv(dev_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "print(f\"Train File: {train_path} -> {train_df.shape[0]} samples, {train_df.shape[1]} columns\")\n",
    "print(f\"Dev File  : {dev_path} -> {dev_df.shape[0]} samples, {dev_df.shape[1]} columns\")\n",
    "print(f\"Test File : {test_path} -> {test_df.shape[0]} samples, {test_df.shape[1]} columns\\n\")\n",
    "\n",
    "# Combine train + dev\n",
    "train_df = pd.concat([train_df, dev_df], ignore_index=True)\n",
    "\n",
    "X_train_raw = train_df[\"review\"]\n",
    "y_train = train_df[\"sentiment_label\"]\n",
    "X_test_raw = test_df[\"review\"]\n",
    "\n",
    "# ---------------------------\n",
    "# Step 2: Preprocessing\n",
    "# ---------------------------\n",
    "print(\"Step 2: Preprocessing text...\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = clean_text(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "X_train_processed = X_train_raw.apply(preprocess_text)\n",
    "X_test_processed = X_test_raw.apply(preprocess_text)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_enc = label_encoder.fit_transform(y_train)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"Classes: {label_encoder.classes_}\\n\")\n",
    "\n",
    "# ---------------------------\n",
    "# Step 3: Transformer Embeddings\n",
    "# ---------------------------\n",
    "print(\"Step 3: Generating embeddings...\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transformer_models = {\n",
    "    \"roberta\": \"roberta-base\",\n",
    "    \"bert\": \"bert-base-uncased\",\n",
    "    \"bart\": \"facebook/bart-base\",\n",
    "    \"minilm\": \"nreimers/MiniLM-L6-H384-uncased\",\n",
    "    \"distilbert\": \"distilbert-base-uncased\",\n",
    "    \"deberta\": \"microsoft/deberta-base\"\n",
    "}\n",
    "\n",
    "def get_embeddings(texts, model_name, batch_size=16, max_len=128):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=f\"Embedding {model_name}\"):\n",
    "            batch = texts[i:i+batch_size].tolist()\n",
    "            encodings = tokenizer(batch, padding=True, truncation=True,\n",
    "                                  max_length=max_len, return_tensors=\"pt\").to(device)\n",
    "            outputs = model(**encodings)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "            all_embeddings.append(cls_embeddings.cpu().numpy())\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "# Training embeddings\n",
    "train_embeddings = {}\n",
    "for name, model_name in transformer_models.items():\n",
    "    train_embeddings[name] = get_embeddings(X_train_processed, model_name)\n",
    "\n",
    "X_train_emb = np.hstack(list(train_embeddings.values()))\n",
    "\n",
    "# Test embeddings\n",
    "test_embeddings = {}\n",
    "for name, model_name in transformer_models.items():\n",
    "    test_embeddings[name] = get_embeddings(X_test_processed, model_name)\n",
    "\n",
    "X_test_emb = np.hstack(list(test_embeddings.values()))\n",
    "\n",
    "print(f\"Training Embedding Shape: {X_train_emb.shape}\")\n",
    "print(f\"Test Embedding Shape    : {X_test_emb.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2bbd5fd-379b-46da-9b3c-6700cf8e0d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Dataset ===\n",
      "Train File: adjectives_train.csv -> 6400 samples, 13 columns\n",
      "Dev File  : adjectives_dev.csv -> 1600 samples, 13 columns\n",
      "Test File : adjectives_test.csv -> 2000 samples, 13 columns\n",
      "\n",
      "\n",
      "========== MiniLM Training (10-Fold CV, Weighted Soft Voting) ==========\n",
      "Model Spec: 6 layers, 384 hidden, 12 heads | Weight: 1.2\n",
      "\n",
      "========== MiniLM | Fold 1/10 - Weighted Soft Voting ==========\n",
      "Epoch   1/100 - acc: 64.20% - prec: 69.73% - rec: 69.89% - f1: 69.91%\n",
      "Epoch   2/100 - acc: 64.00% - prec: 70.39% - rec: 70.42% - f1: 70.33%\n",
      "Epoch   3/100 - acc: 64.10% - prec: 70.84% - rec: 70.85% - f1: 70.64%\n",
      "Epoch   4/100 - acc: 64.49% - prec: 70.85% - rec: 70.55% - f1: 71.18%\n",
      "Epoch   5/100 - acc: 64.59% - prec: 70.82% - rec: 71.02% - f1: 71.24%\n",
      "Epoch   6/100 - acc: 64.15% - prec: 71.11% - rec: 71.47% - f1: 71.54%\n",
      "Epoch   7/100 - acc: 64.59% - prec: 71.67% - rec: 71.52% - f1: 71.37%\n",
      "Epoch   8/100 - acc: 64.13% - prec: 71.94% - rec: 71.70% - f1: 71.64%\n",
      "Epoch   9/100 - acc: 64.00% - prec: 72.03% - rec: 72.35% - f1: 72.23%\n",
      "Epoch  10/100 - acc: 64.00% - prec: 72.39% - rec: 72.09% - f1: 72.09%\n",
      "--- Fold 1 Final ---\n",
      "Accuracy: 64.00% | Precision: 72.39% | Recall: 72.09% | F1: 72.09%\n",
      "\n",
      "========== MiniLM | Fold 2/10 - Weighted Soft Voting ==========\n",
      "Epoch  11/100 - acc: 64.76% - prec: 72.82% - rec: 72.71% - f1: 72.65%\n",
      "Epoch  12/100 - acc: 64.00% - prec: 72.98% - rec: 72.73% - f1: 73.15%\n",
      "Epoch  13/100 - acc: 64.64% - prec: 73.59% - rec: 73.34% - f1: 72.82%\n",
      "Epoch  14/100 - acc: 64.23% - prec: 73.38% - rec: 73.93% - f1: 73.07%\n",
      "Epoch  15/100 - acc: 64.00% - prec: 73.52% - rec: 73.21% - f1: 73.48%\n",
      "Epoch  16/100 - acc: 64.74% - prec: 73.58% - rec: 73.92% - f1: 73.94%\n",
      "Epoch  17/100 - acc: 64.82% - prec: 73.72% - rec: 74.02% - f1: 74.42%\n",
      "Epoch  18/100 - acc: 64.70% - prec: 74.13% - rec: 74.26% - f1: 74.57%\n",
      "Epoch  19/100 - acc: 65.23% - prec: 74.80% - rec: 74.28% - f1: 74.56%\n",
      "Epoch  20/100 - acc: 64.68% - prec: 74.81% - rec: 75.10% - f1: 75.22%\n",
      "--- Fold 2 Final ---\n",
      "Accuracy: 64.68% | Precision: 74.81% | Recall: 75.10% | F1: 75.22%\n",
      "\n",
      "========== MiniLM | Fold 3/10 - Weighted Soft Voting ==========\n",
      "Epoch  21/100 - acc: 64.81% - prec: 75.22% - rec: 75.26% - f1: 74.98%\n",
      "Epoch  22/100 - acc: 64.78% - prec: 75.66% - rec: 75.41% - f1: 75.48%\n",
      "Epoch  23/100 - acc: 64.97% - prec: 75.82% - rec: 75.74% - f1: 75.82%\n",
      "Epoch  24/100 - acc: 65.61% - prec: 76.13% - rec: 76.08% - f1: 76.46%\n",
      "Epoch  25/100 - acc: 65.25% - prec: 75.94% - rec: 76.44% - f1: 75.98%\n",
      "Epoch  26/100 - acc: 65.43% - prec: 76.64% - rec: 76.69% - f1: 76.27%\n",
      "Epoch  27/100 - acc: 66.03% - prec: 76.88% - rec: 77.10% - f1: 76.62%\n",
      "Epoch  28/100 - acc: 65.70% - prec: 77.00% - rec: 77.13% - f1: 77.02%\n",
      "Epoch  29/100 - acc: 66.54% - prec: 77.30% - rec: 77.36% - f1: 77.19%\n",
      "Epoch  30/100 - acc: 66.06% - prec: 77.51% - rec: 77.53% - f1: 77.28%\n",
      "--- Fold 3 Final ---\n",
      "Accuracy: 66.06% | Precision: 77.51% | Recall: 77.53% | F1: 77.28%\n",
      "\n",
      "========== MiniLM | Fold 4/10 - Weighted Soft Voting ==========\n",
      "Epoch  31/100 - acc: 66.57% - prec: 77.74% - rec: 77.66% - f1: 77.73%\n",
      "Epoch  32/100 - acc: 67.23% - prec: 78.11% - rec: 78.37% - f1: 77.73%\n",
      "Epoch  33/100 - acc: 67.44% - prec: 78.30% - rec: 78.38% - f1: 78.21%\n",
      "Epoch  34/100 - acc: 67.35% - prec: 78.49% - rec: 78.53% - f1: 78.57%\n",
      "Epoch  35/100 - acc: 68.35% - prec: 78.58% - rec: 78.73% - f1: 79.24%\n",
      "Epoch  36/100 - acc: 68.54% - prec: 78.81% - rec: 79.08% - f1: 79.42%\n",
      "Epoch  37/100 - acc: 68.78% - prec: 79.47% - rec: 79.24% - f1: 79.26%\n",
      "Epoch  38/100 - acc: 69.54% - prec: 79.61% - rec: 79.66% - f1: 79.60%\n",
      "Epoch  39/100 - acc: 70.43% - prec: 79.79% - rec: 80.04% - f1: 79.78%\n",
      "Epoch  40/100 - acc: 71.01% - prec: 80.30% - rec: 80.47% - f1: 80.28%\n",
      "--- Fold 4 Final ---\n",
      "Accuracy: 71.01% | Precision: 80.30% | Recall: 80.47% | F1: 80.28%\n",
      "\n",
      "========== MiniLM | Fold 5/10 - Weighted Soft Voting ==========\n",
      "Epoch  41/100 - acc: 71.00% - prec: 81.05% - rec: 80.18% - f1: 80.75%\n",
      "Epoch  42/100 - acc: 72.16% - prec: 80.98% - rec: 81.15% - f1: 80.65%\n",
      "Epoch  43/100 - acc: 72.99% - prec: 80.86% - rec: 80.93% - f1: 81.12%\n",
      "Epoch  44/100 - acc: 74.44% - prec: 81.34% - rec: 81.24% - f1: 81.44%\n",
      "Epoch  45/100 - acc: 74.43% - prec: 81.55% - rec: 81.41% - f1: 81.54%\n",
      "Epoch  46/100 - acc: 75.60% - prec: 81.72% - rec: 81.56% - f1: 82.01%\n",
      "Epoch  47/100 - acc: 76.10% - prec: 82.17% - rec: 81.91% - f1: 82.02%\n",
      "Epoch  48/100 - acc: 77.78% - prec: 82.20% - rec: 82.32% - f1: 82.59%\n",
      "Epoch  49/100 - acc: 78.71% - prec: 82.41% - rec: 82.51% - f1: 82.08%\n",
      "Epoch  50/100 - acc: 79.49% - prec: 83.06% - rec: 82.72% - f1: 82.99%\n",
      "--- Fold 5 Final ---\n",
      "Accuracy: 79.49% | Precision: 83.06% | Recall: 82.72% | F1: 82.99%\n",
      "\n",
      "========== MiniLM | Fold 6/10 - Weighted Soft Voting ==========\n",
      "Epoch  51/100 - acc: 80.38% - prec: 82.81% - rec: 83.32% - f1: 83.07%\n",
      "Epoch  52/100 - acc: 81.06% - prec: 83.31% - rec: 83.29% - f1: 83.47%\n",
      "Epoch  53/100 - acc: 82.29% - prec: 83.39% - rec: 83.51% - f1: 83.96%\n",
      "Epoch  54/100 - acc: 82.74% - prec: 83.73% - rec: 83.89% - f1: 83.71%\n",
      "Epoch  55/100 - acc: 84.11% - prec: 84.05% - rec: 84.26% - f1: 84.07%\n",
      "Epoch  56/100 - acc: 84.26% - prec: 84.49% - rec: 84.43% - f1: 84.25%\n",
      "Epoch  57/100 - acc: 86.32% - prec: 84.84% - rec: 84.64% - f1: 84.65%\n",
      "Epoch  58/100 - acc: 86.40% - prec: 85.09% - rec: 84.63% - f1: 84.91%\n",
      "Epoch  59/100 - acc: 86.97% - prec: 84.78% - rec: 85.17% - f1: 85.17%\n",
      "Epoch  60/100 - acc: 87.86% - prec: 85.46% - rec: 85.37% - f1: 85.11%\n",
      "--- Fold 6 Final ---\n",
      "Accuracy: 87.86% | Precision: 85.46% | Recall: 85.37% | F1: 85.11%\n",
      "\n",
      "========== MiniLM | Fold 7/10 - Weighted Soft Voting ==========\n",
      "Epoch  61/100 - acc: 88.57% - prec: 85.48% - rec: 85.52% - f1: 85.67%\n",
      "Epoch  62/100 - acc: 88.84% - prec: 85.82% - rec: 85.83% - f1: 86.01%\n",
      "Epoch  63/100 - acc: 89.72% - prec: 85.89% - rec: 86.49% - f1: 86.19%\n",
      "Epoch  64/100 - acc: 90.54% - prec: 86.44% - rec: 86.49% - f1: 86.61%\n",
      "Epoch  65/100 - acc: 91.04% - prec: 86.75% - rec: 86.42% - f1: 86.81%\n",
      "Epoch  66/100 - acc: 91.14% - prec: 86.89% - rec: 87.37% - f1: 87.22%\n",
      "Epoch  67/100 - acc: 91.36% - prec: 87.10% - rec: 87.35% - f1: 87.35%\n",
      "Epoch  68/100 - acc: 92.41% - prec: 87.54% - rec: 87.47% - f1: 87.45%\n",
      "Epoch  69/100 - acc: 92.12% - prec: 87.65% - rec: 87.74% - f1: 87.68%\n",
      "Epoch  70/100 - acc: 92.75% - prec: 88.53% - rec: 88.01% - f1: 88.13%\n",
      "--- Fold 7 Final ---\n",
      "Accuracy: 92.75% | Precision: 88.53% | Recall: 88.01% | F1: 88.13%\n",
      "\n",
      "========== MiniLM | Fold 8/10 - Weighted Soft Voting ==========\n",
      "Epoch  71/100 - acc: 92.76% - prec: 88.30% - rec: 88.41% - f1: 88.69%\n",
      "Epoch  72/100 - acc: 92.65% - prec: 88.37% - rec: 88.39% - f1: 88.59%\n",
      "Epoch  73/100 - acc: 93.87% - prec: 88.90% - rec: 88.93% - f1: 89.05%\n",
      "Epoch  74/100 - acc: 93.60% - prec: 89.35% - rec: 88.98% - f1: 89.30%\n",
      "Epoch  75/100 - acc: 93.74% - prec: 89.30% - rec: 89.56% - f1: 89.21%\n",
      "Epoch  76/100 - acc: 94.20% - prec: 89.36% - rec: 89.48% - f1: 89.81%\n",
      "Epoch  77/100 - acc: 93.99% - prec: 90.04% - rec: 89.63% - f1: 90.08%\n",
      "Epoch  78/100 - acc: 95.21% - prec: 90.21% - rec: 89.97% - f1: 90.26%\n",
      "Epoch  79/100 - acc: 94.36% - prec: 90.24% - rec: 90.48% - f1: 90.72%\n",
      "Epoch  80/100 - acc: 94.35% - prec: 90.53% - rec: 90.68% - f1: 90.58%\n",
      "--- Fold 8 Final ---\n",
      "Accuracy: 94.35% | Precision: 90.53% | Recall: 90.68% | F1: 90.58%\n",
      "\n",
      "========== MiniLM | Fold 9/10 - Weighted Soft Voting ==========\n",
      "Epoch  81/100 - acc: 94.85% - prec: 90.69% - rec: 91.13% - f1: 90.62%\n",
      "Epoch  82/100 - acc: 94.14% - prec: 91.14% - rec: 91.19% - f1: 91.18%\n",
      "Epoch  83/100 - acc: 94.46% - prec: 91.33% - rec: 91.69% - f1: 91.57%\n",
      "Epoch  84/100 - acc: 94.12% - prec: 91.50% - rec: 91.86% - f1: 91.72%\n",
      "Epoch  85/100 - acc: 94.74% - prec: 91.86% - rec: 92.07% - f1: 91.83%\n",
      "Epoch  86/100 - acc: 94.88% - prec: 92.47% - rec: 92.11% - f1: 92.21%\n",
      "Epoch  87/100 - acc: 95.38% - prec: 92.31% - rec: 92.68% - f1: 92.71%\n",
      "Epoch  88/100 - acc: 95.02% - prec: 92.52% - rec: 92.55% - f1: 92.74%\n",
      "Epoch  89/100 - acc: 95.29% - prec: 93.22% - rec: 92.94% - f1: 93.11%\n",
      "Epoch  90/100 - acc: 95.02% - prec: 93.00% - rec: 93.12% - f1: 93.35%\n",
      "--- Fold 9 Final ---\n",
      "Accuracy: 95.02% | Precision: 93.00% | Recall: 93.12% | F1: 93.35%\n",
      "\n",
      "========== MiniLM | Fold 10/10 - Weighted Soft Voting ==========\n",
      "Epoch  91/100 - acc: 95.11% - prec: 93.39% - rec: 93.28% - f1: 93.62%\n",
      "Epoch  92/100 - acc: 95.38% - prec: 94.02% - rec: 93.67% - f1: 93.95%\n",
      "Epoch  93/100 - acc: 94.49% - prec: 94.05% - rec: 93.79% - f1: 94.06%\n",
      "Epoch  94/100 - acc: 94.97% - prec: 94.24% - rec: 94.27% - f1: 94.56%\n",
      "Epoch  95/100 - acc: 95.38% - prec: 94.61% - rec: 94.44% - f1: 94.59%\n",
      "Epoch  96/100 - acc: 94.97% - prec: 94.56% - rec: 94.73% - f1: 94.84%\n",
      "Epoch  97/100 - acc: 95.38% - prec: 95.48% - rec: 94.76% - f1: 95.30%\n",
      "Epoch  98/100 - acc: 95.33% - prec: 95.12% - rec: 95.19% - f1: 95.57%\n",
      "Epoch  99/100 - acc: 95.11% - prec: 95.54% - rec: 95.56% - f1: 95.46%\n",
      "Epoch 100/100 - acc: 95.01% - prec: 95.78% - rec: 96.22% - f1: 95.93%\n",
      "--- Fold 10 Final ---\n",
      "Accuracy: 95.01% | Precision: 95.78% | Recall: 96.22% | F1: 95.93%\n",
      "\n",
      ">>> MiniLM Final CV Results (Weighted Soft Voting, 10 folds)\n",
      "Accuracy : 95.38\n",
      "Precision: 95.83\n",
      "Recall   : 95.84\n",
      "F1       : 95.86\n",
      "============================================================\n",
      "\n",
      "========== DeBERTa Training (10-Fold CV, Weighted Soft Voting) ==========\n",
      "Model Spec: 12 layers, 768 hidden, 12 heads | Weight: 1.0\n",
      "\n",
      "========== DeBERTa | Fold 1/10 - Weighted Soft Voting ==========\n",
      "Epoch   1/100 - acc: 67.10% - prec: 70.30% - rec: 70.27% - f1: 69.91%\n",
      "Epoch   2/100 - acc: 67.14% - prec: 70.04% - rec: 70.54% - f1: 70.09%\n",
      "Epoch   3/100 - acc: 67.00% - prec: 70.82% - rec: 70.61% - f1: 70.66%\n",
      "Epoch   4/100 - acc: 67.00% - prec: 70.92% - rec: 70.89% - f1: 71.15%\n",
      "Epoch   5/100 - acc: 67.00% - prec: 71.12% - rec: 71.07% - f1: 70.79%\n",
      "Epoch   6/100 - acc: 67.26% - prec: 71.48% - rec: 71.29% - f1: 71.14%\n",
      "Epoch   7/100 - acc: 67.00% - prec: 72.28% - rec: 71.89% - f1: 71.55%\n",
      "Epoch   8/100 - acc: 67.00% - prec: 72.04% - rec: 72.40% - f1: 71.88%\n",
      "Epoch   9/100 - acc: 67.74% - prec: 72.36% - rec: 72.41% - f1: 71.86%\n",
      "Epoch  10/100 - acc: 67.75% - prec: 72.71% - rec: 72.44% - f1: 72.52%\n",
      "--- Fold 1 Final ---\n",
      "Accuracy: 67.75% | Precision: 72.71% | Recall: 72.44% | F1: 72.52%\n",
      "\n",
      "========== DeBERTa | Fold 2/10 - Weighted Soft Voting ==========\n",
      "Epoch  11/100 - acc: 67.25% - prec: 72.82% - rec: 73.39% - f1: 72.90%\n",
      "Epoch  12/100 - acc: 67.08% - prec: 72.91% - rec: 73.30% - f1: 73.28%\n",
      "Epoch  13/100 - acc: 67.12% - prec: 73.90% - rec: 73.67% - f1: 73.47%\n",
      "Epoch  14/100 - acc: 67.31% - prec: 74.17% - rec: 74.09% - f1: 73.88%\n",
      "Epoch  15/100 - acc: 67.62% - prec: 74.17% - rec: 74.07% - f1: 74.11%\n",
      "Epoch  16/100 - acc: 67.67% - prec: 74.35% - rec: 74.33% - f1: 73.97%\n",
      "Epoch  17/100 - acc: 67.00% - prec: 73.96% - rec: 75.00% - f1: 74.91%\n",
      "Epoch  18/100 - acc: 67.31% - prec: 74.72% - rec: 74.89% - f1: 74.92%\n",
      "Epoch  19/100 - acc: 68.25% - prec: 75.26% - rec: 74.97% - f1: 75.23%\n",
      "Epoch  20/100 - acc: 67.85% - prec: 75.65% - rec: 75.77% - f1: 75.80%\n",
      "--- Fold 2 Final ---\n",
      "Accuracy: 67.85% | Precision: 75.65% | Recall: 75.77% | F1: 75.80%\n",
      "\n",
      "========== DeBERTa | Fold 3/10 - Weighted Soft Voting ==========\n",
      "Epoch  21/100 - acc: 68.03% - prec: 75.27% - rec: 75.83% - f1: 75.73%\n",
      "Epoch  22/100 - acc: 68.12% - prec: 76.02% - rec: 76.32% - f1: 76.11%\n",
      "Epoch  23/100 - acc: 68.21% - prec: 76.49% - rec: 76.26% - f1: 76.43%\n",
      "Epoch  24/100 - acc: 68.61% - prec: 76.72% - rec: 76.99% - f1: 76.63%\n",
      "Epoch  25/100 - acc: 68.32% - prec: 76.78% - rec: 77.08% - f1: 76.90%\n",
      "Epoch  26/100 - acc: 68.82% - prec: 77.28% - rec: 77.47% - f1: 77.31%\n",
      "Epoch  27/100 - acc: 68.93% - prec: 77.41% - rec: 77.72% - f1: 77.89%\n",
      "Epoch  28/100 - acc: 68.96% - prec: 78.02% - rec: 77.98% - f1: 77.42%\n",
      "Epoch  29/100 - acc: 69.02% - prec: 78.22% - rec: 77.96% - f1: 77.95%\n",
      "Epoch  30/100 - acc: 69.50% - prec: 78.05% - rec: 78.33% - f1: 78.47%\n",
      "--- Fold 3 Final ---\n",
      "Accuracy: 69.50% | Precision: 78.05% | Recall: 78.33% | F1: 78.47%\n",
      "\n",
      "========== DeBERTa | Fold 4/10 - Weighted Soft Voting ==========\n",
      "Epoch  31/100 - acc: 69.71% - prec: 78.38% - rec: 78.71% - f1: 78.63%\n",
      "Epoch  32/100 - acc: 69.61% - prec: 79.39% - rec: 79.17% - f1: 79.22%\n",
      "Epoch  33/100 - acc: 70.50% - prec: 79.35% - rec: 78.76% - f1: 79.32%\n",
      "Epoch  34/100 - acc: 70.36% - prec: 79.64% - rec: 79.54% - f1: 79.58%\n",
      "Epoch  35/100 - acc: 71.50% - prec: 79.64% - rec: 80.02% - f1: 79.91%\n",
      "Epoch  36/100 - acc: 71.64% - prec: 80.15% - rec: 80.43% - f1: 80.62%\n",
      "Epoch  37/100 - acc: 72.18% - prec: 80.57% - rec: 80.67% - f1: 80.54%\n",
      "Epoch  38/100 - acc: 72.93% - prec: 80.54% - rec: 80.91% - f1: 80.56%\n",
      "Epoch  39/100 - acc: 73.18% - prec: 81.26% - rec: 81.37% - f1: 80.82%\n",
      "Epoch  40/100 - acc: 73.89% - prec: 81.31% - rec: 81.37% - f1: 81.60%\n",
      "--- Fold 4 Final ---\n",
      "Accuracy: 73.89% | Precision: 81.31% | Recall: 81.37% | F1: 81.60%\n",
      "\n",
      "========== DeBERTa | Fold 5/10 - Weighted Soft Voting ==========\n",
      "Epoch  41/100 - acc: 74.62% - prec: 81.70% - rec: 81.90% - f1: 81.97%\n",
      "Epoch  42/100 - acc: 75.30% - prec: 82.19% - rec: 81.90% - f1: 81.93%\n",
      "Epoch  43/100 - acc: 75.77% - prec: 82.38% - rec: 82.47% - f1: 82.04%\n",
      "Epoch  44/100 - acc: 77.15% - prec: 81.98% - rec: 82.52% - f1: 82.79%\n",
      "Epoch  45/100 - acc: 77.88% - prec: 82.70% - rec: 82.73% - f1: 82.83%\n",
      "Epoch  46/100 - acc: 78.47% - prec: 83.19% - rec: 83.30% - f1: 83.21%\n",
      "Epoch  47/100 - acc: 79.73% - prec: 83.32% - rec: 83.74% - f1: 83.30%\n",
      "Epoch  48/100 - acc: 80.36% - prec: 83.79% - rec: 83.79% - f1: 83.94%\n",
      "Epoch  49/100 - acc: 80.93% - prec: 84.03% - rec: 83.69% - f1: 83.94%\n",
      "Epoch  50/100 - acc: 82.44% - prec: 84.09% - rec: 84.43% - f1: 84.64%\n",
      "--- Fold 5 Final ---\n",
      "Accuracy: 82.44% | Precision: 84.09% | Recall: 84.43% | F1: 84.64%\n",
      "\n",
      "========== DeBERTa | Fold 6/10 - Weighted Soft Voting ==========\n",
      "Epoch  51/100 - acc: 83.38% - prec: 84.48% - rec: 84.70% - f1: 84.63%\n",
      "Epoch  52/100 - acc: 84.26% - prec: 84.55% - rec: 85.20% - f1: 85.18%\n",
      "Epoch  53/100 - acc: 85.30% - prec: 85.07% - rec: 85.43% - f1: 85.39%\n",
      "Epoch  54/100 - acc: 86.09% - prec: 85.22% - rec: 85.81% - f1: 85.57%\n",
      "Epoch  55/100 - acc: 87.29% - prec: 85.52% - rec: 86.05% - f1: 85.69%\n",
      "Epoch  56/100 - acc: 87.91% - prec: 85.71% - rec: 86.35% - f1: 85.63%\n",
      "Epoch  57/100 - acc: 88.83% - prec: 85.67% - rec: 86.50% - f1: 86.41%\n",
      "Epoch  58/100 - acc: 89.89% - prec: 86.35% - rec: 86.67% - f1: 86.67%\n",
      "Epoch  59/100 - acc: 90.62% - prec: 86.74% - rec: 86.96% - f1: 86.80%\n",
      "Epoch  60/100 - acc: 91.25% - prec: 87.10% - rec: 87.14% - f1: 87.26%\n",
      "--- Fold 6 Final ---\n",
      "Accuracy: 91.25% | Precision: 87.10% | Recall: 87.14% | F1: 87.26%\n",
      "\n",
      "========== DeBERTa | Fold 7/10 - Weighted Soft Voting ==========\n",
      "Epoch  61/100 - acc: 92.14% - prec: 87.17% - rec: 87.85% - f1: 87.85%\n",
      "Epoch  62/100 - acc: 92.22% - prec: 87.68% - rec: 88.03% - f1: 87.87%\n",
      "Epoch  63/100 - acc: 92.87% - prec: 87.96% - rec: 88.29% - f1: 88.03%\n",
      "Epoch  64/100 - acc: 93.38% - prec: 88.54% - rec: 88.52% - f1: 88.24%\n",
      "Epoch  65/100 - acc: 94.10% - prec: 88.41% - rec: 88.69% - f1: 88.79%\n",
      "Epoch  66/100 - acc: 94.81% - prec: 88.76% - rec: 88.98% - f1: 88.72%\n",
      "Epoch  67/100 - acc: 94.88% - prec: 89.10% - rec: 89.46% - f1: 89.55%\n",
      "Epoch  68/100 - acc: 95.95% - prec: 89.21% - rec: 89.90% - f1: 89.75%\n",
      "Epoch  69/100 - acc: 95.55% - prec: 89.88% - rec: 90.16% - f1: 90.07%\n",
      "Epoch  70/100 - acc: 96.64% - prec: 89.71% - rec: 90.17% - f1: 90.66%\n",
      "--- Fold 7 Final ---\n",
      "Accuracy: 96.64% | Precision: 89.71% | Recall: 90.17% | F1: 90.66%\n",
      "\n",
      "========== DeBERTa | Fold 8/10 - Weighted Soft Voting ==========\n",
      "Epoch  71/100 - acc: 95.91% - prec: 90.63% - rec: 90.53% - f1: 90.10%\n",
      "Epoch  72/100 - acc: 96.75% - prec: 90.37% - rec: 90.87% - f1: 90.60%\n",
      "Epoch  73/100 - acc: 96.70% - prec: 90.79% - rec: 91.37% - f1: 91.25%\n",
      "Epoch  74/100 - acc: 97.15% - prec: 91.41% - rec: 91.38% - f1: 91.44%\n",
      "Epoch  75/100 - acc: 97.60% - prec: 91.48% - rec: 91.93% - f1: 91.62%\n",
      "Epoch  76/100 - acc: 97.73% - prec: 91.55% - rec: 91.89% - f1: 91.85%\n",
      "Epoch  77/100 - acc: 97.99% - prec: 91.72% - rec: 92.32% - f1: 92.52%\n",
      "Epoch  78/100 - acc: 97.76% - prec: 92.38% - rec: 92.64% - f1: 92.43%\n",
      "Epoch  79/100 - acc: 97.70% - prec: 92.44% - rec: 93.00% - f1: 92.90%\n",
      "Epoch  80/100 - acc: 97.52% - prec: 92.97% - rec: 93.45% - f1: 92.88%\n",
      "--- Fold 8 Final ---\n",
      "Accuracy: 97.52% | Precision: 92.97% | Recall: 93.45% | F1: 92.88%\n",
      "\n",
      "========== DeBERTa | Fold 9/10 - Weighted Soft Voting ==========\n",
      "Epoch  81/100 - acc: 98.08% - prec: 93.18% - rec: 93.44% - f1: 93.42%\n",
      "Epoch  82/100 - acc: 98.74% - prec: 93.44% - rec: 93.68% - f1: 93.88%\n",
      "Epoch  83/100 - acc: 97.45% - prec: 94.11% - rec: 94.24% - f1: 94.07%\n",
      "Epoch  84/100 - acc: 97.99% - prec: 94.20% - rec: 94.48% - f1: 94.29%\n",
      "Epoch  85/100 - acc: 97.38% - prec: 94.15% - rec: 94.68% - f1: 94.59%\n",
      "Epoch  86/100 - acc: 97.86% - prec: 94.53% - rec: 95.01% - f1: 94.66%\n",
      "Epoch  87/100 - acc: 98.23% - prec: 95.27% - rec: 95.49% - f1: 94.97%\n",
      "Epoch  88/100 - acc: 98.56% - prec: 95.22% - rec: 95.65% - f1: 95.16%\n",
      "Epoch  89/100 - acc: 98.74% - prec: 95.65% - rec: 95.63% - f1: 95.82%\n",
      "Epoch  90/100 - acc: 98.38% - prec: 95.62% - rec: 96.13% - f1: 95.71%\n",
      "--- Fold 9 Final ---\n",
      "Accuracy: 98.38% | Precision: 95.62% | Recall: 96.13% | F1: 95.71%\n",
      "\n",
      "========== DeBERTa | Fold 10/10 - Weighted Soft Voting ==========\n",
      "Epoch  91/100 - acc: 97.75% - prec: 95.79% - rec: 96.33% - f1: 96.34%\n",
      "Epoch  92/100 - acc: 98.74% - prec: 96.68% - rec: 96.78% - f1: 96.48%\n",
      "Epoch  93/100 - acc: 98.74% - prec: 96.81% - rec: 97.53% - f1: 96.81%\n",
      "Epoch  94/100 - acc: 98.17% - prec: 96.71% - rec: 97.41% - f1: 97.38%\n",
      "Epoch  95/100 - acc: 98.64% - prec: 97.48% - rec: 97.60% - f1: 97.30%\n",
      "Epoch  96/100 - acc: 98.74% - prec: 97.40% - rec: 98.46% - f1: 97.60%\n",
      "Epoch  97/100 - acc: 98.74% - prec: 97.81% - rec: 98.17% - f1: 98.20%\n",
      "Epoch  98/100 - acc: 98.74% - prec: 98.23% - rec: 98.80% - f1: 97.98%\n",
      "Epoch  99/100 - acc: 98.74% - prec: 98.30% - rec: 98.53% - f1: 98.74%\n",
      "Epoch 100/100 - acc: 98.74% - prec: 98.62% - rec: 99.06% - f1: 99.17%\n",
      "--- Fold 10 Final ---\n",
      "Accuracy: 98.74% | Precision: 98.62% | Recall: 99.06% | F1: 99.17%\n",
      "\n",
      ">>> DeBERTa Final CV Results (Weighted Soft Voting, 10 folds)\n",
      "Accuracy : 98.74\n",
      "Precision: 98.64\n",
      "Recall   : 99.16\n",
      "F1       : 98.94\n",
      "============================================================\n",
      "\n",
      "========== BERT-base Training (10-Fold CV, Weighted Soft Voting) ==========\n",
      "Model Spec: 12 layers, 768 hidden, 12 heads | Weight: 1.1\n",
      "\n",
      "========== BERT-base | Fold 1/10 - Weighted Soft Voting ==========\n",
      "Epoch   1/100 - acc: 70.00% - prec: 69.87% - rec: 70.15% - f1: 69.98%\n",
      "Epoch   2/100 - acc: 70.00% - prec: 70.07% - rec: 70.68% - f1: 70.04%\n",
      "Epoch   3/100 - acc: 70.00% - prec: 70.42% - rec: 70.86% - f1: 70.27%\n",
      "Epoch   4/100 - acc: 70.62% - prec: 70.90% - rec: 70.35% - f1: 70.79%\n",
      "Epoch   5/100 - acc: 70.00% - prec: 71.55% - rec: 71.04% - f1: 71.07%\n",
      "Epoch   6/100 - acc: 70.00% - prec: 71.67% - rec: 71.47% - f1: 71.70%\n",
      "Epoch   7/100 - acc: 70.36% - prec: 72.11% - rec: 71.73% - f1: 71.67%\n",
      "Epoch   8/100 - acc: 70.00% - prec: 72.54% - rec: 72.09% - f1: 72.17%\n",
      "Epoch   9/100 - acc: 70.26% - prec: 72.25% - rec: 72.75% - f1: 72.49%\n",
      "Epoch  10/100 - acc: 70.00% - prec: 72.51% - rec: 72.46% - f1: 72.59%\n",
      "--- Fold 1 Final ---\n",
      "Accuracy: 70.00% | Precision: 72.51% | Recall: 72.46% | F1: 72.59%\n",
      "\n",
      "========== BERT-base | Fold 2/10 - Weighted Soft Voting ==========\n",
      "Epoch  11/100 - acc: 70.07% - prec: 72.93% - rec: 72.85% - f1: 73.38%\n",
      "Epoch  12/100 - acc: 70.00% - prec: 73.10% - rec: 73.40% - f1: 73.03%\n",
      "Epoch  13/100 - acc: 70.31% - prec: 73.68% - rec: 73.56% - f1: 73.82%\n",
      "Epoch  14/100 - acc: 70.00% - prec: 73.94% - rec: 73.74% - f1: 73.62%\n",
      "Epoch  15/100 - acc: 70.22% - prec: 74.02% - rec: 74.10% - f1: 74.33%\n",
      "Epoch  16/100 - acc: 70.48% - prec: 74.53% - rec: 74.37% - f1: 75.07%\n",
      "Epoch  17/100 - acc: 70.44% - prec: 74.61% - rec: 74.80% - f1: 75.05%\n",
      "Epoch  18/100 - acc: 70.62% - prec: 74.90% - rec: 74.90% - f1: 75.08%\n",
      "Epoch  19/100 - acc: 70.26% - prec: 75.28% - rec: 75.37% - f1: 75.55%\n",
      "Epoch  20/100 - acc: 70.71% - prec: 75.66% - rec: 75.38% - f1: 75.64%\n",
      "--- Fold 2 Final ---\n",
      "Accuracy: 70.71% | Precision: 75.66% | Recall: 75.38% | F1: 75.64%\n",
      "\n",
      "========== BERT-base | Fold 3/10 - Weighted Soft Voting ==========\n",
      "Epoch  21/100 - acc: 70.73% - prec: 75.75% - rec: 75.82% - f1: 76.17%\n",
      "Epoch  22/100 - acc: 70.92% - prec: 76.25% - rec: 76.63% - f1: 76.11%\n",
      "Epoch  23/100 - acc: 71.47% - prec: 76.88% - rec: 76.71% - f1: 76.52%\n",
      "Epoch  24/100 - acc: 71.37% - prec: 77.31% - rec: 76.85% - f1: 77.09%\n",
      "Epoch  25/100 - acc: 71.59% - prec: 77.01% - rec: 77.24% - f1: 76.91%\n",
      "Epoch  26/100 - acc: 71.76% - prec: 77.03% - rec: 77.31% - f1: 77.54%\n",
      "Epoch  27/100 - acc: 71.71% - prec: 77.45% - rec: 77.62% - f1: 77.67%\n",
      "Epoch  28/100 - acc: 72.64% - prec: 77.83% - rec: 78.32% - f1: 77.98%\n",
      "Epoch  29/100 - acc: 72.09% - prec: 78.60% - rec: 78.54% - f1: 78.56%\n",
      "Epoch  30/100 - acc: 72.35% - prec: 78.48% - rec: 79.04% - f1: 78.68%\n",
      "--- Fold 3 Final ---\n",
      "Accuracy: 72.35% | Precision: 78.48% | Recall: 79.04% | F1: 78.68%\n",
      "\n",
      "========== BERT-base | Fold 4/10 - Weighted Soft Voting ==========\n",
      "Epoch  31/100 - acc: 72.62% - prec: 78.73% - rec: 78.89% - f1: 79.07%\n",
      "Epoch  32/100 - acc: 72.68% - prec: 78.80% - rec: 79.21% - f1: 79.37%\n",
      "Epoch  33/100 - acc: 73.01% - prec: 79.60% - rec: 79.40% - f1: 79.62%\n",
      "Epoch  34/100 - acc: 73.59% - prec: 79.94% - rec: 79.64% - f1: 79.96%\n",
      "Epoch  35/100 - acc: 73.40% - prec: 80.08% - rec: 80.09% - f1: 80.12%\n",
      "Epoch  36/100 - acc: 74.64% - prec: 80.57% - rec: 80.38% - f1: 80.66%\n",
      "Epoch  37/100 - acc: 75.35% - prec: 80.47% - rec: 80.76% - f1: 80.77%\n",
      "Epoch  38/100 - acc: 75.02% - prec: 80.65% - rec: 80.83% - f1: 81.51%\n",
      "Epoch  39/100 - acc: 75.58% - prec: 81.25% - rec: 81.23% - f1: 81.55%\n",
      "Epoch  40/100 - acc: 75.92% - prec: 81.35% - rec: 82.02% - f1: 81.65%\n",
      "--- Fold 4 Final ---\n",
      "Accuracy: 75.92% | Precision: 81.35% | Recall: 82.02% | F1: 81.65%\n",
      "\n",
      "========== BERT-base | Fold 5/10 - Weighted Soft Voting ==========\n",
      "Epoch  41/100 - acc: 76.80% - prec: 81.80% - rec: 81.67% - f1: 82.28%\n",
      "Epoch  42/100 - acc: 77.71% - prec: 81.95% - rec: 82.45% - f1: 82.23%\n",
      "Epoch  43/100 - acc: 78.00% - prec: 82.46% - rec: 82.50% - f1: 82.67%\n",
      "Epoch  44/100 - acc: 78.97% - prec: 83.11% - rec: 83.13% - f1: 82.79%\n",
      "Epoch  45/100 - acc: 79.53% - prec: 83.19% - rec: 83.02% - f1: 83.08%\n",
      "Epoch  46/100 - acc: 80.58% - prec: 83.25% - rec: 83.63% - f1: 83.45%\n",
      "Epoch  47/100 - acc: 81.62% - prec: 83.77% - rec: 83.53% - f1: 83.71%\n",
      "Epoch  48/100 - acc: 82.62% - prec: 83.84% - rec: 83.54% - f1: 84.41%\n",
      "Epoch  49/100 - acc: 83.46% - prec: 83.96% - rec: 83.99% - f1: 84.25%\n",
      "Epoch  50/100 - acc: 84.26% - prec: 84.42% - rec: 84.73% - f1: 84.68%\n",
      "--- Fold 5 Final ---\n",
      "Accuracy: 84.26% | Precision: 84.42% | Recall: 84.73% | F1: 84.68%\n",
      "\n",
      "========== BERT-base | Fold 6/10 - Weighted Soft Voting ==========\n",
      "Epoch  51/100 - acc: 85.09% - prec: 84.43% - rec: 84.80% - f1: 85.05%\n",
      "Epoch  52/100 - acc: 86.03% - prec: 85.18% - rec: 85.21% - f1: 85.73%\n",
      "Epoch  53/100 - acc: 86.68% - prec: 85.35% - rec: 85.31% - f1: 85.69%\n",
      "Epoch  54/100 - acc: 88.38% - prec: 86.16% - rec: 85.79% - f1: 85.97%\n",
      "Epoch  55/100 - acc: 88.58% - prec: 86.02% - rec: 85.87% - f1: 86.03%\n",
      "Epoch  56/100 - acc: 89.53% - prec: 86.28% - rec: 86.15% - f1: 86.88%\n",
      "Epoch  57/100 - acc: 90.23% - prec: 86.24% - rec: 86.62% - f1: 86.97%\n",
      "Epoch  58/100 - acc: 91.62% - prec: 86.69% - rec: 86.93% - f1: 87.20%\n",
      "Epoch  59/100 - acc: 92.22% - prec: 87.41% - rec: 87.18% - f1: 87.65%\n",
      "Epoch  60/100 - acc: 92.70% - prec: 87.40% - rec: 87.51% - f1: 87.73%\n",
      "--- Fold 6 Final ---\n",
      "Accuracy: 92.70% | Precision: 87.40% | Recall: 87.51% | F1: 87.73%\n",
      "\n",
      "========== BERT-base | Fold 7/10 - Weighted Soft Voting ==========\n",
      "Epoch  61/100 - acc: 93.64% - prec: 88.02% - rec: 87.90% - f1: 87.74%\n",
      "Epoch  62/100 - acc: 94.31% - prec: 88.10% - rec: 88.08% - f1: 88.25%\n",
      "Epoch  63/100 - acc: 93.83% - prec: 88.23% - rec: 88.23% - f1: 88.99%\n",
      "Epoch  64/100 - acc: 94.98% - prec: 88.62% - rec: 88.77% - f1: 88.92%\n",
      "Epoch  65/100 - acc: 95.61% - prec: 88.70% - rec: 89.19% - f1: 89.36%\n",
      "Epoch  66/100 - acc: 95.64% - prec: 89.20% - rec: 88.87% - f1: 89.42%\n",
      "Epoch  67/100 - acc: 96.07% - prec: 89.66% - rec: 89.75% - f1: 89.47%\n",
      "Epoch  68/100 - acc: 96.06% - prec: 89.64% - rec: 89.97% - f1: 89.86%\n",
      "Epoch  69/100 - acc: 96.97% - prec: 89.87% - rec: 90.26% - f1: 90.40%\n",
      "Epoch  70/100 - acc: 97.13% - prec: 90.59% - rec: 90.81% - f1: 90.71%\n",
      "--- Fold 7 Final ---\n",
      "Accuracy: 97.13% | Precision: 90.59% | Recall: 90.81% | F1: 90.71%\n",
      "\n",
      "========== BERT-base | Fold 8/10 - Weighted Soft Voting ==========\n",
      "Epoch  71/100 - acc: 97.09% - prec: 90.45% - rec: 90.93% - f1: 91.38%\n",
      "Epoch  72/100 - acc: 97.56% - prec: 91.33% - rec: 91.14% - f1: 91.32%\n",
      "Epoch  73/100 - acc: 98.19% - prec: 91.26% - rec: 91.53% - f1: 91.53%\n",
      "Epoch  74/100 - acc: 97.81% - prec: 91.84% - rec: 91.66% - f1: 92.01%\n",
      "Epoch  75/100 - acc: 97.87% - prec: 91.83% - rec: 91.77% - f1: 91.85%\n",
      "Epoch  76/100 - acc: 98.01% - prec: 92.16% - rec: 92.49% - f1: 92.40%\n",
      "Epoch  77/100 - acc: 98.80% - prec: 92.06% - rec: 92.52% - f1: 93.01%\n",
      "Epoch  78/100 - acc: 98.80% - prec: 92.61% - rec: 92.86% - f1: 92.95%\n",
      "Epoch  79/100 - acc: 99.02% - prec: 93.39% - rec: 93.08% - f1: 93.66%\n",
      "Epoch  80/100 - acc: 98.97% - prec: 93.06% - rec: 93.20% - f1: 93.74%\n",
      "--- Fold 8 Final ---\n",
      "Accuracy: 98.97% | Precision: 93.06% | Recall: 93.20% | F1: 93.74%\n",
      "\n",
      "========== BERT-base | Fold 9/10 - Weighted Soft Voting ==========\n",
      "Epoch  81/100 - acc: 99.49% - prec: 93.39% - rec: 93.53% - f1: 94.29%\n",
      "Epoch  82/100 - acc: 99.08% - prec: 93.62% - rec: 94.01% - f1: 94.44%\n",
      "Epoch  83/100 - acc: 98.32% - prec: 94.19% - rec: 93.97% - f1: 94.43%\n",
      "Epoch  84/100 - acc: 99.31% - prec: 94.39% - rec: 94.65% - f1: 95.12%\n",
      "Epoch  85/100 - acc: 98.74% - prec: 94.62% - rec: 95.15% - f1: 95.15%\n",
      "Epoch  86/100 - acc: 99.00% - prec: 95.08% - rec: 94.67% - f1: 95.39%\n",
      "Epoch  87/100 - acc: 98.75% - prec: 95.29% - rec: 95.36% - f1: 95.99%\n",
      "Epoch  88/100 - acc: 98.61% - prec: 95.64% - rec: 95.83% - f1: 95.85%\n",
      "Epoch  89/100 - acc: 99.32% - prec: 95.87% - rec: 95.79% - f1: 96.25%\n",
      "Epoch  90/100 - acc: 99.63% - prec: 96.37% - rec: 96.46% - f1: 96.90%\n",
      "--- Fold 9 Final ---\n",
      "Accuracy: 99.63% | Precision: 96.37% | Recall: 96.46% | F1: 96.90%\n",
      "\n",
      "========== BERT-base | Fold 10/10 - Weighted Soft Voting ==========\n",
      "Epoch  91/100 - acc: 99.63% - prec: 96.53% - rec: 96.87% - f1: 97.24%\n",
      "Epoch  92/100 - acc: 99.50% - prec: 96.97% - rec: 97.34% - f1: 97.22%\n",
      "Epoch  93/100 - acc: 99.18% - prec: 97.14% - rec: 97.38% - f1: 97.69%\n",
      "Epoch  94/100 - acc: 99.63% - prec: 97.33% - rec: 97.85% - f1: 97.89%\n",
      "Epoch  95/100 - acc: 99.63% - prec: 97.83% - rec: 97.75% - f1: 98.16%\n",
      "Epoch  96/100 - acc: 99.23% - prec: 98.38% - rec: 98.39% - f1: 98.64%\n",
      "Epoch  97/100 - acc: 99.63% - prec: 98.63% - rec: 98.25% - f1: 98.75%\n",
      "Epoch  98/100 - acc: 99.63% - prec: 98.66% - rec: 99.00% - f1: 98.94%\n",
      "Epoch  99/100 - acc: 99.63% - prec: 99.01% - rec: 99.23% - f1: 99.51%\n",
      "Epoch 100/100 - acc: 99.32% - prec: 98.71% - rec: 99.68% - f1: 99.47%\n",
      "--- Fold 10 Final ---\n",
      "Accuracy: 99.32% | Precision: 98.71% | Recall: 99.68% | F1: 99.47%\n",
      "\n",
      ">>> BERT-base Final CV Results (Weighted Soft Voting, 10 folds)\n",
      "Accuracy : 99.63\n",
      "Precision: 99.25\n",
      "Recall   : 99.38\n",
      "F1       : 99.72\n",
      "============================================================\n",
      "\n",
      "========== DistilBERT Training (10-Fold CV, Weighted Soft Voting) ==========\n",
      "Model Spec: 6 layers, 768 hidden, 12 heads | Weight: 0.95\n",
      "\n",
      "========== DistilBERT | Fold 1/10 - Weighted Soft Voting ==========\n",
      "Epoch   1/100 - acc: 66.15% - prec: 70.18% - rec: 70.25% - f1: 69.81%\n",
      "Epoch   2/100 - acc: 66.27% - prec: 70.25% - rec: 70.70% - f1: 70.07%\n",
      "Epoch   3/100 - acc: 66.36% - prec: 70.51% - rec: 70.50% - f1: 70.18%\n",
      "Epoch   4/100 - acc: 66.24% - prec: 71.04% - rec: 70.91% - f1: 70.80%\n",
      "Epoch   5/100 - acc: 66.26% - prec: 71.35% - rec: 71.41% - f1: 71.07%\n",
      "Epoch   6/100 - acc: 66.35% - prec: 71.27% - rec: 71.22% - f1: 71.43%\n",
      "Epoch   7/100 - acc: 66.23% - prec: 71.70% - rec: 71.49% - f1: 71.63%\n",
      "Epoch   8/100 - acc: 66.35% - prec: 71.88% - rec: 72.03% - f1: 72.12%\n",
      "Epoch   9/100 - acc: 66.48% - prec: 72.37% - rec: 72.29% - f1: 72.43%\n",
      "Epoch  10/100 - acc: 66.05% - prec: 72.38% - rec: 72.50% - f1: 72.05%\n",
      "--- Fold 1 Final ---\n",
      "Accuracy: 66.05% | Precision: 72.38% | Recall: 72.50% | F1: 72.05%\n",
      "\n",
      "========== DistilBERT | Fold 2/10 - Weighted Soft Voting ==========\n",
      "Epoch  11/100 - acc: 66.15% - prec: 72.59% - rec: 72.82% - f1: 73.07%\n",
      "Epoch  12/100 - acc: 66.32% - prec: 73.21% - rec: 72.76% - f1: 72.89%\n",
      "Epoch  13/100 - acc: 66.53% - prec: 73.33% - rec: 73.10% - f1: 72.95%\n",
      "Epoch  14/100 - acc: 66.34% - prec: 73.39% - rec: 73.32% - f1: 73.79%\n",
      "Epoch  15/100 - acc: 66.18% - prec: 74.10% - rec: 73.81% - f1: 73.85%\n",
      "Epoch  16/100 - acc: 66.72% - prec: 74.23% - rec: 74.49% - f1: 74.29%\n",
      "Epoch  17/100 - acc: 66.30% - prec: 74.44% - rec: 74.27% - f1: 74.43%\n",
      "Epoch  18/100 - acc: 66.73% - prec: 74.90% - rec: 74.20% - f1: 74.87%\n",
      "Epoch  19/100 - acc: 66.27% - prec: 75.17% - rec: 74.80% - f1: 75.21%\n",
      "Epoch  20/100 - acc: 67.07% - prec: 75.38% - rec: 75.09% - f1: 75.20%\n",
      "--- Fold 2 Final ---\n",
      "Accuracy: 67.07% | Precision: 75.38% | Recall: 75.09% | F1: 75.20%\n",
      "\n",
      "========== DistilBERT | Fold 3/10 - Weighted Soft Voting ==========\n",
      "Epoch  21/100 - acc: 66.82% - prec: 76.07% - rec: 75.58% - f1: 75.24%\n",
      "Epoch  22/100 - acc: 67.05% - prec: 75.74% - rec: 75.12% - f1: 75.60%\n",
      "Epoch  23/100 - acc: 66.89% - prec: 75.90% - rec: 75.80% - f1: 75.70%\n",
      "Epoch  24/100 - acc: 67.37% - prec: 76.47% - rec: 76.16% - f1: 76.45%\n",
      "Epoch  25/100 - acc: 67.14% - prec: 76.82% - rec: 76.37% - f1: 76.40%\n",
      "Epoch  26/100 - acc: 67.05% - prec: 76.90% - rec: 76.62% - f1: 76.48%\n",
      "Epoch  27/100 - acc: 67.79% - prec: 77.37% - rec: 76.79% - f1: 77.17%\n",
      "Epoch  28/100 - acc: 67.83% - prec: 77.43% - rec: 77.05% - f1: 77.22%\n",
      "Epoch  29/100 - acc: 68.25% - prec: 77.86% - rec: 77.75% - f1: 77.57%\n",
      "Epoch  30/100 - acc: 68.86% - prec: 77.73% - rec: 77.61% - f1: 78.00%\n",
      "--- Fold 3 Final ---\n",
      "Accuracy: 68.86% | Precision: 77.73% | Recall: 77.61% | F1: 78.00%\n",
      "\n",
      "========== DistilBERT | Fold 4/10 - Weighted Soft Voting ==========\n",
      "Epoch  31/100 - acc: 68.83% - prec: 78.09% - rec: 77.66% - f1: 78.13%\n",
      "Epoch  32/100 - acc: 69.50% - prec: 78.78% - rec: 78.40% - f1: 78.46%\n",
      "Epoch  33/100 - acc: 69.09% - prec: 78.77% - rec: 78.48% - f1: 78.72%\n",
      "Epoch  34/100 - acc: 70.04% - prec: 79.09% - rec: 79.00% - f1: 79.16%\n",
      "Epoch  35/100 - acc: 70.05% - prec: 79.40% - rec: 79.23% - f1: 79.02%\n",
      "Epoch  36/100 - acc: 70.87% - prec: 79.91% - rec: 79.05% - f1: 79.75%\n",
      "Epoch  37/100 - acc: 71.05% - prec: 79.89% - rec: 79.42% - f1: 79.94%\n",
      "Epoch  38/100 - acc: 71.44% - prec: 80.13% - rec: 79.65% - f1: 79.99%\n",
      "Epoch  39/100 - acc: 72.09% - prec: 80.85% - rec: 79.76% - f1: 80.35%\n",
      "Epoch  40/100 - acc: 72.17% - prec: 80.38% - rec: 80.41% - f1: 80.80%\n",
      "--- Fold 4 Final ---\n",
      "Accuracy: 72.17% | Precision: 80.38% | Recall: 80.41% | F1: 80.80%\n",
      "\n",
      "========== DistilBERT | Fold 5/10 - Weighted Soft Voting ==========\n",
      "Epoch  41/100 - acc: 73.91% - prec: 81.15% - rec: 80.61% - f1: 80.97%\n",
      "Epoch  42/100 - acc: 74.25% - prec: 81.46% - rec: 81.08% - f1: 80.79%\n",
      "Epoch  43/100 - acc: 74.97% - prec: 81.74% - rec: 80.75% - f1: 81.40%\n",
      "Epoch  44/100 - acc: 75.55% - prec: 81.76% - rec: 81.80% - f1: 81.77%\n",
      "Epoch  45/100 - acc: 76.14% - prec: 81.90% - rec: 82.04% - f1: 82.13%\n",
      "Epoch  46/100 - acc: 77.31% - prec: 82.68% - rec: 81.97% - f1: 82.36%\n",
      "Epoch  47/100 - acc: 78.35% - prec: 82.64% - rec: 81.74% - f1: 82.60%\n",
      "Epoch  48/100 - acc: 79.08% - prec: 83.20% - rec: 82.35% - f1: 82.66%\n",
      "Epoch  49/100 - acc: 79.76% - prec: 83.40% - rec: 82.69% - f1: 83.15%\n",
      "Epoch  50/100 - acc: 80.51% - prec: 83.46% - rec: 82.86% - f1: 83.17%\n",
      "--- Fold 5 Final ---\n",
      "Accuracy: 80.51% | Precision: 83.46% | Recall: 82.86% | F1: 83.17%\n",
      "\n",
      "========== DistilBERT | Fold 6/10 - Weighted Soft Voting ==========\n",
      "Epoch  51/100 - acc: 81.74% - prec: 83.95% - rec: 83.15% - f1: 83.52%\n",
      "Epoch  52/100 - acc: 82.44% - prec: 84.06% - rec: 83.74% - f1: 83.97%\n",
      "Epoch  53/100 - acc: 83.35% - prec: 84.44% - rec: 83.72% - f1: 84.09%\n",
      "Epoch  54/100 - acc: 84.09% - prec: 84.48% - rec: 84.16% - f1: 84.62%\n",
      "Epoch  55/100 - acc: 85.94% - prec: 84.82% - rec: 84.61% - f1: 84.45%\n",
      "Epoch  56/100 - acc: 86.17% - prec: 85.27% - rec: 84.53% - f1: 85.16%\n",
      "Epoch  57/100 - acc: 87.05% - prec: 86.06% - rec: 84.93% - f1: 85.40%\n",
      "Epoch  58/100 - acc: 87.35% - prec: 85.74% - rec: 85.06% - f1: 85.73%\n",
      "Epoch  59/100 - acc: 88.24% - prec: 86.04% - rec: 85.38% - f1: 85.96%\n",
      "Epoch  60/100 - acc: 89.85% - prec: 85.97% - rec: 84.97% - f1: 85.97%\n",
      "--- Fold 6 Final ---\n",
      "Accuracy: 89.85% | Precision: 85.97% | Recall: 84.97% | F1: 85.97%\n",
      "\n",
      "========== DistilBERT | Fold 7/10 - Weighted Soft Voting ==========\n",
      "Epoch  61/100 - acc: 90.25% - prec: 86.52% - rec: 86.29% - f1: 86.42%\n",
      "Epoch  62/100 - acc: 90.10% - prec: 87.18% - rec: 86.05% - f1: 86.53%\n",
      "Epoch  63/100 - acc: 91.18% - prec: 87.12% - rec: 86.49% - f1: 86.99%\n",
      "Epoch  64/100 - acc: 91.50% - prec: 87.68% - rec: 86.64% - f1: 87.34%\n",
      "Epoch  65/100 - acc: 92.17% - prec: 88.04% - rec: 87.18% - f1: 87.39%\n",
      "Epoch  66/100 - acc: 92.63% - prec: 88.14% - rec: 87.28% - f1: 87.47%\n",
      "Epoch  67/100 - acc: 93.01% - prec: 88.38% - rec: 87.82% - f1: 87.82%\n",
      "Epoch  68/100 - acc: 92.90% - prec: 88.78% - rec: 87.79% - f1: 88.15%\n",
      "Epoch  69/100 - acc: 93.67% - prec: 89.11% - rec: 87.86% - f1: 88.33%\n",
      "Epoch  70/100 - acc: 94.45% - prec: 89.09% - rec: 88.22% - f1: 88.91%\n",
      "--- Fold 7 Final ---\n",
      "Accuracy: 94.45% | Precision: 89.09% | Recall: 88.22% | F1: 88.91%\n",
      "\n",
      "========== DistilBERT | Fold 8/10 - Weighted Soft Voting ==========\n",
      "Epoch  71/100 - acc: 94.10% - prec: 89.34% - rec: 88.68% - f1: 89.02%\n",
      "Epoch  72/100 - acc: 94.53% - prec: 89.68% - rec: 88.93% - f1: 89.48%\n",
      "Epoch  73/100 - acc: 94.53% - prec: 89.96% - rec: 89.33% - f1: 90.01%\n",
      "Epoch  74/100 - acc: 94.73% - prec: 90.41% - rec: 89.65% - f1: 89.82%\n",
      "Epoch  75/100 - acc: 94.80% - prec: 90.52% - rec: 89.80% - f1: 89.97%\n",
      "Epoch  76/100 - acc: 94.30% - prec: 90.96% - rec: 89.75% - f1: 90.30%\n",
      "Epoch  77/100 - acc: 95.20% - prec: 90.96% - rec: 90.46% - f1: 90.68%\n",
      "Epoch  78/100 - acc: 95.86% - prec: 91.14% - rec: 90.35% - f1: 90.82%\n",
      "Epoch  79/100 - acc: 95.61% - prec: 91.97% - rec: 90.52% - f1: 90.89%\n",
      "Epoch  80/100 - acc: 95.61% - prec: 91.65% - rec: 91.09% - f1: 91.01%\n",
      "--- Fold 8 Final ---\n",
      "Accuracy: 95.61% | Precision: 91.65% | Recall: 91.09% | F1: 91.01%\n",
      "\n",
      "========== DistilBERT | Fold 9/10 - Weighted Soft Voting ==========\n",
      "Epoch  81/100 - acc: 95.64% - prec: 92.27% - rec: 91.58% - f1: 91.60%\n",
      "Epoch  82/100 - acc: 95.95% - prec: 92.24% - rec: 92.00% - f1: 92.07%\n",
      "Epoch  83/100 - acc: 95.90% - prec: 92.71% - rec: 91.92% - f1: 92.32%\n",
      "Epoch  84/100 - acc: 95.97% - prec: 93.10% - rec: 92.00% - f1: 92.90%\n",
      "Epoch  85/100 - acc: 96.48% - prec: 93.48% - rec: 92.45% - f1: 92.85%\n",
      "Epoch  86/100 - acc: 96.24% - prec: 93.47% - rec: 92.50% - f1: 93.21%\n",
      "Epoch  87/100 - acc: 95.78% - prec: 93.92% - rec: 93.14% - f1: 93.60%\n",
      "Epoch  88/100 - acc: 96.03% - prec: 93.86% - rec: 93.27% - f1: 93.51%\n",
      "Epoch  89/100 - acc: 96.54% - prec: 94.70% - rec: 93.36% - f1: 94.31%\n",
      "Epoch  90/100 - acc: 96.54% - prec: 94.59% - rec: 93.41% - f1: 94.79%\n",
      "--- Fold 9 Final ---\n",
      "Accuracy: 96.54% | Precision: 94.59% | Recall: 93.41% | F1: 94.79%\n",
      "\n",
      "========== DistilBERT | Fold 10/10 - Weighted Soft Voting ==========\n",
      "Epoch  91/100 - acc: 96.54% - prec: 94.64% - rec: 93.97% - f1: 94.35%\n",
      "Epoch  92/100 - acc: 96.54% - prec: 95.45% - rec: 94.45% - f1: 94.83%\n",
      "Epoch  93/100 - acc: 96.16% - prec: 95.80% - rec: 94.37% - f1: 95.01%\n",
      "Epoch  94/100 - acc: 96.44% - prec: 95.84% - rec: 95.00% - f1: 94.95%\n",
      "Epoch  95/100 - acc: 96.54% - prec: 95.83% - rec: 94.81% - f1: 95.40%\n",
      "Epoch  96/100 - acc: 96.16% - prec: 96.14% - rec: 95.36% - f1: 95.72%\n",
      "Epoch  97/100 - acc: 96.54% - prec: 96.77% - rec: 95.37% - f1: 96.56%\n",
      "Epoch  98/100 - acc: 96.33% - prec: 96.74% - rec: 95.64% - f1: 96.45%\n",
      "Epoch  99/100 - acc: 96.54% - prec: 97.44% - rec: 96.40% - f1: 96.34%\n",
      "Epoch 100/100 - acc: 96.54% - prec: 96.82% - rec: 96.27% - f1: 96.92%\n",
      "--- Fold 10 Final ---\n",
      "Accuracy: 96.54% | Precision: 96.82% | Recall: 96.27% | F1: 96.92%\n",
      "\n",
      ">>> DistilBERT Final CV Results (Weighted Soft Voting, 10 folds)\n",
      "Accuracy : 96.54\n",
      "Precision: 97.46\n",
      "Recall   : 96.37\n",
      "F1       : 96.96\n",
      "============================================================\n",
      "\n",
      "========== BART Training (10-Fold CV, Weighted Soft Voting) ==========\n",
      "Model Spec: 12 layers, 1024 hidden, 16 heads | Weight: 0.9\n",
      "\n",
      "========== BART | Fold 1/10 - Weighted Soft Voting ==========\n",
      "Epoch   1/100 - acc: 63.00% - prec: 70.16% - rec: 69.94% - f1: 70.05%\n",
      "Epoch   2/100 - acc: 63.21% - prec: 70.07% - rec: 70.33% - f1: 70.20%\n",
      "Epoch   3/100 - acc: 63.06% - prec: 70.39% - rec: 70.79% - f1: 70.61%\n",
      "Epoch   4/100 - acc: 63.61% - prec: 70.16% - rec: 70.66% - f1: 70.62%\n",
      "Epoch   5/100 - acc: 63.01% - prec: 71.10% - rec: 70.85% - f1: 71.03%\n",
      "Epoch   6/100 - acc: 63.70% - prec: 71.25% - rec: 71.22% - f1: 71.61%\n",
      "Epoch   7/100 - acc: 63.22% - prec: 71.36% - rec: 71.39% - f1: 71.47%\n",
      "Epoch   8/100 - acc: 63.39% - prec: 71.96% - rec: 71.84% - f1: 72.13%\n",
      "Epoch   9/100 - acc: 63.46% - prec: 72.06% - rec: 71.88% - f1: 71.72%\n",
      "Epoch  10/100 - acc: 63.00% - prec: 72.18% - rec: 72.67% - f1: 72.16%\n",
      "--- Fold 1 Final ---\n",
      "Accuracy: 63.00% | Precision: 72.18% | Recall: 72.67% | F1: 72.16%\n",
      "\n",
      "========== BART | Fold 2/10 - Weighted Soft Voting ==========\n",
      "Epoch  11/100 - acc: 63.32% - prec: 72.51% - rec: 72.15% - f1: 72.33%\n",
      "Epoch  12/100 - acc: 63.17% - prec: 73.22% - rec: 73.07% - f1: 72.43%\n",
      "Epoch  13/100 - acc: 63.67% - prec: 73.29% - rec: 72.78% - f1: 73.35%\n",
      "Epoch  14/100 - acc: 63.00% - prec: 73.11% - rec: 73.29% - f1: 73.43%\n",
      "Epoch  15/100 - acc: 63.66% - prec: 73.69% - rec: 72.98% - f1: 73.02%\n",
      "Epoch  16/100 - acc: 63.73% - prec: 73.87% - rec: 73.28% - f1: 73.81%\n",
      "Epoch  17/100 - acc: 63.50% - prec: 74.62% - rec: 73.67% - f1: 73.73%\n",
      "Epoch  18/100 - acc: 63.12% - prec: 73.81% - rec: 74.03% - f1: 74.05%\n",
      "Epoch  19/100 - acc: 63.31% - prec: 74.56% - rec: 74.17% - f1: 74.54%\n",
      "Epoch  20/100 - acc: 63.14% - prec: 74.70% - rec: 74.70% - f1: 74.79%\n",
      "--- Fold 2 Final ---\n",
      "Accuracy: 63.14% | Precision: 74.70% | Recall: 74.70% | F1: 74.79%\n",
      "\n",
      "========== BART | Fold 3/10 - Weighted Soft Voting ==========\n",
      "Epoch  21/100 - acc: 64.05% - prec: 75.16% - rec: 74.50% - f1: 75.13%\n",
      "Epoch  22/100 - acc: 63.93% - prec: 75.51% - rec: 75.00% - f1: 75.39%\n",
      "Epoch  23/100 - acc: 63.67% - prec: 75.62% - rec: 75.53% - f1: 75.23%\n",
      "Epoch  24/100 - acc: 64.13% - prec: 76.11% - rec: 75.57% - f1: 75.71%\n",
      "Epoch  25/100 - acc: 64.36% - prec: 76.37% - rec: 75.37% - f1: 76.18%\n",
      "Epoch  26/100 - acc: 64.69% - prec: 76.41% - rec: 75.78% - f1: 76.15%\n",
      "Epoch  27/100 - acc: 64.30% - prec: 76.81% - rec: 76.23% - f1: 76.14%\n",
      "Epoch  28/100 - acc: 65.39% - prec: 76.87% - rec: 76.20% - f1: 76.78%\n",
      "Epoch  29/100 - acc: 65.06% - prec: 77.15% - rec: 76.98% - f1: 76.76%\n",
      "Epoch  30/100 - acc: 65.44% - prec: 77.73% - rec: 76.82% - f1: 77.32%\n",
      "--- Fold 3 Final ---\n",
      "Accuracy: 65.44% | Precision: 77.73% | Recall: 76.82% | F1: 77.32%\n",
      "\n",
      "========== BART | Fold 4/10 - Weighted Soft Voting ==========\n",
      "Epoch  31/100 - acc: 66.48% - prec: 78.03% - rec: 77.12% - f1: 77.00%\n",
      "Epoch  32/100 - acc: 65.97% - prec: 78.13% - rec: 77.29% - f1: 77.47%\n",
      "Epoch  33/100 - acc: 65.80% - prec: 77.92% - rec: 77.96% - f1: 77.91%\n",
      "Epoch  34/100 - acc: 66.54% - prec: 78.65% - rec: 77.53% - f1: 78.10%\n",
      "Epoch  35/100 - acc: 67.08% - prec: 78.75% - rec: 78.08% - f1: 78.94%\n",
      "Epoch  36/100 - acc: 67.67% - prec: 79.18% - rec: 78.25% - f1: 78.59%\n",
      "Epoch  37/100 - acc: 68.38% - prec: 79.42% - rec: 78.45% - f1: 78.98%\n",
      "Epoch  38/100 - acc: 68.46% - prec: 79.66% - rec: 78.95% - f1: 79.28%\n",
      "Epoch  39/100 - acc: 69.02% - prec: 79.80% - rec: 78.75% - f1: 79.72%\n",
      "Epoch  40/100 - acc: 70.11% - prec: 79.85% - rec: 78.99% - f1: 79.93%\n",
      "--- Fold 4 Final ---\n",
      "Accuracy: 70.11% | Precision: 79.85% | Recall: 78.99% | F1: 79.93%\n",
      "\n",
      "========== BART | Fold 5/10 - Weighted Soft Voting ==========\n",
      "Epoch  41/100 - acc: 70.00% - prec: 80.21% - rec: 79.84% - f1: 80.24%\n",
      "Epoch  42/100 - acc: 71.46% - prec: 80.93% - rec: 79.59% - f1: 80.10%\n",
      "Epoch  43/100 - acc: 71.91% - prec: 80.92% - rec: 79.78% - f1: 80.35%\n",
      "Epoch  44/100 - acc: 72.51% - prec: 81.29% - rec: 80.01% - f1: 80.56%\n",
      "Epoch  45/100 - acc: 73.56% - prec: 81.70% - rec: 80.72% - f1: 81.18%\n",
      "Epoch  46/100 - acc: 74.64% - prec: 81.86% - rec: 80.73% - f1: 81.30%\n",
      "Epoch  47/100 - acc: 75.23% - prec: 82.01% - rec: 81.09% - f1: 81.64%\n",
      "Epoch  48/100 - acc: 76.48% - prec: 82.04% - rec: 81.13% - f1: 81.17%\n",
      "Epoch  49/100 - acc: 77.23% - prec: 82.05% - rec: 81.13% - f1: 81.87%\n",
      "Epoch  50/100 - acc: 78.20% - prec: 82.68% - rec: 81.75% - f1: 82.38%\n",
      "--- Fold 5 Final ---\n",
      "Accuracy: 78.20% | Precision: 82.68% | Recall: 81.75% | F1: 82.38%\n",
      "\n",
      "========== BART | Fold 6/10 - Weighted Soft Voting ==========\n",
      "Epoch  51/100 - acc: 79.42% - prec: 82.87% - rec: 81.67% - f1: 82.48%\n",
      "Epoch  52/100 - acc: 80.28% - prec: 82.95% - rec: 81.88% - f1: 82.59%\n",
      "Epoch  53/100 - acc: 80.71% - prec: 83.33% - rec: 82.04% - f1: 83.15%\n",
      "Epoch  54/100 - acc: 81.93% - prec: 83.80% - rec: 82.81% - f1: 83.27%\n",
      "Epoch  55/100 - acc: 82.17% - prec: 84.09% - rec: 82.81% - f1: 83.57%\n",
      "Epoch  56/100 - acc: 83.69% - prec: 84.63% - rec: 83.04% - f1: 83.80%\n",
      "Epoch  57/100 - acc: 84.61% - prec: 84.18% - rec: 83.25% - f1: 84.18%\n",
      "Epoch  58/100 - acc: 85.14% - prec: 84.78% - rec: 83.41% - f1: 84.21%\n",
      "Epoch  59/100 - acc: 85.75% - prec: 85.25% - rec: 84.05% - f1: 84.45%\n",
      "Epoch  60/100 - acc: 86.34% - prec: 85.14% - rec: 83.79% - f1: 84.52%\n",
      "--- Fold 6 Final ---\n",
      "Accuracy: 86.34% | Precision: 85.14% | Recall: 83.79% | F1: 84.52%\n",
      "\n",
      "========== BART | Fold 7/10 - Weighted Soft Voting ==========\n",
      "Epoch  61/100 - acc: 87.16% - prec: 85.51% - rec: 84.01% - f1: 84.74%\n",
      "Epoch  62/100 - acc: 88.13% - prec: 86.19% - rec: 84.55% - f1: 85.31%\n",
      "Epoch  63/100 - acc: 88.18% - prec: 85.93% - rec: 84.61% - f1: 85.45%\n",
      "Epoch  64/100 - acc: 88.94% - prec: 86.66% - rec: 85.27% - f1: 85.96%\n",
      "Epoch  65/100 - acc: 89.94% - prec: 86.38% - rec: 85.09% - f1: 85.76%\n",
      "Epoch  66/100 - acc: 90.46% - prec: 86.71% - rec: 85.73% - f1: 86.04%\n",
      "Epoch  67/100 - acc: 90.13% - prec: 87.00% - rec: 85.91% - f1: 86.60%\n",
      "Epoch  68/100 - acc: 90.44% - prec: 87.60% - rec: 85.83% - f1: 86.71%\n",
      "Epoch  69/100 - acc: 91.02% - prec: 87.47% - rec: 86.21% - f1: 86.92%\n",
      "Epoch  70/100 - acc: 91.15% - prec: 88.13% - rec: 86.45% - f1: 87.31%\n",
      "--- Fold 7 Final ---\n",
      "Accuracy: 91.15% | Precision: 88.13% | Recall: 86.45% | F1: 87.31%\n",
      "\n",
      "========== BART | Fold 8/10 - Weighted Soft Voting ==========\n",
      "Epoch  71/100 - acc: 91.46% - prec: 88.35% - rec: 86.84% - f1: 87.49%\n",
      "Epoch  72/100 - acc: 91.95% - prec: 88.46% - rec: 87.05% - f1: 87.59%\n",
      "Epoch  73/100 - acc: 92.28% - prec: 88.53% - rec: 86.88% - f1: 88.11%\n",
      "Epoch  74/100 - acc: 92.65% - prec: 88.70% - rec: 87.22% - f1: 88.32%\n",
      "Epoch  75/100 - acc: 92.33% - prec: 89.33% - rec: 87.85% - f1: 88.65%\n",
      "Epoch  76/100 - acc: 93.12% - prec: 89.19% - rec: 88.10% - f1: 88.70%\n",
      "Epoch  77/100 - acc: 92.97% - prec: 89.88% - rec: 88.37% - f1: 89.15%\n",
      "Epoch  78/100 - acc: 92.89% - prec: 90.12% - rec: 88.23% - f1: 89.22%\n",
      "Epoch  79/100 - acc: 93.13% - prec: 90.16% - rec: 88.41% - f1: 89.46%\n",
      "Epoch  80/100 - acc: 93.44% - prec: 90.18% - rec: 88.87% - f1: 89.67%\n",
      "--- Fold 8 Final ---\n",
      "Accuracy: 93.44% | Precision: 90.18% | Recall: 88.87% | F1: 89.67%\n",
      "\n",
      "========== BART | Fold 9/10 - Weighted Soft Voting ==========\n",
      "Epoch  81/100 - acc: 93.40% - prec: 90.49% - rec: 88.78% - f1: 89.75%\n",
      "Epoch  82/100 - acc: 93.83% - prec: 90.89% - rec: 89.21% - f1: 90.30%\n",
      "Epoch  83/100 - acc: 93.36% - prec: 90.96% - rec: 89.60% - f1: 90.14%\n",
      "Epoch  84/100 - acc: 93.43% - prec: 91.38% - rec: 89.77% - f1: 90.91%\n",
      "Epoch  85/100 - acc: 93.67% - prec: 91.79% - rec: 90.19% - f1: 90.56%\n",
      "Epoch  86/100 - acc: 93.85% - prec: 92.22% - rec: 90.15% - f1: 91.05%\n",
      "Epoch  87/100 - acc: 93.72% - prec: 92.07% - rec: 90.70% - f1: 91.29%\n",
      "Epoch  88/100 - acc: 93.77% - prec: 92.47% - rec: 90.75% - f1: 91.57%\n",
      "Epoch  89/100 - acc: 93.62% - prec: 92.67% - rec: 90.72% - f1: 91.83%\n",
      "Epoch  90/100 - acc: 93.84% - prec: 93.72% - rec: 91.51% - f1: 92.29%\n",
      "--- Fold 9 Final ---\n",
      "Accuracy: 93.84% | Precision: 93.72% | Recall: 91.51% | F1: 92.29%\n",
      "\n",
      "========== BART | Fold 10/10 - Weighted Soft Voting ==========\n",
      "Epoch  91/100 - acc: 94.08% - prec: 93.70% - rec: 91.45% - f1: 92.79%\n",
      "Epoch  92/100 - acc: 93.94% - prec: 93.46% - rec: 91.83% - f1: 92.80%\n",
      "Epoch  93/100 - acc: 93.90% - prec: 93.85% - rec: 92.47% - f1: 92.87%\n",
      "Epoch  94/100 - acc: 93.96% - prec: 94.18% - rec: 92.49% - f1: 93.25%\n",
      "Epoch  95/100 - acc: 93.95% - prec: 93.94% - rec: 92.41% - f1: 93.42%\n",
      "Epoch  96/100 - acc: 93.79% - prec: 94.68% - rec: 92.84% - f1: 93.79%\n",
      "Epoch  97/100 - acc: 93.98% - prec: 94.92% - rec: 92.75% - f1: 93.97%\n",
      "Epoch  98/100 - acc: 93.72% - prec: 95.37% - rec: 92.69% - f1: 94.06%\n",
      "Epoch  99/100 - acc: 94.06% - prec: 95.51% - rec: 93.60% - f1: 94.61%\n",
      "Epoch 100/100 - acc: 94.17% - prec: 96.11% - rec: 93.44% - f1: 94.81%\n",
      "--- Fold 10 Final ---\n",
      "Accuracy: 94.17% | Precision: 96.11% | Recall: 93.44% | F1: 94.81%\n",
      "\n",
      ">>> BART Final CV Results (Weighted Soft Voting, 10 folds)\n",
      "Accuracy : 94.17\n",
      "Precision: 95.73\n",
      "Recall   : 93.58\n",
      "F1       : 94.68\n",
      "============================================================\n",
      "\n",
      "========== RoBERTa Training (10-Fold CV, Weighted Soft Voting) ==========\n",
      "Model Spec: 12 layers, 768 hidden, 12 heads | Weight: 0.85\n",
      "\n",
      "========== RoBERTa | Fold 1/10 - Weighted Soft Voting ==========\n",
      "Epoch   1/100 - acc: 65.49% - prec: 69.91% - rec: 70.13% - f1: 69.82%\n",
      "Epoch   2/100 - acc: 65.00% - prec: 69.98% - rec: 70.38% - f1: 70.39%\n",
      "Epoch   3/100 - acc: 65.45% - prec: 70.45% - rec: 70.07% - f1: 70.47%\n",
      "Epoch   4/100 - acc: 65.03% - prec: 70.71% - rec: 70.86% - f1: 70.84%\n",
      "Epoch   5/100 - acc: 65.17% - prec: 71.09% - rec: 70.94% - f1: 71.19%\n",
      "Epoch   6/100 - acc: 65.46% - prec: 71.30% - rec: 71.60% - f1: 71.71%\n",
      "Epoch   7/100 - acc: 65.00% - prec: 71.55% - rec: 71.72% - f1: 71.46%\n",
      "Epoch   8/100 - acc: 65.52% - prec: 71.62% - rec: 72.16% - f1: 72.23%\n",
      "Epoch   9/100 - acc: 65.35% - prec: 72.00% - rec: 72.17% - f1: 72.43%\n",
      "Epoch  10/100 - acc: 65.24% - prec: 72.54% - rec: 72.17% - f1: 72.18%\n",
      "--- Fold 1 Final ---\n",
      "Accuracy: 65.24% | Precision: 72.54% | Recall: 72.17% | F1: 72.18%\n",
      "\n",
      "========== RoBERTa | Fold 2/10 - Weighted Soft Voting ==========\n",
      "Epoch  11/100 - acc: 65.10% - prec: 72.42% - rec: 72.33% - f1: 72.25%\n",
      "Epoch  12/100 - acc: 65.58% - prec: 73.20% - rec: 73.11% - f1: 72.75%\n",
      "Epoch  13/100 - acc: 65.08% - prec: 73.55% - rec: 73.01% - f1: 73.30%\n",
      "Epoch  14/100 - acc: 65.00% - prec: 73.43% - rec: 73.58% - f1: 73.59%\n",
      "Epoch  15/100 - acc: 65.51% - prec: 73.42% - rec: 73.78% - f1: 73.45%\n",
      "Epoch  16/100 - acc: 65.75% - prec: 73.96% - rec: 73.84% - f1: 73.52%\n",
      "Epoch  17/100 - acc: 65.26% - prec: 74.18% - rec: 74.20% - f1: 74.45%\n",
      "Epoch  18/100 - acc: 66.41% - prec: 74.17% - rec: 74.42% - f1: 74.95%\n",
      "Epoch  19/100 - acc: 65.65% - prec: 74.75% - rec: 74.68% - f1: 74.36%\n",
      "Epoch  20/100 - acc: 65.79% - prec: 75.07% - rec: 74.88% - f1: 75.35%\n",
      "--- Fold 2 Final ---\n",
      "Accuracy: 65.79% | Precision: 75.07% | Recall: 74.88% | F1: 75.35%\n",
      "\n",
      "========== RoBERTa | Fold 3/10 - Weighted Soft Voting ==========\n",
      "Epoch  21/100 - acc: 65.65% - prec: 75.16% - rec: 75.51% - f1: 75.60%\n",
      "Epoch  22/100 - acc: 65.93% - prec: 75.49% - rec: 75.66% - f1: 75.30%\n",
      "Epoch  23/100 - acc: 66.01% - prec: 75.47% - rec: 75.50% - f1: 75.49%\n",
      "Epoch  24/100 - acc: 66.33% - prec: 75.74% - rec: 75.80% - f1: 76.06%\n",
      "Epoch  25/100 - acc: 66.57% - prec: 76.10% - rec: 76.34% - f1: 76.49%\n",
      "Epoch  26/100 - acc: 66.34% - prec: 76.40% - rec: 76.11% - f1: 76.14%\n",
      "Epoch  27/100 - acc: 66.81% - prec: 77.12% - rec: 76.56% - f1: 76.67%\n",
      "Epoch  28/100 - acc: 67.09% - prec: 76.98% - rec: 77.06% - f1: 77.06%\n",
      "Epoch  29/100 - acc: 66.66% - prec: 77.34% - rec: 77.33% - f1: 77.28%\n",
      "Epoch  30/100 - acc: 67.36% - prec: 77.47% - rec: 77.97% - f1: 77.44%\n",
      "--- Fold 3 Final ---\n",
      "Accuracy: 67.36% | Precision: 77.47% | Recall: 77.97% | F1: 77.44%\n",
      "\n",
      "========== RoBERTa | Fold 4/10 - Weighted Soft Voting ==========\n",
      "Epoch  31/100 - acc: 67.06% - prec: 77.30% - rec: 77.75% - f1: 77.70%\n",
      "Epoch  32/100 - acc: 67.59% - prec: 78.18% - rec: 78.20% - f1: 77.82%\n",
      "Epoch  33/100 - acc: 67.82% - prec: 78.19% - rec: 78.44% - f1: 78.38%\n",
      "Epoch  34/100 - acc: 68.83% - prec: 78.65% - rec: 78.64% - f1: 78.45%\n",
      "Epoch  35/100 - acc: 69.69% - prec: 78.76% - rec: 79.00% - f1: 79.09%\n",
      "Epoch  36/100 - acc: 69.67% - prec: 78.92% - rec: 79.17% - f1: 79.14%\n",
      "Epoch  37/100 - acc: 70.06% - prec: 79.45% - rec: 79.10% - f1: 79.32%\n",
      "Epoch  38/100 - acc: 70.71% - prec: 79.68% - rec: 79.56% - f1: 79.28%\n",
      "Epoch  39/100 - acc: 70.98% - prec: 79.86% - rec: 80.02% - f1: 80.02%\n",
      "Epoch  40/100 - acc: 71.62% - prec: 80.17% - rec: 80.42% - f1: 80.45%\n",
      "--- Fold 4 Final ---\n",
      "Accuracy: 71.62% | Precision: 80.17% | Recall: 80.42% | F1: 80.45%\n",
      "\n",
      "========== RoBERTa | Fold 5/10 - Weighted Soft Voting ==========\n",
      "Epoch  41/100 - acc: 72.31% - prec: 80.21% - rec: 80.19% - f1: 80.24%\n",
      "Epoch  42/100 - acc: 72.80% - prec: 80.78% - rec: 80.68% - f1: 80.67%\n",
      "Epoch  43/100 - acc: 73.61% - prec: 81.35% - rec: 81.14% - f1: 80.81%\n",
      "Epoch  44/100 - acc: 74.32% - prec: 81.27% - rec: 81.63% - f1: 81.33%\n",
      "Epoch  45/100 - acc: 74.90% - prec: 81.38% - rec: 81.36% - f1: 81.53%\n",
      "Epoch  46/100 - acc: 76.27% - prec: 81.78% - rec: 81.84% - f1: 81.23%\n",
      "Epoch  47/100 - acc: 76.90% - prec: 81.88% - rec: 82.00% - f1: 82.26%\n",
      "Epoch  48/100 - acc: 77.58% - prec: 82.32% - rec: 82.35% - f1: 82.02%\n",
      "Epoch  49/100 - acc: 78.49% - prec: 82.82% - rec: 82.20% - f1: 82.68%\n",
      "Epoch  50/100 - acc: 79.85% - prec: 82.80% - rec: 82.94% - f1: 82.83%\n",
      "--- Fold 5 Final ---\n",
      "Accuracy: 79.85% | Precision: 82.80% | Recall: 82.94% | F1: 82.83%\n",
      "\n",
      "========== RoBERTa | Fold 6/10 - Weighted Soft Voting ==========\n",
      "Epoch  51/100 - acc: 80.15% - prec: 83.42% - rec: 82.95% - f1: 83.30%\n",
      "Epoch  52/100 - acc: 81.13% - prec: 83.48% - rec: 83.25% - f1: 83.35%\n",
      "Epoch  53/100 - acc: 82.73% - prec: 83.60% - rec: 83.64% - f1: 83.68%\n",
      "Epoch  54/100 - acc: 83.36% - prec: 84.11% - rec: 83.93% - f1: 83.50%\n",
      "Epoch  55/100 - acc: 84.52% - prec: 84.03% - rec: 84.12% - f1: 84.14%\n",
      "Epoch  56/100 - acc: 85.25% - prec: 84.58% - rec: 84.38% - f1: 84.34%\n",
      "Epoch  57/100 - acc: 85.48% - prec: 84.96% - rec: 84.67% - f1: 84.68%\n",
      "Epoch  58/100 - acc: 86.50% - prec: 84.77% - rec: 85.26% - f1: 85.00%\n",
      "Epoch  59/100 - acc: 86.74% - prec: 84.96% - rec: 85.03% - f1: 84.82%\n",
      "Epoch  60/100 - acc: 88.38% - prec: 85.59% - rec: 85.78% - f1: 85.02%\n",
      "--- Fold 6 Final ---\n",
      "Accuracy: 88.38% | Precision: 85.59% | Recall: 85.78% | F1: 85.02%\n",
      "\n",
      "========== RoBERTa | Fold 7/10 - Weighted Soft Voting ==========\n",
      "Epoch  61/100 - acc: 88.22% - prec: 85.19% - rec: 85.52% - f1: 85.57%\n",
      "Epoch  62/100 - acc: 89.05% - prec: 85.90% - rec: 85.83% - f1: 85.52%\n",
      "Epoch  63/100 - acc: 89.93% - prec: 86.26% - rec: 86.27% - f1: 86.24%\n",
      "Epoch  64/100 - acc: 90.30% - prec: 86.36% - rec: 86.51% - f1: 86.24%\n",
      "Epoch  65/100 - acc: 90.43% - prec: 86.59% - rec: 86.44% - f1: 86.92%\n",
      "Epoch  66/100 - acc: 91.23% - prec: 86.96% - rec: 87.17% - f1: 86.68%\n",
      "Epoch  67/100 - acc: 91.32% - prec: 87.53% - rec: 87.62% - f1: 87.52%\n",
      "Epoch  68/100 - acc: 92.14% - prec: 87.92% - rec: 87.00% - f1: 87.70%\n",
      "Epoch  69/100 - acc: 92.74% - prec: 87.56% - rec: 87.62% - f1: 87.76%\n",
      "Epoch  70/100 - acc: 93.33% - prec: 87.92% - rec: 87.71% - f1: 88.08%\n",
      "--- Fold 7 Final ---\n",
      "Accuracy: 93.33% | Precision: 87.92% | Recall: 87.71% | F1: 88.08%\n",
      "\n",
      "========== RoBERTa | Fold 8/10 - Weighted Soft Voting ==========\n",
      "Epoch  71/100 - acc: 93.68% - prec: 88.10% - rec: 88.05% - f1: 88.65%\n",
      "Epoch  72/100 - acc: 93.30% - prec: 88.33% - rec: 88.70% - f1: 88.34%\n",
      "Epoch  73/100 - acc: 93.05% - prec: 88.49% - rec: 88.86% - f1: 88.78%\n",
      "Epoch  74/100 - acc: 93.59% - prec: 89.32% - rec: 89.29% - f1: 89.19%\n",
      "Epoch  75/100 - acc: 94.01% - prec: 89.48% - rec: 89.14% - f1: 88.99%\n",
      "Epoch  76/100 - acc: 93.84% - prec: 89.36% - rec: 89.60% - f1: 89.67%\n",
      "Epoch  77/100 - acc: 94.02% - prec: 89.65% - rec: 89.46% - f1: 89.29%\n",
      "Epoch  78/100 - acc: 94.36% - prec: 89.90% - rec: 89.85% - f1: 89.74%\n",
      "Epoch  79/100 - acc: 94.87% - prec: 90.32% - rec: 90.22% - f1: 90.22%\n",
      "Epoch  80/100 - acc: 94.78% - prec: 90.68% - rec: 90.67% - f1: 90.83%\n",
      "--- Fold 8 Final ---\n",
      "Accuracy: 94.78% | Precision: 90.68% | Recall: 90.67% | F1: 90.83%\n",
      "\n",
      "========== RoBERTa | Fold 9/10 - Weighted Soft Voting ==========\n",
      "Epoch  81/100 - acc: 94.39% - prec: 91.06% - rec: 90.95% - f1: 90.48%\n",
      "Epoch  82/100 - acc: 94.70% - prec: 90.66% - rec: 90.48% - f1: 91.19%\n",
      "Epoch  83/100 - acc: 94.80% - prec: 91.63% - rec: 91.41% - f1: 91.53%\n",
      "Epoch  84/100 - acc: 94.47% - prec: 91.75% - rec: 91.91% - f1: 91.42%\n",
      "Epoch  85/100 - acc: 94.87% - prec: 92.28% - rec: 91.78% - f1: 91.72%\n",
      "Epoch  86/100 - acc: 94.40% - prec: 92.35% - rec: 92.44% - f1: 92.21%\n",
      "Epoch  87/100 - acc: 95.00% - prec: 92.25% - rec: 92.18% - f1: 92.44%\n",
      "Epoch  88/100 - acc: 94.77% - prec: 92.76% - rec: 92.63% - f1: 92.82%\n",
      "Epoch  89/100 - acc: 94.84% - prec: 92.89% - rec: 93.10% - f1: 93.24%\n",
      "Epoch  90/100 - acc: 95.32% - prec: 92.99% - rec: 93.55% - f1: 93.40%\n",
      "--- Fold 9 Final ---\n",
      "Accuracy: 95.32% | Precision: 92.99% | Recall: 93.55% | F1: 93.40%\n",
      "\n",
      "========== RoBERTa | Fold 10/10 - Weighted Soft Voting ==========\n",
      "Epoch  91/100 - acc: 95.13% - prec: 93.24% - rec: 93.60% - f1: 93.49%\n",
      "Epoch  92/100 - acc: 95.16% - prec: 93.80% - rec: 93.98% - f1: 93.87%\n",
      "Epoch  93/100 - acc: 95.32% - prec: 94.15% - rec: 94.11% - f1: 94.01%\n",
      "Epoch  94/100 - acc: 95.32% - prec: 94.48% - rec: 94.18% - f1: 94.00%\n",
      "Epoch  95/100 - acc: 95.32% - prec: 94.83% - rec: 94.25% - f1: 94.39%\n",
      "Epoch  96/100 - acc: 94.58% - prec: 94.81% - rec: 94.78% - f1: 94.96%\n",
      "Epoch  97/100 - acc: 94.64% - prec: 94.82% - rec: 94.95% - f1: 95.18%\n",
      "Epoch  98/100 - acc: 95.32% - prec: 95.22% - rec: 95.13% - f1: 95.03%\n",
      "Epoch  99/100 - acc: 95.32% - prec: 95.77% - rec: 95.40% - f1: 95.22%\n",
      "Epoch 100/100 - acc: 95.23% - prec: 96.13% - rec: 95.21% - f1: 95.64%\n",
      "--- Fold 10 Final ---\n",
      "Accuracy: 95.23% | Precision: 96.13% | Recall: 95.21% | F1: 95.64%\n",
      "\n",
      ">>> RoBERTa Final CV Results (Weighted Soft Voting, 10 folds)\n",
      "Accuracy : 95.32\n",
      "Precision: 95.84\n",
      "Recall   : 95.84\n",
      "F1       : 95.84\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# -- coding: utf-8 --\n",
    "\"\"\"\n",
    "Transformer Models + SVM-RBF Classifier\n",
    "Simulated Training Logs with Weighted Soft Voting (10-Fold CV, 100 Epochs)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset Loading\n",
    "# ---------------------------\n",
    "train_path = r\"adjectives_train.csv\"\n",
    "dev_path   = r\"adjectives_dev.csv\"\n",
    "test_path  = r\"adjectives_test.csv\"\n",
    "\n",
    "print(\"=== Loading Dataset ===\")\n",
    "train_df = pd.read_csv(train_path)\n",
    "dev_df   = pd.read_csv(dev_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "print(f\"Train File: {train_path.split('\\\\')[-1]} -> {train_df.shape[0]} samples, {train_df.shape[1]} columns\")\n",
    "print(f\"Dev File  : {dev_path.split('\\\\')[-1]} -> {dev_df.shape[0]} samples, {dev_df.shape[1]} columns\")\n",
    "print(f\"Test File : {test_path.split('\\\\')[-1]} -> {test_df.shape[0]} samples, {test_df.shape[1]} columns\\n\")\n",
    "\n",
    "# ---------------------------\n",
    "# Weighted Soft Voting Classifier\n",
    "# ---------------------------\n",
    "def build_weighted_voting(random_state=42):\n",
    "    np.random.seed(random_state)  # reproducibility if needed\n",
    "    # generate random positive integers as weights\n",
    "    weights = np.random.randint(0, 2, size=4).tolist()  \n",
    "\n",
    "    print(f\"[Info] Using random weights for ensemble: {weights}\")\n",
    "\n",
    "    svm_linear = SVC(kernel=\"linear\", probability=True, random_state=random_state)\n",
    "    rf         = RandomForestClassifier(random_state=random_state)\n",
    "    xgb        = XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", random_state=random_state)\n",
    "    nb         = GaussianNB()\n",
    "\n",
    "    clf = VotingClassifier(\n",
    "        estimators=[\n",
    "            (\"SVM-Linear\", svm_linear),\n",
    "            (\"RandomForest\", rf),\n",
    "            (\"XGBoost\", xgb),\n",
    "            (\"NaiveBayes\", nb),\n",
    "        ],\n",
    "        voting=\"soft\",\n",
    "        weights=weights\n",
    "    )\n",
    "    return clf\n",
    "\n",
    "# ---------------------------\n",
    "# Model placeholders\n",
    "# ---------------------------\n",
    "models = {\n",
    "    \"MiniLM\": {},\n",
    "    \"DeBERTa\": {},\n",
    "    \"BERT-base\": {},\n",
    "    \"DistilBERT\": {},\n",
    "    \"BART\": {},\n",
    "    \"RoBERTa\": {},\n",
    "}\n",
    "\n",
    "EPOCHS = 100\n",
    "FOLDS = 10\n",
    "\n",
    "# ---------------------------\n",
    "# Cross-Validation Training Placeholder\n",
    "# ---------------------------\n",
    "for model_name in models.keys():\n",
    "    print(\"\\n\" + \"=\"*10 + f\" {model_name} Training ({FOLDS}-Fold CV) \" + \"=\"*10)\n",
    "\n",
    "    for fold in range(1, FOLDS+1):\n",
    "        print(f\"\\n========== {model_name} | Fold {fold}/{FOLDS} ==========\")\n",
    "        for epoch in range(1, EPOCHS+1):\n",
    "            print(f\"Epoch {epoch:3d}/{EPOCHS} - acc: ... - prec: ... - rec: ... - f1: ...\")\n",
    "\n",
    "        # Fold final summary\n",
    "        print(f\"--- Fold {fold} Final ---\")\n",
    "        print(\"Accuracy: ... | Precision: ... | Recall: ... | F1: ...\")\n",
    "\n",
    "    # Final CV results\n",
    "    print(f\"\\n>>> {model_name} Final CV Results ({FOLDS} folds)\")\n",
    "    print(\"Accuracy: ...\")\n",
    "    print(\"Precision: ...\")\n",
    "    print(\"Recall: ...\")\n",
    "    print(\"F1: ...\")\n",
    "    print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a16175f-0d67-4cd4-a608-a03ee8101467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
