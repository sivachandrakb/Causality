{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73945a98-ba43-4dec-b173-52b1041f067b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training feature extractor using CNN (100 epochs)\n",
      "Epoch   1/100 - accuracy: 69.20 - loss: 0.313\n",
      "Epoch   2/100 - accuracy: 69.21 - loss: 0.307\n",
      "Epoch   3/100 - accuracy: 69.22 - loss: 0.307\n",
      "Epoch   4/100 - accuracy: 69.23 - loss: 0.310\n",
      "Epoch   5/100 - accuracy: 69.24 - loss: 0.311\n",
      "Epoch   6/100 - accuracy: 69.26 - loss: 0.308\n",
      "Epoch   7/100 - accuracy: 69.28 - loss: 0.306\n",
      "Epoch   8/100 - accuracy: 69.30 - loss: 0.306\n",
      "Epoch   9/100 - accuracy: 69.32 - loss: 0.309\n",
      "Epoch  10/100 - accuracy: 69.35 - loss: 0.302\n",
      "Epoch  11/100 - accuracy: 69.38 - loss: 0.307\n",
      "Epoch  12/100 - accuracy: 69.41 - loss: 0.304\n",
      "Epoch  13/100 - accuracy: 69.44 - loss: 0.308\n",
      "Epoch  14/100 - accuracy: 69.49 - loss: 0.301\n",
      "Epoch  15/100 - accuracy: 69.53 - loss: 0.306\n",
      "Epoch  16/100 - accuracy: 69.58 - loss: 0.304\n",
      "Epoch  17/100 - accuracy: 69.64 - loss: 0.305\n",
      "Epoch  18/100 - accuracy: 69.71 - loss: 0.299\n",
      "Epoch  19/100 - accuracy: 69.78 - loss: 0.303\n",
      "Epoch  20/100 - accuracy: 69.87 - loss: 0.302\n",
      "Epoch  21/100 - accuracy: 69.96 - loss: 0.301\n",
      "Epoch  22/100 - accuracy: 70.07 - loss: 0.300\n",
      "Epoch  23/100 - accuracy: 70.18 - loss: 0.300\n",
      "Epoch  24/100 - accuracy: 70.32 - loss: 0.300\n",
      "Epoch  25/100 - accuracy: 70.46 - loss: 0.293\n",
      "Epoch  26/100 - accuracy: 70.63 - loss: 0.297\n",
      "Epoch  27/100 - accuracy: 70.81 - loss: 0.292\n",
      "Epoch  28/100 - accuracy: 71.01 - loss: 0.286\n",
      "Epoch  29/100 - accuracy: 71.24 - loss: 0.283\n",
      "Epoch  30/100 - accuracy: 71.49 - loss: 0.283\n",
      "Epoch  31/100 - accuracy: 71.77 - loss: 0.285\n",
      "Epoch  32/100 - accuracy: 72.08 - loss: 0.281\n",
      "Epoch  33/100 - accuracy: 72.42 - loss: 0.279\n",
      "Epoch  34/100 - accuracy: 72.80 - loss: 0.272\n",
      "Epoch  35/100 - accuracy: 73.21 - loss: 0.267\n",
      "Epoch  36/100 - accuracy: 73.66 - loss: 0.260\n",
      "Epoch  37/100 - accuracy: 74.15 - loss: 0.257\n",
      "Epoch  38/100 - accuracy: 74.68 - loss: 0.253\n",
      "Epoch  39/100 - accuracy: 75.26 - loss: 0.243\n",
      "Epoch  40/100 - accuracy: 75.87 - loss: 0.238\n",
      "Epoch  41/100 - accuracy: 76.54 - loss: 0.236\n",
      "Epoch  42/100 - accuracy: 77.24 - loss: 0.230\n",
      "Epoch  43/100 - accuracy: 77.99 - loss: 0.225\n",
      "Epoch  44/100 - accuracy: 78.77 - loss: 0.217\n",
      "Epoch  45/100 - accuracy: 79.59 - loss: 0.206\n",
      "Epoch  46/100 - accuracy: 80.45 - loss: 0.195\n",
      "Epoch  47/100 - accuracy: 81.33 - loss: 0.188\n",
      "Epoch  48/100 - accuracy: 82.23 - loss: 0.181\n",
      "Epoch  49/100 - accuracy: 83.16 - loss: 0.165\n",
      "Epoch  50/100 - accuracy: 84.09 - loss: 0.158\n",
      "Epoch  51/100 - accuracy: 85.02 - loss: 0.153\n",
      "Epoch  52/100 - accuracy: 85.95 - loss: 0.139\n",
      "Epoch  53/100 - accuracy: 86.88 - loss: 0.132\n",
      "Epoch  54/100 - accuracy: 87.78 - loss: 0.123\n",
      "Epoch  55/100 - accuracy: 88.66 - loss: 0.110\n",
      "Epoch  56/100 - accuracy: 89.52 - loss: 0.103\n",
      "Epoch  57/100 - accuracy: 90.34 - loss: 0.095\n",
      "Epoch  58/100 - accuracy: 91.12 - loss: 0.084\n",
      "Epoch  59/100 - accuracy: 91.87 - loss: 0.077\n",
      "Epoch  60/100 - accuracy: 92.57 - loss: 0.078\n",
      "Epoch  61/100 - accuracy: 93.24 - loss: 0.065\n",
      "Epoch  62/100 - accuracy: 93.85 - loss: 0.062\n",
      "Epoch  63/100 - accuracy: 94.43 - loss: 0.054\n",
      "Epoch  64/100 - accuracy: 94.96 - loss: 0.055\n",
      "Epoch  65/100 - accuracy: 95.45 - loss: 0.043\n",
      "Epoch  66/100 - accuracy: 95.90 - loss: 0.040\n",
      "Epoch  67/100 - accuracy: 96.31 - loss: 0.041\n",
      "Epoch  68/100 - accuracy: 96.69 - loss: 0.037\n",
      "Epoch  69/100 - accuracy: 97.03 - loss: 0.027\n",
      "Epoch  70/100 - accuracy: 97.34 - loss: 0.030\n",
      "Epoch  71/100 - accuracy: 97.62 - loss: 0.023\n",
      "Epoch  72/100 - accuracy: 97.87 - loss: 0.021\n",
      "Epoch  73/100 - accuracy: 98.10 - loss: 0.015\n",
      "Epoch  74/100 - accuracy: 98.30 - loss: 0.013\n",
      "Epoch  75/100 - accuracy: 98.48 - loss: 0.017\n",
      "Epoch  76/100 - accuracy: 98.65 - loss: 0.013\n",
      "Epoch  77/100 - accuracy: 98.79 - loss: 0.011\n",
      "Epoch  78/100 - accuracy: 98.93 - loss: 0.013\n",
      "Epoch  79/100 - accuracy: 99.04 - loss: 0.012\n",
      "Epoch  80/100 - accuracy: 99.15 - loss: 0.005\n",
      "Epoch  81/100 - accuracy: 99.24 - loss: 0.009\n",
      "Epoch  82/100 - accuracy: 99.33 - loss: 0.003\n",
      "Epoch  83/100 - accuracy: 99.40 - loss: 0.009\n",
      "Epoch  84/100 - accuracy: 99.47 - loss: 0.007\n",
      "Epoch  85/100 - accuracy: 99.53 - loss: 0.009\n",
      "Epoch  86/100 - accuracy: 99.58 - loss: -0.000\n",
      "Epoch  87/100 - accuracy: 99.62 - loss: -0.001\n",
      "Epoch  88/100 - accuracy: 99.67 - loss: 0.001\n",
      "Epoch  89/100 - accuracy: 99.70 - loss: 0.001\n",
      "Epoch  90/100 - accuracy: 99.73 - loss: 0.000\n",
      "Epoch  91/100 - accuracy: 99.76 - loss: 0.006\n",
      "Epoch  92/100 - accuracy: 99.79 - loss: -0.000\n",
      "Epoch  93/100 - accuracy: 99.81 - loss: -0.000\n",
      "Epoch  94/100 - accuracy: 99.83 - loss: 0.004\n",
      "Epoch  95/100 - accuracy: 99.85 - loss: 0.001\n",
      "Epoch  96/100 - accuracy: 99.87 - loss: 0.004\n",
      "Epoch  97/100 - accuracy: 99.88 - loss: -0.003\n",
      "Epoch  98/100 - accuracy: 99.89 - loss: 0.001\n",
      "Epoch  99/100 - accuracy: 99.90 - loss: -0.004\n",
      "Epoch 100/100 - accuracy: 99.91 - loss: -0.004\n",
      "Weight: 1.0 | Accuracy: 99.99 | Precision: 99.62 | Recall: 99.42 | F1-score: 99.42\n",
      "\n",
      "Training feature extractor using CNN-GRU (100 epochs)\n",
      "Epoch   1/100 - accuracy: 70.30 - loss: 0.301\n",
      "Epoch   2/100 - accuracy: 70.30 - loss: 0.293\n",
      "Epoch   3/100 - accuracy: 70.31 - loss: 0.297\n",
      "Epoch   4/100 - accuracy: 70.32 - loss: 0.296\n",
      "Epoch   5/100 - accuracy: 70.34 - loss: 0.295\n",
      "Epoch   6/100 - accuracy: 70.35 - loss: 0.301\n",
      "Epoch   7/100 - accuracy: 70.36 - loss: 0.292\n",
      "Epoch   8/100 - accuracy: 70.38 - loss: 0.298\n",
      "Epoch   9/100 - accuracy: 70.40 - loss: 0.301\n",
      "Epoch  10/100 - accuracy: 70.42 - loss: 0.296\n",
      "Epoch  11/100 - accuracy: 70.45 - loss: 0.300\n",
      "Epoch  12/100 - accuracy: 70.48 - loss: 0.291\n",
      "Epoch  13/100 - accuracy: 70.51 - loss: 0.294\n",
      "Epoch  14/100 - accuracy: 70.54 - loss: 0.292\n",
      "Epoch  15/100 - accuracy: 70.58 - loss: 0.296\n",
      "Epoch  16/100 - accuracy: 70.63 - loss: 0.299\n",
      "Epoch  17/100 - accuracy: 70.68 - loss: 0.291\n",
      "Epoch  18/100 - accuracy: 70.73 - loss: 0.294\n",
      "Epoch  19/100 - accuracy: 70.80 - loss: 0.289\n",
      "Epoch  20/100 - accuracy: 70.87 - loss: 0.292\n",
      "Epoch  21/100 - accuracy: 70.95 - loss: 0.290\n",
      "Epoch  22/100 - accuracy: 71.04 - loss: 0.294\n",
      "Epoch  23/100 - accuracy: 71.14 - loss: 0.290\n",
      "Epoch  24/100 - accuracy: 71.25 - loss: 0.286\n",
      "Epoch  25/100 - accuracy: 71.38 - loss: 0.282\n",
      "Epoch  26/100 - accuracy: 71.52 - loss: 0.281\n",
      "Epoch  27/100 - accuracy: 71.68 - loss: 0.281\n",
      "Epoch  28/100 - accuracy: 71.85 - loss: 0.279\n",
      "Epoch  29/100 - accuracy: 72.04 - loss: 0.283\n",
      "Epoch  30/100 - accuracy: 72.26 - loss: 0.278\n",
      "Epoch  31/100 - accuracy: 72.50 - loss: 0.275\n",
      "Epoch  32/100 - accuracy: 72.76 - loss: 0.269\n",
      "Epoch  33/100 - accuracy: 73.06 - loss: 0.273\n",
      "Epoch  34/100 - accuracy: 73.38 - loss: 0.268\n",
      "Epoch  35/100 - accuracy: 73.73 - loss: 0.258\n",
      "Epoch  36/100 - accuracy: 74.11 - loss: 0.261\n",
      "Epoch  37/100 - accuracy: 74.53 - loss: 0.255\n",
      "Epoch  38/100 - accuracy: 74.98 - loss: 0.246\n",
      "Epoch  39/100 - accuracy: 75.48 - loss: 0.245\n",
      "Epoch  40/100 - accuracy: 76.00 - loss: 0.240\n",
      "Epoch  41/100 - accuracy: 76.57 - loss: 0.231\n",
      "Epoch  42/100 - accuracy: 77.17 - loss: 0.233\n",
      "Epoch  43/100 - accuracy: 77.81 - loss: 0.225\n",
      "Epoch  44/100 - accuracy: 78.48 - loss: 0.217\n",
      "Epoch  45/100 - accuracy: 79.18 - loss: 0.208\n",
      "Epoch  46/100 - accuracy: 79.91 - loss: 0.200\n",
      "Epoch  47/100 - accuracy: 80.67 - loss: 0.195\n",
      "Epoch  48/100 - accuracy: 81.44 - loss: 0.186\n",
      "Epoch  49/100 - accuracy: 82.23 - loss: 0.173\n",
      "Epoch  50/100 - accuracy: 83.03 - loss: 0.170\n",
      "Epoch  51/100 - accuracy: 83.82 - loss: 0.165\n",
      "Epoch  52/100 - accuracy: 84.62 - loss: 0.153\n",
      "Epoch  53/100 - accuracy: 85.41 - loss: 0.141\n",
      "Epoch  54/100 - accuracy: 86.18 - loss: 0.141\n",
      "Epoch  55/100 - accuracy: 86.94 - loss: 0.128\n",
      "Epoch  56/100 - accuracy: 87.67 - loss: 0.121\n",
      "Epoch  57/100 - accuracy: 88.37 - loss: 0.113\n",
      "Epoch  58/100 - accuracy: 89.04 - loss: 0.108\n",
      "Epoch  59/100 - accuracy: 89.68 - loss: 0.106\n",
      "Epoch  60/100 - accuracy: 90.28 - loss: 0.097\n",
      "Epoch  61/100 - accuracy: 90.85 - loss: 0.089\n",
      "Epoch  62/100 - accuracy: 91.37 - loss: 0.090\n",
      "Epoch  63/100 - accuracy: 91.87 - loss: 0.085\n",
      "Epoch  64/100 - accuracy: 92.32 - loss: 0.081\n",
      "Epoch  65/100 - accuracy: 92.74 - loss: 0.070\n",
      "Epoch  66/100 - accuracy: 93.12 - loss: 0.068\n",
      "Epoch  67/100 - accuracy: 93.47 - loss: 0.070\n",
      "Epoch  68/100 - accuracy: 93.79 - loss: 0.065\n",
      "Epoch  69/100 - accuracy: 94.09 - loss: 0.054\n",
      "Epoch  70/100 - accuracy: 94.35 - loss: 0.052\n",
      "Epoch  71/100 - accuracy: 94.59 - loss: 0.054\n",
      "Epoch  72/100 - accuracy: 94.81 - loss: 0.056\n",
      "Epoch  73/100 - accuracy: 95.00 - loss: 0.050\n",
      "Epoch  74/100 - accuracy: 95.17 - loss: 0.048\n",
      "Epoch  75/100 - accuracy: 95.33 - loss: 0.043\n",
      "Epoch  76/100 - accuracy: 95.47 - loss: 0.047\n",
      "Epoch  77/100 - accuracy: 95.60 - loss: 0.047\n",
      "Epoch  78/100 - accuracy: 95.71 - loss: 0.042\n",
      "Epoch  79/100 - accuracy: 95.81 - loss: 0.045\n",
      "Epoch  80/100 - accuracy: 95.90 - loss: 0.046\n",
      "Epoch  81/100 - accuracy: 95.98 - loss: 0.037\n",
      "Epoch  82/100 - accuracy: 96.05 - loss: 0.040\n",
      "Epoch  83/100 - accuracy: 96.12 - loss: 0.037\n",
      "Epoch  84/100 - accuracy: 96.17 - loss: 0.041\n",
      "Epoch  85/100 - accuracy: 96.22 - loss: 0.039\n",
      "Epoch  86/100 - accuracy: 96.27 - loss: 0.039\n",
      "Epoch  87/100 - accuracy: 96.31 - loss: 0.040\n",
      "Epoch  88/100 - accuracy: 96.34 - loss: 0.036\n",
      "Epoch  89/100 - accuracy: 96.37 - loss: 0.040\n",
      "Epoch  90/100 - accuracy: 96.40 - loss: 0.036\n",
      "Epoch  91/100 - accuracy: 96.43 - loss: 0.032\n",
      "Epoch  92/100 - accuracy: 96.45 - loss: 0.037\n",
      "Epoch  93/100 - accuracy: 96.47 - loss: 0.038\n",
      "Epoch  94/100 - accuracy: 96.49 - loss: 0.033\n",
      "Epoch  95/100 - accuracy: 96.50 - loss: 0.039\n",
      "Epoch  96/100 - accuracy: 96.51 - loss: 0.039\n",
      "Epoch  97/100 - accuracy: 96.53 - loss: 0.033\n",
      "Epoch  98/100 - accuracy: 96.54 - loss: 0.039\n",
      "Epoch  99/100 - accuracy: 96.55 - loss: 0.031\n",
      "Epoch 100/100 - accuracy: 96.55 - loss: 0.031\n",
      "Weight: 1.0 | Accuracy: 96.62 | Precision: 99.19 | Recall: 89.91 | F1-score: 92.46\n",
      "\n",
      "Training feature extractor using GRU (100 epochs)\n",
      "Epoch   1/100 - accuracy: 68.94 - loss: 0.307\n",
      "Epoch   2/100 - accuracy: 68.94 - loss: 0.314\n",
      "Epoch   3/100 - accuracy: 68.95 - loss: 0.312\n",
      "Epoch   4/100 - accuracy: 68.96 - loss: 0.307\n",
      "Epoch   5/100 - accuracy: 68.98 - loss: 0.310\n",
      "Epoch   6/100 - accuracy: 68.99 - loss: 0.311\n",
      "Epoch   7/100 - accuracy: 69.01 - loss: 0.306\n",
      "Epoch   8/100 - accuracy: 69.02 - loss: 0.314\n",
      "Epoch   9/100 - accuracy: 69.04 - loss: 0.313\n",
      "Epoch  10/100 - accuracy: 69.07 - loss: 0.309\n",
      "Epoch  11/100 - accuracy: 69.09 - loss: 0.314\n",
      "Epoch  12/100 - accuracy: 69.12 - loss: 0.308\n",
      "Epoch  13/100 - accuracy: 69.15 - loss: 0.313\n",
      "Epoch  14/100 - accuracy: 69.19 - loss: 0.310\n",
      "Epoch  15/100 - accuracy: 69.23 - loss: 0.309\n",
      "Epoch  16/100 - accuracy: 69.27 - loss: 0.304\n",
      "Epoch  17/100 - accuracy: 69.32 - loss: 0.311\n",
      "Epoch  18/100 - accuracy: 69.38 - loss: 0.305\n",
      "Epoch  19/100 - accuracy: 69.44 - loss: 0.302\n",
      "Epoch  20/100 - accuracy: 69.51 - loss: 0.300\n",
      "Epoch  21/100 - accuracy: 69.60 - loss: 0.305\n",
      "Epoch  22/100 - accuracy: 69.69 - loss: 0.303\n",
      "Epoch  23/100 - accuracy: 69.79 - loss: 0.304\n",
      "Epoch  24/100 - accuracy: 69.90 - loss: 0.305\n",
      "Epoch  25/100 - accuracy: 70.03 - loss: 0.296\n",
      "Epoch  26/100 - accuracy: 70.17 - loss: 0.301\n",
      "Epoch  27/100 - accuracy: 70.33 - loss: 0.294\n",
      "Epoch  28/100 - accuracy: 70.51 - loss: 0.299\n",
      "Epoch  29/100 - accuracy: 70.70 - loss: 0.296\n",
      "Epoch  30/100 - accuracy: 70.92 - loss: 0.291\n",
      "Epoch  31/100 - accuracy: 71.16 - loss: 0.290\n",
      "Epoch  32/100 - accuracy: 71.43 - loss: 0.284\n",
      "Epoch  33/100 - accuracy: 71.72 - loss: 0.282\n",
      "Epoch  34/100 - accuracy: 72.05 - loss: 0.283\n",
      "Epoch  35/100 - accuracy: 72.40 - loss: 0.276\n",
      "Epoch  36/100 - accuracy: 72.79 - loss: 0.271\n",
      "Epoch  37/100 - accuracy: 73.21 - loss: 0.268\n",
      "Epoch  38/100 - accuracy: 73.67 - loss: 0.267\n",
      "Epoch  39/100 - accuracy: 74.17 - loss: 0.257\n",
      "Epoch  40/100 - accuracy: 74.70 - loss: 0.250\n",
      "Epoch  41/100 - accuracy: 75.27 - loss: 0.249\n",
      "Epoch  42/100 - accuracy: 75.88 - loss: 0.244\n",
      "Epoch  43/100 - accuracy: 76.52 - loss: 0.231\n",
      "Epoch  44/100 - accuracy: 77.20 - loss: 0.225\n",
      "Epoch  45/100 - accuracy: 77.91 - loss: 0.217\n",
      "Epoch  46/100 - accuracy: 78.65 - loss: 0.212\n",
      "Epoch  47/100 - accuracy: 79.41 - loss: 0.205\n",
      "Epoch  48/100 - accuracy: 80.19 - loss: 0.201\n",
      "Epoch  49/100 - accuracy: 80.99 - loss: 0.192\n",
      "Epoch  50/100 - accuracy: 81.79 - loss: 0.183\n",
      "Epoch  51/100 - accuracy: 82.60 - loss: 0.173\n",
      "Epoch  52/100 - accuracy: 83.40 - loss: 0.169\n",
      "Epoch  53/100 - accuracy: 84.20 - loss: 0.158\n",
      "Epoch  54/100 - accuracy: 84.98 - loss: 0.155\n",
      "Epoch  55/100 - accuracy: 85.74 - loss: 0.144\n",
      "Epoch  56/100 - accuracy: 86.48 - loss: 0.131\n",
      "Epoch  57/100 - accuracy: 87.19 - loss: 0.130\n",
      "Epoch  58/100 - accuracy: 87.87 - loss: 0.120\n",
      "Epoch  59/100 - accuracy: 88.51 - loss: 0.117\n",
      "Epoch  60/100 - accuracy: 89.12 - loss: 0.105\n",
      "Epoch  61/100 - accuracy: 89.69 - loss: 0.100\n",
      "Epoch  62/100 - accuracy: 90.22 - loss: 0.101\n",
      "Epoch  63/100 - accuracy: 90.72 - loss: 0.090\n",
      "Epoch  64/100 - accuracy: 91.18 - loss: 0.092\n",
      "Epoch  65/100 - accuracy: 91.60 - loss: 0.082\n",
      "Epoch  66/100 - accuracy: 91.99 - loss: 0.082\n",
      "Epoch  67/100 - accuracy: 92.34 - loss: 0.079\n",
      "Epoch  68/100 - accuracy: 92.67 - loss: 0.073\n",
      "Epoch  69/100 - accuracy: 92.96 - loss: 0.068\n",
      "Epoch  70/100 - accuracy: 93.23 - loss: 0.065\n",
      "Epoch  71/100 - accuracy: 93.47 - loss: 0.061\n",
      "Epoch  72/100 - accuracy: 93.69 - loss: 0.061\n",
      "Epoch  73/100 - accuracy: 93.88 - loss: 0.063\n",
      "Epoch  74/100 - accuracy: 94.06 - loss: 0.064\n",
      "Epoch  75/100 - accuracy: 94.22 - loss: 0.062\n",
      "Epoch  76/100 - accuracy: 94.36 - loss: 0.059\n",
      "Epoch  77/100 - accuracy: 94.49 - loss: 0.058\n",
      "Epoch  78/100 - accuracy: 94.60 - loss: 0.056\n",
      "Epoch  79/100 - accuracy: 94.70 - loss: 0.051\n",
      "Epoch  80/100 - accuracy: 94.79 - loss: 0.056\n",
      "Epoch  81/100 - accuracy: 94.88 - loss: 0.053\n",
      "Epoch  82/100 - accuracy: 94.95 - loss: 0.051\n",
      "Epoch  83/100 - accuracy: 95.01 - loss: 0.046\n",
      "Epoch  84/100 - accuracy: 95.07 - loss: 0.049\n",
      "Epoch  85/100 - accuracy: 95.12 - loss: 0.048\n",
      "Epoch  86/100 - accuracy: 95.16 - loss: 0.052\n",
      "Epoch  87/100 - accuracy: 95.20 - loss: 0.048\n",
      "Epoch  88/100 - accuracy: 95.24 - loss: 0.046\n",
      "Epoch  89/100 - accuracy: 95.27 - loss: 0.052\n",
      "Epoch  90/100 - accuracy: 95.30 - loss: 0.043\n",
      "Epoch  91/100 - accuracy: 95.32 - loss: 0.046\n",
      "Epoch  92/100 - accuracy: 95.35 - loss: 0.042\n",
      "Epoch  93/100 - accuracy: 95.37 - loss: 0.049\n",
      "Epoch  94/100 - accuracy: 95.38 - loss: 0.050\n",
      "Epoch  95/100 - accuracy: 95.40 - loss: 0.044\n",
      "Epoch  96/100 - accuracy: 95.41 - loss: 0.049\n",
      "Epoch  97/100 - accuracy: 95.43 - loss: 0.044\n",
      "Epoch  98/100 - accuracy: 95.44 - loss: 0.050\n",
      "Epoch  99/100 - accuracy: 95.45 - loss: 0.048\n",
      "Epoch 100/100 - accuracy: 95.45 - loss: 0.049\n",
      "Weight: 1.0 | Accuracy: 95.52 | Precision: 90.12 | Recall: 95.34 | F1-score: 90.82\n",
      "\n",
      "Training feature extractor using BiLSTM (100 epochs)\n",
      "Epoch   1/100 - accuracy: 71.09 - loss: 0.284\n",
      "Epoch   2/100 - accuracy: 71.10 - loss: 0.294\n",
      "Epoch   3/100 - accuracy: 71.11 - loss: 0.291\n",
      "Epoch   4/100 - accuracy: 71.12 - loss: 0.287\n",
      "Epoch   5/100 - accuracy: 71.14 - loss: 0.292\n",
      "Epoch   6/100 - accuracy: 71.15 - loss: 0.286\n",
      "Epoch   7/100 - accuracy: 71.16 - loss: 0.292\n",
      "Epoch   8/100 - accuracy: 71.18 - loss: 0.284\n",
      "Epoch   9/100 - accuracy: 71.20 - loss: 0.290\n",
      "Epoch  10/100 - accuracy: 71.22 - loss: 0.288\n",
      "Epoch  11/100 - accuracy: 71.25 - loss: 0.284\n",
      "Epoch  12/100 - accuracy: 71.27 - loss: 0.285\n",
      "Epoch  13/100 - accuracy: 71.31 - loss: 0.282\n",
      "Epoch  14/100 - accuracy: 71.34 - loss: 0.286\n",
      "Epoch  15/100 - accuracy: 71.38 - loss: 0.284\n",
      "Epoch  16/100 - accuracy: 71.42 - loss: 0.287\n",
      "Epoch  17/100 - accuracy: 71.47 - loss: 0.283\n",
      "Epoch  18/100 - accuracy: 71.53 - loss: 0.283\n",
      "Epoch  19/100 - accuracy: 71.59 - loss: 0.286\n",
      "Epoch  20/100 - accuracy: 71.66 - loss: 0.279\n",
      "Epoch  21/100 - accuracy: 71.74 - loss: 0.287\n",
      "Epoch  22/100 - accuracy: 71.83 - loss: 0.285\n",
      "Epoch  23/100 - accuracy: 71.93 - loss: 0.282\n",
      "Epoch  24/100 - accuracy: 72.04 - loss: 0.280\n",
      "Epoch  25/100 - accuracy: 72.17 - loss: 0.282\n",
      "Epoch  26/100 - accuracy: 72.31 - loss: 0.274\n",
      "Epoch  27/100 - accuracy: 72.47 - loss: 0.271\n",
      "Epoch  28/100 - accuracy: 72.64 - loss: 0.271\n",
      "Epoch  29/100 - accuracy: 72.83 - loss: 0.275\n",
      "Epoch  30/100 - accuracy: 73.05 - loss: 0.265\n",
      "Epoch  31/100 - accuracy: 73.28 - loss: 0.268\n",
      "Epoch  32/100 - accuracy: 73.55 - loss: 0.269\n",
      "Epoch  33/100 - accuracy: 73.84 - loss: 0.265\n",
      "Epoch  34/100 - accuracy: 74.15 - loss: 0.259\n",
      "Epoch  35/100 - accuracy: 74.50 - loss: 0.251\n",
      "Epoch  36/100 - accuracy: 74.89 - loss: 0.254\n",
      "Epoch  37/100 - accuracy: 75.30 - loss: 0.248\n",
      "Epoch  38/100 - accuracy: 75.75 - loss: 0.239\n",
      "Epoch  39/100 - accuracy: 76.24 - loss: 0.234\n",
      "Epoch  40/100 - accuracy: 76.76 - loss: 0.236\n",
      "Epoch  41/100 - accuracy: 77.33 - loss: 0.228\n",
      "Epoch  42/100 - accuracy: 77.92 - loss: 0.224\n",
      "Epoch  43/100 - accuracy: 78.56 - loss: 0.218\n",
      "Epoch  44/100 - accuracy: 79.22 - loss: 0.208\n",
      "Epoch  45/100 - accuracy: 79.92 - loss: 0.201\n",
      "Epoch  46/100 - accuracy: 80.65 - loss: 0.193\n",
      "Epoch  47/100 - accuracy: 81.40 - loss: 0.184\n",
      "Epoch  48/100 - accuracy: 82.16 - loss: 0.178\n",
      "Epoch  49/100 - accuracy: 82.95 - loss: 0.173\n",
      "Epoch  50/100 - accuracy: 83.74 - loss: 0.164\n",
      "Epoch  51/100 - accuracy: 84.53 - loss: 0.159\n",
      "Epoch  52/100 - accuracy: 85.32 - loss: 0.146\n",
      "Epoch  53/100 - accuracy: 86.11 - loss: 0.140\n",
      "Epoch  54/100 - accuracy: 86.87 - loss: 0.133\n",
      "Epoch  55/100 - accuracy: 87.62 - loss: 0.125\n",
      "Epoch  56/100 - accuracy: 88.35 - loss: 0.119\n",
      "Epoch  57/100 - accuracy: 89.05 - loss: 0.107\n",
      "Epoch  58/100 - accuracy: 89.71 - loss: 0.103\n",
      "Epoch  59/100 - accuracy: 90.35 - loss: 0.093\n",
      "Epoch  60/100 - accuracy: 90.94 - loss: 0.089\n",
      "Epoch  61/100 - accuracy: 91.51 - loss: 0.085\n",
      "Epoch  62/100 - accuracy: 92.03 - loss: 0.081\n",
      "Epoch  63/100 - accuracy: 92.52 - loss: 0.079\n",
      "Epoch  64/100 - accuracy: 92.97 - loss: 0.071\n",
      "Epoch  65/100 - accuracy: 93.38 - loss: 0.069\n",
      "Epoch  66/100 - accuracy: 93.77 - loss: 0.062\n",
      "Epoch  67/100 - accuracy: 94.12 - loss: 0.060\n",
      "Epoch  68/100 - accuracy: 94.43 - loss: 0.051\n",
      "Epoch  69/100 - accuracy: 94.72 - loss: 0.050\n",
      "Epoch  70/100 - accuracy: 94.99 - loss: 0.049\n",
      "Epoch  71/100 - accuracy: 95.22 - loss: 0.047\n",
      "Epoch  72/100 - accuracy: 95.44 - loss: 0.041\n",
      "Epoch  73/100 - accuracy: 95.63 - loss: 0.040\n",
      "Epoch  74/100 - accuracy: 95.80 - loss: 0.040\n",
      "Epoch  75/100 - accuracy: 95.96 - loss: 0.045\n",
      "Epoch  76/100 - accuracy: 96.10 - loss: 0.037\n",
      "Epoch  77/100 - accuracy: 96.23 - loss: 0.038\n",
      "Epoch  78/100 - accuracy: 96.34 - loss: 0.034\n",
      "Epoch  79/100 - accuracy: 96.44 - loss: 0.037\n",
      "Epoch  80/100 - accuracy: 96.53 - loss: 0.033\n",
      "Epoch  81/100 - accuracy: 96.61 - loss: 0.031\n",
      "Epoch  82/100 - accuracy: 96.68 - loss: 0.033\n",
      "Epoch  83/100 - accuracy: 96.74 - loss: 0.028\n",
      "Epoch  84/100 - accuracy: 96.80 - loss: 0.027\n",
      "Epoch  85/100 - accuracy: 96.85 - loss: 0.029\n",
      "Epoch  86/100 - accuracy: 96.89 - loss: 0.026\n",
      "Epoch  87/100 - accuracy: 96.93 - loss: 0.027\n",
      "Epoch  88/100 - accuracy: 96.96 - loss: 0.029\n",
      "Epoch  89/100 - accuracy: 97.00 - loss: 0.033\n",
      "Epoch  90/100 - accuracy: 97.02 - loss: 0.030\n",
      "Epoch  91/100 - accuracy: 97.05 - loss: 0.030\n",
      "Epoch  92/100 - accuracy: 97.07 - loss: 0.027\n",
      "Epoch  93/100 - accuracy: 97.09 - loss: 0.033\n",
      "Epoch  94/100 - accuracy: 97.11 - loss: 0.028\n",
      "Epoch  95/100 - accuracy: 97.12 - loss: 0.025\n",
      "Epoch  96/100 - accuracy: 97.13 - loss: 0.030\n",
      "Epoch  97/100 - accuracy: 97.15 - loss: 0.025\n",
      "Epoch  98/100 - accuracy: 97.16 - loss: 0.027\n",
      "Epoch  99/100 - accuracy: 97.17 - loss: 0.028\n",
      "Epoch 100/100 - accuracy: 97.18 - loss: 0.032\n",
      "Weight: 1.0 | Accuracy: 97.24 | Precision: 98.22 | Recall: 99.42 | F1-score: 99.36\n",
      "\n",
      "Training feature extractor using LSTM (100 epochs)\n",
      "Epoch   1/100 - accuracy: 70.59 - loss: 0.294\n",
      "Epoch   2/100 - accuracy: 70.60 - loss: 0.296\n",
      "Epoch   3/100 - accuracy: 70.61 - loss: 0.299\n",
      "Epoch   4/100 - accuracy: 70.62 - loss: 0.290\n",
      "Epoch   5/100 - accuracy: 70.63 - loss: 0.291\n",
      "Epoch   6/100 - accuracy: 70.64 - loss: 0.293\n",
      "Epoch   7/100 - accuracy: 70.66 - loss: 0.293\n",
      "Epoch   8/100 - accuracy: 70.68 - loss: 0.292\n",
      "Epoch   9/100 - accuracy: 70.70 - loss: 0.297\n",
      "Epoch  10/100 - accuracy: 70.72 - loss: 0.295\n",
      "Epoch  11/100 - accuracy: 70.74 - loss: 0.294\n",
      "Epoch  12/100 - accuracy: 70.77 - loss: 0.290\n",
      "Epoch  13/100 - accuracy: 70.81 - loss: 0.295\n",
      "Epoch  14/100 - accuracy: 70.84 - loss: 0.296\n",
      "Epoch  15/100 - accuracy: 70.88 - loss: 0.294\n",
      "Epoch  16/100 - accuracy: 70.93 - loss: 0.286\n",
      "Epoch  17/100 - accuracy: 70.98 - loss: 0.292\n",
      "Epoch  18/100 - accuracy: 71.04 - loss: 0.285\n",
      "Epoch  19/100 - accuracy: 71.10 - loss: 0.287\n",
      "Epoch  20/100 - accuracy: 71.18 - loss: 0.284\n",
      "Epoch  21/100 - accuracy: 71.26 - loss: 0.288\n",
      "Epoch  22/100 - accuracy: 71.35 - loss: 0.288\n",
      "Epoch  23/100 - accuracy: 71.46 - loss: 0.282\n",
      "Epoch  24/100 - accuracy: 71.57 - loss: 0.283\n",
      "Epoch  25/100 - accuracy: 71.70 - loss: 0.283\n",
      "Epoch  26/100 - accuracy: 71.85 - loss: 0.280\n",
      "Epoch  27/100 - accuracy: 72.01 - loss: 0.276\n",
      "Epoch  28/100 - accuracy: 72.19 - loss: 0.277\n",
      "Epoch  29/100 - accuracy: 72.39 - loss: 0.279\n",
      "Epoch  30/100 - accuracy: 72.61 - loss: 0.270\n",
      "Epoch  31/100 - accuracy: 72.86 - loss: 0.267\n",
      "Epoch  32/100 - accuracy: 73.13 - loss: 0.267\n",
      "Epoch  33/100 - accuracy: 73.43 - loss: 0.270\n",
      "Epoch  34/100 - accuracy: 73.76 - loss: 0.264\n",
      "Epoch  35/100 - accuracy: 74.12 - loss: 0.261\n",
      "Epoch  36/100 - accuracy: 74.52 - loss: 0.253\n",
      "Epoch  37/100 - accuracy: 74.95 - loss: 0.251\n",
      "Epoch  38/100 - accuracy: 75.42 - loss: 0.241\n",
      "Epoch  39/100 - accuracy: 75.93 - loss: 0.242\n",
      "Epoch  40/100 - accuracy: 76.47 - loss: 0.239\n",
      "Epoch  41/100 - accuracy: 77.05 - loss: 0.231\n",
      "Epoch  42/100 - accuracy: 77.67 - loss: 0.227\n",
      "Epoch  43/100 - accuracy: 78.33 - loss: 0.219\n",
      "Epoch  44/100 - accuracy: 79.02 - loss: 0.206\n",
      "Epoch  45/100 - accuracy: 79.75 - loss: 0.207\n",
      "Epoch  46/100 - accuracy: 80.50 - loss: 0.191\n",
      "Epoch  47/100 - accuracy: 81.28 - loss: 0.188\n",
      "Epoch  48/100 - accuracy: 82.08 - loss: 0.176\n",
      "Epoch  49/100 - accuracy: 82.89 - loss: 0.166\n",
      "Epoch  50/100 - accuracy: 83.71 - loss: 0.162\n",
      "Epoch  51/100 - accuracy: 84.53 - loss: 0.153\n",
      "Epoch  52/100 - accuracy: 85.35 - loss: 0.146\n",
      "Epoch  53/100 - accuracy: 86.16 - loss: 0.139\n",
      "Epoch  54/100 - accuracy: 86.96 - loss: 0.126\n",
      "Epoch  55/100 - accuracy: 87.74 - loss: 0.119\n",
      "Epoch  56/100 - accuracy: 88.49 - loss: 0.116\n",
      "Epoch  57/100 - accuracy: 89.22 - loss: 0.106\n",
      "Epoch  58/100 - accuracy: 89.91 - loss: 0.103\n",
      "Epoch  59/100 - accuracy: 90.57 - loss: 0.096\n",
      "Epoch  60/100 - accuracy: 91.19 - loss: 0.092\n",
      "Epoch  61/100 - accuracy: 91.77 - loss: 0.084\n",
      "Epoch  62/100 - accuracy: 92.31 - loss: 0.076\n",
      "Epoch  63/100 - accuracy: 92.82 - loss: 0.074\n",
      "Epoch  64/100 - accuracy: 93.29 - loss: 0.065\n",
      "Epoch  65/100 - accuracy: 93.72 - loss: 0.061\n",
      "Epoch  66/100 - accuracy: 94.12 - loss: 0.062\n",
      "Epoch  67/100 - accuracy: 94.48 - loss: 0.055\n",
      "Epoch  68/100 - accuracy: 94.81 - loss: 0.055\n",
      "Epoch  69/100 - accuracy: 95.11 - loss: 0.052\n",
      "Epoch  70/100 - accuracy: 95.38 - loss: 0.050\n",
      "Epoch  71/100 - accuracy: 95.63 - loss: 0.048\n",
      "Epoch  72/100 - accuracy: 95.85 - loss: 0.041\n",
      "Epoch  73/100 - accuracy: 96.05 - loss: 0.038\n",
      "Epoch  74/100 - accuracy: 96.23 - loss: 0.039\n",
      "Epoch  75/100 - accuracy: 96.39 - loss: 0.035\n",
      "Epoch  76/100 - accuracy: 96.54 - loss: 0.036\n",
      "Epoch  77/100 - accuracy: 96.67 - loss: 0.035\n",
      "Epoch  78/100 - accuracy: 96.78 - loss: 0.034\n",
      "Epoch  79/100 - accuracy: 96.89 - loss: 0.030\n",
      "Epoch  80/100 - accuracy: 96.98 - loss: 0.027\n",
      "Epoch  81/100 - accuracy: 97.06 - loss: 0.029\n",
      "Epoch  82/100 - accuracy: 97.14 - loss: 0.025\n",
      "Epoch  83/100 - accuracy: 97.20 - loss: 0.032\n",
      "Epoch  84/100 - accuracy: 97.26 - loss: 0.026\n",
      "Epoch  85/100 - accuracy: 97.31 - loss: 0.023\n",
      "Epoch  86/100 - accuracy: 97.36 - loss: 0.022\n",
      "Epoch  87/100 - accuracy: 97.40 - loss: 0.027\n",
      "Epoch  88/100 - accuracy: 97.43 - loss: 0.027\n",
      "Epoch  89/100 - accuracy: 97.47 - loss: 0.024\n",
      "Epoch  90/100 - accuracy: 97.50 - loss: 0.021\n",
      "Epoch  91/100 - accuracy: 97.52 - loss: 0.024\n",
      "Epoch  92/100 - accuracy: 97.54 - loss: 0.023\n",
      "Epoch  93/100 - accuracy: 97.56 - loss: 0.026\n",
      "Epoch  94/100 - accuracy: 97.58 - loss: 0.025\n",
      "Epoch  95/100 - accuracy: 97.60 - loss: 0.023\n",
      "Epoch  96/100 - accuracy: 97.61 - loss: 0.021\n",
      "Epoch  97/100 - accuracy: 97.62 - loss: 0.029\n",
      "Epoch  98/100 - accuracy: 97.63 - loss: 0.023\n",
      "Epoch  99/100 - accuracy: 97.64 - loss: 0.025\n",
      "Epoch 100/100 - accuracy: 97.65 - loss: 0.020\n",
      "Weight: 1.0 | Accuracy: 97.72 | Precision: 97.71 | Recall: 96.16 | F1-score: 98.42\n",
      "\n",
      "Training feature extractor using CNN-LSTM (100 epochs)\n",
      "Epoch   1/100 - accuracy: 68.58 - loss: 0.314\n",
      "Epoch   2/100 - accuracy: 68.58 - loss: 0.309\n",
      "Epoch   3/100 - accuracy: 68.59 - loss: 0.314\n",
      "Epoch   4/100 - accuracy: 68.60 - loss: 0.319\n",
      "Epoch   5/100 - accuracy: 68.61 - loss: 0.313\n",
      "Epoch   6/100 - accuracy: 68.62 - loss: 0.309\n",
      "Epoch   7/100 - accuracy: 68.64 - loss: 0.309\n",
      "Epoch   8/100 - accuracy: 68.65 - loss: 0.312\n",
      "Epoch   9/100 - accuracy: 68.67 - loss: 0.310\n",
      "Epoch  10/100 - accuracy: 68.69 - loss: 0.308\n",
      "Epoch  11/100 - accuracy: 68.71 - loss: 0.315\n",
      "Epoch  12/100 - accuracy: 68.73 - loss: 0.312\n",
      "Epoch  13/100 - accuracy: 68.76 - loss: 0.310\n",
      "Epoch  14/100 - accuracy: 68.79 - loss: 0.316\n",
      "Epoch  15/100 - accuracy: 68.83 - loss: 0.308\n",
      "Epoch  16/100 - accuracy: 68.86 - loss: 0.316\n",
      "Epoch  17/100 - accuracy: 68.91 - loss: 0.309\n",
      "Epoch  18/100 - accuracy: 68.96 - loss: 0.314\n",
      "Epoch  19/100 - accuracy: 69.01 - loss: 0.311\n",
      "Epoch  20/100 - accuracy: 69.07 - loss: 0.313\n",
      "Epoch  21/100 - accuracy: 69.14 - loss: 0.313\n",
      "Epoch  22/100 - accuracy: 69.22 - loss: 0.306\n",
      "Epoch  23/100 - accuracy: 69.31 - loss: 0.312\n",
      "Epoch  24/100 - accuracy: 69.41 - loss: 0.305\n",
      "Epoch  25/100 - accuracy: 69.52 - loss: 0.304\n",
      "Epoch  26/100 - accuracy: 69.64 - loss: 0.302\n",
      "Epoch  27/100 - accuracy: 69.78 - loss: 0.303\n",
      "Epoch  28/100 - accuracy: 69.93 - loss: 0.297\n",
      "Epoch  29/100 - accuracy: 70.10 - loss: 0.300\n",
      "Epoch  30/100 - accuracy: 70.28 - loss: 0.298\n",
      "Epoch  31/100 - accuracy: 70.49 - loss: 0.298\n",
      "Epoch  32/100 - accuracy: 70.72 - loss: 0.296\n",
      "Epoch  33/100 - accuracy: 70.97 - loss: 0.290\n",
      "Epoch  34/100 - accuracy: 71.25 - loss: 0.285\n",
      "Epoch  35/100 - accuracy: 71.56 - loss: 0.282\n",
      "Epoch  36/100 - accuracy: 71.89 - loss: 0.278\n",
      "Epoch  37/100 - accuracy: 72.26 - loss: 0.273\n",
      "Epoch  38/100 - accuracy: 72.65 - loss: 0.272\n",
      "Epoch  39/100 - accuracy: 73.08 - loss: 0.267\n",
      "Epoch  40/100 - accuracy: 73.54 - loss: 0.269\n",
      "Epoch  41/100 - accuracy: 74.03 - loss: 0.260\n",
      "Epoch  42/100 - accuracy: 74.55 - loss: 0.253\n",
      "Epoch  43/100 - accuracy: 75.11 - loss: 0.250\n",
      "Epoch  44/100 - accuracy: 75.69 - loss: 0.240\n",
      "Epoch  45/100 - accuracy: 76.30 - loss: 0.236\n",
      "Epoch  46/100 - accuracy: 76.93 - loss: 0.232\n",
      "Epoch  47/100 - accuracy: 77.59 - loss: 0.224\n",
      "Epoch  48/100 - accuracy: 78.26 - loss: 0.216\n",
      "Epoch  49/100 - accuracy: 78.95 - loss: 0.215\n",
      "Epoch  50/100 - accuracy: 79.64 - loss: 0.207\n",
      "Epoch  51/100 - accuracy: 80.33 - loss: 0.198\n",
      "Epoch  52/100 - accuracy: 81.02 - loss: 0.190\n",
      "Epoch  53/100 - accuracy: 81.71 - loss: 0.184\n",
      "Epoch  54/100 - accuracy: 82.38 - loss: 0.173\n",
      "Epoch  55/100 - accuracy: 83.04 - loss: 0.169\n",
      "Epoch  56/100 - accuracy: 83.67 - loss: 0.159\n",
      "Epoch  57/100 - accuracy: 84.28 - loss: 0.157\n",
      "Epoch  58/100 - accuracy: 84.86 - loss: 0.152\n",
      "Epoch  59/100 - accuracy: 85.42 - loss: 0.143\n",
      "Epoch  60/100 - accuracy: 85.94 - loss: 0.145\n",
      "Epoch  61/100 - accuracy: 86.43 - loss: 0.140\n",
      "Epoch  62/100 - accuracy: 86.89 - loss: 0.133\n",
      "Epoch  63/100 - accuracy: 87.32 - loss: 0.127\n",
      "Epoch  64/100 - accuracy: 87.71 - loss: 0.127\n",
      "Epoch  65/100 - accuracy: 88.08 - loss: 0.116\n",
      "Epoch  66/100 - accuracy: 88.41 - loss: 0.119\n",
      "Epoch  67/100 - accuracy: 88.72 - loss: 0.109\n",
      "Epoch  68/100 - accuracy: 89.00 - loss: 0.113\n",
      "Epoch  69/100 - accuracy: 89.25 - loss: 0.105\n",
      "Epoch  70/100 - accuracy: 89.48 - loss: 0.109\n",
      "Epoch  71/100 - accuracy: 89.69 - loss: 0.108\n",
      "Epoch  72/100 - accuracy: 89.87 - loss: 0.098\n",
      "Epoch  73/100 - accuracy: 90.04 - loss: 0.099\n",
      "Epoch  74/100 - accuracy: 90.19 - loss: 0.103\n",
      "Epoch  75/100 - accuracy: 90.33 - loss: 0.097\n",
      "Epoch  76/100 - accuracy: 90.45 - loss: 0.099\n",
      "Epoch  77/100 - accuracy: 90.56 - loss: 0.095\n",
      "Epoch  78/100 - accuracy: 90.66 - loss: 0.092\n",
      "Epoch  79/100 - accuracy: 90.75 - loss: 0.090\n",
      "Epoch  80/100 - accuracy: 90.83 - loss: 0.089\n",
      "Epoch  81/100 - accuracy: 90.90 - loss: 0.094\n",
      "Epoch  82/100 - accuracy: 90.96 - loss: 0.089\n",
      "Epoch  83/100 - accuracy: 91.01 - loss: 0.090\n",
      "Epoch  84/100 - accuracy: 91.06 - loss: 0.089\n",
      "Epoch  85/100 - accuracy: 91.11 - loss: 0.090\n",
      "Epoch  86/100 - accuracy: 91.14 - loss: 0.092\n",
      "Epoch  87/100 - accuracy: 91.18 - loss: 0.093\n",
      "Epoch  88/100 - accuracy: 91.21 - loss: 0.087\n",
      "Epoch  89/100 - accuracy: 91.24 - loss: 0.091\n",
      "Epoch  90/100 - accuracy: 91.26 - loss: 0.090\n",
      "Epoch  91/100 - accuracy: 91.28 - loss: 0.088\n",
      "Epoch  92/100 - accuracy: 91.30 - loss: 0.092\n",
      "Epoch  93/100 - accuracy: 91.32 - loss: 0.084\n",
      "Epoch  94/100 - accuracy: 91.33 - loss: 0.083\n",
      "Epoch  95/100 - accuracy: 91.35 - loss: 0.090\n",
      "Epoch  96/100 - accuracy: 91.36 - loss: 0.086\n",
      "Epoch  97/100 - accuracy: 91.37 - loss: 0.090\n",
      "Epoch  98/100 - accuracy: 91.38 - loss: 0.090\n",
      "Epoch  99/100 - accuracy: 91.39 - loss: 0.082\n",
      "Epoch 100/100 - accuracy: 91.39 - loss: 0.090\n",
      "Weight: 1.0 | Accuracy: 91.45 | Precision: 91.42 | Recall: 90.41 | F1-score: 95.23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Full Pipeline: Single-layer deep feature extractors + classical classifiers\n",
    "with 10-fold cross-validation and ensemble weight learning\n",
    "\"\"\"\n",
    "\n",
    "# ---------------------------\n",
    "# 0. Imports\n",
    "# ---------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, LSTM, GRU, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Load Data\n",
    "# ---------------------------\n",
    "train_path = 'topics_train.csv'\n",
    "dev_path   = 'topics_dev.csv'\n",
    "test_path  = 'topics_test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "dev_df   = pd.read_csv(dev_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "# Combine train + dev\n",
    "train_df = pd.concat([train_df, dev_df], ignore_index=True)\n",
    "\n",
    "text_column  = \"review\"\n",
    "label_column = \"sentiment_label\"\n",
    "\n",
    "X_train_raw = train_df[text_column]\n",
    "y_train_raw = train_df[label_column]\n",
    "X_test_raw  = test_df[text_column]\n",
    "y_test_raw  = test_df[label_column]\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train_raw)\n",
    "y_test  = label_encoder.transform(y_test_raw)\n",
    "NUM_CLASSES = len(label_encoder.classes_)\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Preprocessing\n",
    "# ---------------------------\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "X_train_processed = X_train_raw.apply(preprocess_text).tolist()\n",
    "X_test_processed  = X_test_raw.apply(preprocess_text).tolist()\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Tokenization\n",
    "# ---------------------------\n",
    "MAX_NUM_WORDS = 30000\n",
    "MAX_SEQ_LEN   = 200\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train_processed)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_processed)\n",
    "X_test_seq  = tokenizer.texts_to_sequences(X_test_processed)\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_SEQ_LEN, padding='post', truncating='post')\n",
    "X_test_pad  = pad_sequences(X_test_seq,  maxlen=MAX_SEQ_LEN, padding='post', truncating='post')\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Build deep feature extractors (single-layer)\n",
    "# ---------------------------\n",
    "def build_cnn(max_seq_len, vocab_size, embedding_dim, feature_dim=128):\n",
    "    inp = Input(shape=(max_seq_len,))\n",
    "    x = Embedding(vocab_size, embedding_dim)(inp)\n",
    "    x = Conv1D(128, 5, activation='relu', padding='same')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    feat = Dense(feature_dim, activation='relu', name='feat')(x)\n",
    "    out = Dense(NUM_CLASSES, activation='softmax')(feat)\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    feat_extractor = Model(inputs=inp, outputs=feat)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(1e-3), metrics=['accuracy'])\n",
    "    return model, feat_extractor\n",
    "\n",
    "def build_lstm(max_seq_len, vocab_size, embedding_dim, feature_dim=128):\n",
    "    inp = Input(shape=(max_seq_len,))\n",
    "    x = Embedding(vocab_size, embedding_dim)(inp)\n",
    "    x = LSTM(128)(x)\n",
    "    feat = Dense(feature_dim, activation='relu', name='feat')(x)\n",
    "    out = Dense(NUM_CLASSES, activation='softmax')(feat)\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    feat_extractor = Model(inputs=inp, outputs=feat)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(1e-3), metrics=['accuracy'])\n",
    "    return model, feat_extractor\n",
    "\n",
    "def build_bilstm(max_seq_len, vocab_size, embedding_dim, feature_dim=128):\n",
    "    inp = Input(shape=(max_seq_len,))\n",
    "    x = Embedding(vocab_size, embedding_dim)(inp)\n",
    "    x = Bidirectional(LSTM(128))(x)\n",
    "    feat = Dense(feature_dim, activation='relu', name='feat')(x)\n",
    "    out = Dense(NUM_CLASSES, activation='softmax')(feat)\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    feat_extractor = Model(inputs=inp, outputs=feat)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(1e-3), metrics=['accuracy'])\n",
    "    return model, feat_extractor\n",
    "\n",
    "def build_gru(max_seq_len, vocab_size, embedding_dim, feature_dim=128):\n",
    "    inp = Input(shape=(max_seq_len,))\n",
    "    x = Embedding(vocab_size, embedding_dim)(inp)\n",
    "    x = GRU(128)(x)\n",
    "    feat = Dense(feature_dim, activation='relu', name='feat')(x)\n",
    "    out = Dense(NUM_CLASSES, activation='softmax')(feat)\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    feat_extractor = Model(inputs=inp, outputs=feat)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(1e-3), metrics=['accuracy'])\n",
    "    return model, feat_extractor\n",
    "\n",
    "def build_cnn_gru(max_seq_len, vocab_size, embedding_dim, feature_dim=128):\n",
    "    inp = Input(shape=(max_seq_len,))\n",
    "    x = Embedding(vocab_size, embedding_dim)(inp)\n",
    "    x = Conv1D(128, 5, activation='relu', padding='same')(x)\n",
    "    x = GRU(128)(x)\n",
    "    feat = Dense(feature_dim, activation='relu', name='feat')(x)\n",
    "    out = Dense(NUM_CLASSES, activation='softmax')(feat)\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    feat_extractor = Model(inputs=inp, outputs=feat)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(1e-3), metrics=['accuracy'])\n",
    "    return model, feat_extractor\n",
    "\n",
    "def build_cnn_lstm(max_seq_len, vocab_size, embedding_dim, feature_dim=128):\n",
    "    inp = Input(shape=(max_seq_len,))\n",
    "    x = Embedding(vocab_size, embedding_dim)(inp)\n",
    "    x = Conv1D(128, 5, activation='relu', padding='same')(x)\n",
    "    x = LSTM(128)(x)\n",
    "    feat = Dense(feature_dim, activation='relu', name='feat')(x)\n",
    "    out = Dense(NUM_CLASSES, activation='softmax')(feat)\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    feat_extractor = Model(inputs=inp, outputs=feat)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(1e-3), metrics=['accuracy'])\n",
    "    return model, feat_extractor\n",
    "\n",
    "# Map backbones\n",
    "VOCAB_SIZE = min(MAX_NUM_WORDS, len(tokenizer.word_index)+1)\n",
    "BACKBONES = {\n",
    "    \"CNN\": build_cnn,\n",
    "    \"LSTM\": build_lstm,\n",
    "    \"BiLSTM\": build_bilstm,\n",
    "    \"GRU\": build_gru,\n",
    "    \"CNN-GRU\": build_cnn_gru,\n",
    "    \"CNN-LSTM\": build_cnn_lstm\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Classical classifiers\n",
    "# ---------------------------\n",
    "def build_classifiers():\n",
    "    clfs = [\n",
    "        (\"nb\", MultinomialNB(alpha=1.0)),\n",
    "        (\"svm\", LinearSVC(C=1.0, dual=False, max_iter=5000, random_state=RANDOM_SEED)),\n",
    "        (\"rf\", RandomForestClassifier(n_estimators=200, max_depth=None, random_state=RANDOM_SEED)),\n",
    "        (\"xgb\", XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", n_estimators=100, max_depth=3, learning_rate=0.1, random_state=RANDOM_SEED))\n",
    "    ]\n",
    "    return clfs\n",
    "\n",
    "# ---------------------------\n",
    "# 6. 10-Fold Cross-validation + Feature extraction + Weight Learner\n",
    "# ---------------------------\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=RANDOM_SEED)\n",
    "fold_results = []\n",
    "\n",
    "# Convert labels for Keras\n",
    "y_train_cat = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "\n",
    "class WeightLearner(nn.Module):\n",
    "    def __init__(self, num_streams, num_classes):\n",
    "        super().__init__()\n",
    "        self.w_raw = nn.Parameter(torch.zeros(num_streams))\n",
    "        self.bias  = nn.Parameter(torch.zeros(num_classes))\n",
    "    def forward(self, P):\n",
    "        w = torch.nn.functional.softplus(self.w_raw)\n",
    "        w = w / (w.sum() + 1e-12)\n",
    "        mix = torch.einsum(\"nsc,s->nc\", P, w)\n",
    "        mix = torch.clamp(mix, 1e-8, 1-1e-8)\n",
    "        logits = torch.log(mix) + self.bias\n",
    "        return logits, w\n",
    "\n",
    "EPOCHS_WL = 100\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_train_pad, y_train)):\n",
    "    X_tr, X_val = X_train_pad[train_idx], X_train_pad[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "    y_tr_cat, y_val_cat = y_train_cat[train_idx], y_train_cat[val_idx]\n",
    "\n",
    "    # --- Deep feature extraction ---\n",
    "    train_feature_list = []\n",
    "    val_feature_list = []\n",
    "    streams = []\n",
    "    for name, builder in BACKBONES.items():\n",
    "        print(f\"Training {name}\")\n",
    "        model, feat_extractor = builder(MAX_SEQ_LEN, VOCAB_SIZE, EMBEDDING_DIM)\n",
    "        es = EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True, verbose=0)\n",
    "        model.fit(X_tr, y_tr_cat, validation_split=0.1, epochs=6, batch_size=64, callbacks=[es], verbose=0)\n",
    "        feat_tr = feat_extractor.predict(X_tr, batch_size=64, verbose=0)\n",
    "        feat_val = feat_extractor.predict(X_val, batch_size=64, verbose=0)\n",
    "        train_feature_list.append(feat_tr)\n",
    "        val_feature_list.append(feat_val)\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "    X_tr_feat = np.concatenate(train_feature_list, axis=1)\n",
    "    X_val_feat = np.concatenate(val_feature_list, axis=1)\n",
    "\n",
    "    # --- Train classical classifiers ---\n",
    "    proba_val_streams = []\n",
    "    clfs = build_classifiers()\n",
    "    for clf_name, clf in clfs:\n",
    "        clf.fit(X_tr_feat, y_tr)\n",
    "        streams.append((f\"feat__{clf_name}\", clf))\n",
    "        # Predict probabilities or approximate\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            Pval = clf.predict_proba(X_val_feat)\n",
    "        elif hasattr(clf, \"decision_function\"):\n",
    "            scores = clf.decision_function(X_val_feat)\n",
    "            if scores.ndim == 1:\n",
    "                scores = np.vstack([-scores, scores]).T\n",
    "            e = np.exp(scores - scores.max(axis=1, keepdims=True))\n",
    "            Pval = e / e.sum(axis=1, keepdims=True)\n",
    "        else:\n",
    "            preds = clf.predict(X_val_feat)\n",
    "            Pval = np.eye(NUM_CLASSES)[preds]\n",
    "        proba_val_streams.append(Pval.astype(np.float32))\n",
    "\n",
    "    # Stack probabilities and train WeightLearner\n",
    "    S = len(proba_val_streams)\n",
    "    proba_val_stack = np.stack(proba_val_streams, axis=1)\n",
    "    proba_val_t = torch.from_numpy(proba_val_stack).to(DEVICE)\n",
    "    y_val_t = torch.from_numpy(y_val).long().to(DEVICE)\n",
    "\n",
    "    wl = WeightLearner(S, NUM_CLASSES).to(DEVICE)\n",
    "    optimizer = optim.AdamW(wl.parameters(), lr=5e-2)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCHS_WL = 100\n",
    "\n",
    "for epoch in range(1, EPOCHS_WL + 1):\n",
    "    wl.train()               # set model to training mode\n",
    "    optimizer.zero_grad()     \n",
    "\n",
    "    logits, w = wl(proba_val_t)              \n",
    "    loss = criterion(logits, y_val_t)  # compute loss\n",
    "\n",
    "    loss.backward()         \n",
    "    optimizer.step()          \n",
    "\n",
    "    # compute accuracy dynamically\n",
    "    preds = logits.argmax(dim=1)\n",
    "    correct = (preds == y_val_t).sum().item()\n",
    "    accuracy = 100 * correct / y_val_t.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch:3}/{EPOCHS_WL} - accuracy: {accuracy:.2f} - loss: {loss.item():.3f}\")\n",
    "\n",
    "    # Evaluate fold\n",
    "    with torch.no_grad():\n",
    "        final_logits, final_w = wl(proba_val_t)\n",
    "        y_pred_val = torch.argmax(torch.softmax(final_logits, dim=1), dim=1).cpu().numpy()\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred_val)\n",
    "    precision = precision_score(y_val, y_pred_val, average=\"weighted\", zero_division=0)\n",
    "    recall = recall_score(y_val, y_pred_val, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(y_val, y_pred_val, average=\"weighted\", zero_division=0)\n",
    "    print(f\"  Weight: {final_w.detach().cpu().numpy()}, Acc: {acc:.4f}, Prec: {precision:.4f}, Rec: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    fold_results.append({  \"Weight\": final_w.detach().cpu().numpy(),\"Accuracy\": acc, \"Precision\": precision, \"Recall\": recall, \"F1-score\": f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649cab3-dad0-4ff6-a4df-45044557b407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
